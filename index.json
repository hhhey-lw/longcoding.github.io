[{"content":"6319 HashMap 原理 数据结构：数组 + 链表 （JAVA8之后：数组+链表+红黑树）\n数据结构\njdk1.7：数组+链表，数组每个元素是一个链表的表头，当发生冲突，将新元素添加在头部(头插法) hash冲突：头插法，❗扩容时可能造成环形链表 jdk1.8： 引入红黑树，当链表节点超过8个，那么这个链表会转换为红黑树。查询时间由 O(n) 优化为 O(logn)。当节点小于6个，再转换为链表。 hash冲突：尾插法，避免环形链表❗ 扩容机制 jdk1.7 扩容，元素会重新计算hash值，并分配到新的扩容数组中。⭐比较耗时 扩容时，头插法，在多线程情况下，可能造成环形链表 jdk1.8 扩容时，利用了元素哈希值和旧数组容量关系，减少了重新计算的哈希次数 扩容时，尾插法，避免环形链表 使用键的hashcode()计算hash值，然后(n-1) \u0026amp; hash确定数组中的位置。\nn-1 =\u0026gt; 10000 - 1 = 01111 HashMap的初始默认容量为16，负载因子为0.75。当存储的元素达到75%时，进行扩容，扩容为原来的2倍空间\n扩展知识：\nhashmap的红黑树优化：\nJAVA8开始，为了优化hash冲突时的查找性能。但链表的长度超过8时，链表会转变为红黑树。红黑树是一种自平衡的二叉搜索树 查找时间 O(n) =\u0026gt; O(logn)。 当元素少于6个，切换为链表 hashCode() 和 equals()的重要性：\nhashCode计算hash值，决定键的存储位置。 而hashCode相同=\u0026gt;冲突。 equals()比较的值 1// HashMap Node class 2static class Entry\u0026lt;K,V\u0026gt; { 3 final K key; // 键 4 V value; // 值 5 final int hash; // 计算后的哈希值 6 Entry\u0026lt;K,V\u0026gt; next; // 指向下一个元素的指针（形成链表） 7} 为什么头插法\u0026amp;多线程\u0026amp;扩容会造成环形链表?\n1void transfer(Entry[] newTable) { 2 Entry[] src = table; 3 int newCapacity = newTable.length; 4 for (int j = 0; j \u0026lt; src.length; j++) { // 遍历旧表 5 Entry\u0026lt;K,V\u0026gt; e = src[j]; // 取出当前桶的头结点 6 if (e != null) { // 旧桶不为空 7 src[j] = null; // 释放旧桶的引用（防止 GC 误回收） 8 do { 9 Entry\u0026lt;K,V\u0026gt; next = e.next; // 记录下一个节点 10 int i = indexFor(e.hash, newCapacity); // 计算新索引（线程1暂停） 11 e.next = newTable[i]; // 头插法：将 e 连接到 newTable[i] 上 12 newTable[i] = e; // 将 e 作为 newTable[i] 的新头 13 e = next; // 继续处理下一个节点 14 } while (e != null); // 直到旧链表遍历完 15 } 16 } 17} 18 19old: [ ][ ][ ] old: [ ][ ][ ] 20 [1] [2] 21 [2] =\u0026gt; 22 23new: [ ][ ][ ] new: [ ][ ][ ] // 头插法，将节点进行转移 24 [1] 25 26// 环的情况，HashMap多个线程共享 27Thread1: e -\u0026gt; [1][ ][ ] Thread2: [3][ ][ ] 28 next-\u0026gt; [2] 扩容成功 [2] 29 [3] [1] 30 31执行 32{ 33 e.next = newTable[i]; 34 newTable[i] = e; 35 e = next; 36} 37 38newTabel[0] =\u0026gt; [1]-\u0026gt;[3]-\u0026gt;[2]-\u0026gt;[1] 39 ⬆️ ⬅️ ⬅️ 4948 HashMap，有哪些提升性能的技巧？ 合理设置初始容量，减少resize，减少扩容操作。默认16\n调整负载因子，查找多的设置小一点，减少冲突情况，冲突少了(查询效率就高了)，但会提高内存占用情况，反之亦然。默认0.75\n确保hashCode(), 均匀的是均匀分布的，以减少hash冲突。\n扩展：\n当元素数量 \u0026gt; 装填因子 * 数组大小 =\u0026gt; 进行扩容，新数组为当前的2倍，并把当前hash中的数据重新分配到新的hashmap中； LinkedHashMap，拉链法，能够保存插入顺序 保存有序 =\u0026gt; TreeMap. 需要线程安全 =\u0026gt; ConcurrentHashMap 4947 Hash碰撞 \u0026amp; 解决 不同key使用hashcode()\u0026amp;n-1得到相同的坑，然后冲突\n链地址法(拉链法) 开放地址法，顺序往下or左右横跳 线性探测 平方探测 再hash法(双重hash) 出现碰撞后，使用第二个hash函数计算新的索引位置，减少碰撞的概率。 4946 CopyOnWriteArrayList \u0026amp; Collections.synchronizeddList 区别 CopyOnWriteArrayList 是线程安全的List实现，特性是写时复制\n每次对List的修改操作(add, remove, set)都会创建一个新的底层数组。 读操作不需要加锁，而写操作需要加锁\n优点：\n读操作无锁，写操作会创建数组副本 =\u0026gt; 读写不冲突 ⭐读操作在当前数组上执行； 写操作(add,set,remove)会创建一个新数组，新数组上修改再替换旧的(加锁)。 缺点：\n写操作开销大：每次写操作都会创建并复制新数组，并且将数据复制到新的数组中，写频繁的场景下性能会比较低 内存消耗大 🎉适合读多写少的场景\nCollections.synchronizeddList 包装方法，将任何数组转换为线程安全的版本，会对每个访问方法(get, set, add, remove)进行同步(加锁)，线程安全。\n优点：\n方便 缺点：\n并发效率低 🎉适用于简单的将List转为线程安全的版本使用。\n444 Java中有哪些集合类？ List接口\nArrayList LinkedList Vector 基于动态数组实现，且线程安全，所有方法都添加了synchronized Set接口\nHashSet // 冲突的链表元素无序 LinkedHashSet // 继承HashSet，底层由双向链表实现，保证插入顺序 TreeSet // 基于红黑树, 自动排序，提供排序功能 Queue接口\nPriorityQueue， 优先队列，内部元素按级别排序。只能比较器 LinkedList，可以作为队列使用，FIFO Map接口\nHashMap LinkedHashMap TreeMap HashTable不推荐使用，线程安全的哈希表。**早期线程安全的HashMap，锁的粒度为整个表，这样并发能力不高。**底层使用synchronized关键字实现 ConcurrentHashMap，线程安全的hashmap。 高性能的线程安全HashMap 提供更细粒度的锁 分段锁和CAS操作 读操作不加锁 写操作 =\u0026gt; CAS + synchronized细粒度锁 9179 ArrayList的扩容机制是什么？ 默认容量10，当元素数量超过其当前容量，会触发扩容机制。 扩容大小为原数组的1.5倍\n449 HashSet \u0026amp; HashMap HashSet存储不重复元素 =\u0026gt; 不能冲突的HashMap\nHashMap，K=\u0026gt;V, 键唯一，但不同键的值可以相同\n451 HashMap的扩容机制 负载因子默认0.75, 但比例超过负载因子，进行扩容，扩容为原来的2倍。\n当前hashmap中的元素在新hashmap的位置怎么计算？ 就是hashCode() \u0026amp; (n-1) =\u0026gt; hashCode() \u0026amp; (2n-1)\n优化过程\n1// example: 2 n:16= 1,0000 n-1: 0,1111 2^4 32n:32=10,0000 2n-1:01,1111 2^5 4 5// 通过hash值 \u0026amp; 2n-1: 6// 只要判断最高位是否即可 7 8if 第5位== 0：then 9 位置不变； 10else 11 位置偏移16位 452 为什么HashMap扩容采用2的n次方？ 计算散列位置决定=\u0026gt; hashcode \u0026amp; (n-1) 其中 n-1=01111.. 可以将位置映射到数组的每个元素上，分布均匀。 位运算比取余效率高\n457 Java中的LinkedhashMap 基于HashMap \u0026amp; 双向链表 \u0026amp; 额外的顺序指针\n🏷️作用：保持插入顺序or访问顺序\n💠定义如下：\n1static class Entry\u0026lt;K,V\u0026gt; extends HashMap.Node\u0026lt;K,V\u0026gt; { 2 Entry\u0026lt;K,V\u0026gt; before, after; 3 Ectry(){...} // constructor 4} 🏷️图示：\n构想=\u0026gt; 由于可以根据插入时间排序，因此可以模拟LRU(least recently used)算法，进行淘汰最不常用的节点。\n461 ConcurrentHashMap 🏷️背景：在多线程并发条件下，普通的共享HashMap会存在线程安全问题，因为没有加锁，导致数据被覆盖\u0026hellip;；\n🏷️作用：通过同步机制加锁，使得HashMap在背景下是线程安全的，且还需要保证效率；\n🏷️定义：\nJDK1.7之前，采用分段锁，即每个Segment是独立的，将锁的粒度下方，提高线程并发度 利用数组+链表实现 =\u0026gt; 锁的粒度是segment；\n缺点：segment不能扩容，而HashMap会扩容\nJDK1.8后，移除Segment，锁的粒度更加细化，锁只在链表or红黑树节点级别上竞争锁。通过CAS进行插入操作，只有在更新链表or红黑树时才使用synchronized关键字加锁，并且只锁住链表的头节点。 同步HashMap，数组+链表+红黑树实现； 🏷️添加节点过程\n计算key的hash后的下标，如果没有元素 =\u0026gt; 利用CAS添加元素； 冲突 =\u0026gt; 给这个节点上锁使用synchronized。这样其他线程就无法访问该节点以及之后的节点了 🏷️额外扩展（为什么分为CAS\u0026amp;Synchronized呢？）\n无锁机制CAS，能进一步提高并发性能； 因此首次添加节点时，利用CAS很OK，判断\u0026amp;插入 而后续对链表的修改，很难原子化操作orCAS比较交换。因此使用Synchronized，实现互斥，且该锁的粒度很小。 1// 自旋：如果 CAS 失败就重试 2while (true) { 3 currentNode = bucket.get(); 4 5 if (currentNode == null) { 6 // 如果桶位置为空，尝试通过 CAS 插入新节点 7 if (bucket.compareAndSet(null, newNode)) { 8 return null; // 插入成功 9 } 10 } else { 11 // 如果当前位置有节点，进行链表遍历，寻找合适位置插入 12 synchronized (currentNode) { // 在访问链表节点时加锁，防止并发修改 13 Node\u0026lt;K, V\u0026gt; prev = null; 14 while (currentNode != null) { 15 if (currentNode.key.equals(key)) { 16 // 如果找到相同的 key，更新 value 17 currentNode.value = value; 18 return currentNode.value; 19 } 20 prev = currentNode; 21 currentNode = currentNode.next; 22 } 23 // 如果没有找到相同的 key，在链表末尾添加新的节点 24 prev.next = newNode; 25 return null; // 插入成功 26 } 27 } 28} 464 CopyOnwriteArrayList 线程安全的动态数组，通过写时复制机制，保证数据最终一致性和隔离性，并不保证强一致性。\n写操作和读操作(Volatile修饰)分离，读完全ok(可能读到旧版本)；写需要加锁且复制数组，再修改旧数组的引用。 线程安全问题：\n竞争条件 多个线程对共享变量进行累加，可以导致统计不对 死锁 多个线程操作数据时，没有正确的请求资源和释放顺序，相互等待 可见性问题 某个线程对共享变量的修改，其他线程不一定及时可见 =\u0026gt; volatile 强制从内存中修改\u0026amp;读取 原子性问题 逻辑由多个操作步骤组成，其中CPU时间片到期了，中途其他线程修改了共享变量，导致不一致。 线程饥饿 多线程争抢CPU，非公平，有些永远抢不到 不一致视图 多个线程同时修改一个共享对象，导致一部分数据不一致 强制视图一致，就是我第一次拿到的数据，和最终的数据要一致，其他线程别给我改了一部分啊 =\u0026gt; 加synchronized ","permalink":"http://121.40.252.207/posts/jobs/collection/","summary":"\u003ch3 id=\"6319-hashmap-原理\"\u003e6319 HashMap 原理\u003c/h3\u003e\n\u003cp\u003e数据结构：数组 + 链表  （JAVA8之后：数组+链表+红黑树）\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e数据结构\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ejdk1.7：数组+链表，数组每个元素是一个链表的表头，当发生冲突，将新元素添加在头部(头插法)\n\u003cul\u003e\n\u003cli\u003ehash冲突：头插法，❗扩容时可能造成环形链表\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ejdk1.8：\n\u003cul\u003e\n\u003cli\u003e引入红黑树，当链表节点超过8个，那么这个链表会转换为红黑树。查询时间由 O(n) 优化为 O(logn)。当节点小于6个，再转换为链表。\u003c/li\u003e\n\u003cli\u003ehash冲突：尾插法，避免环形链表❗\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e扩容机制\n\u003cul\u003e\n\u003cli\u003ejdk1.7\n\u003cul\u003e\n\u003cli\u003e扩容，元素会重新计算hash值，并分配到新的扩容数组中。⭐比较耗时\u003c/li\u003e\n\u003cli\u003e扩容时，头插法，在多线程情况下，可能造成环形链表\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ejdk1.8\n\u003cul\u003e\n\u003cli\u003e扩容时，利用了元素哈希值和旧数组容量关系，减少了重新计算的哈希次数\u003c/li\u003e\n\u003cli\u003e扩容时，尾插法，避免环形链表\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e使用键的\u003ccode\u003ehashcode()\u003c/code\u003e计算hash值，然后(n-1) \u0026amp; hash确定数组中的位置。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003en-1 =\u0026gt; 10000 - 1 = 01111\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHashMap的初始默认容量为16，负载因子为0.75。当存储的元素达到75%时，进行扩容，扩容为原来的2倍空间\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e扩展知识：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ehashmap的红黑树优化：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eJAVA8开始，为了优化hash冲突时的查找性能。但链表的长度\u003cstrong\u003e超过8\u003c/strong\u003e时，链表会转变为红黑树。红黑树是一种自平衡的二叉搜索树 查找时间 O(n) =\u0026gt; O(logn)。 当元素少于6个，切换为链表\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ehashCode() 和 equals()的重要性：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ehashCode计算hash值，决定键的存储位置。 而hashCode相同=\u0026gt;冲突。 equals()比较的值\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// HashMap Node class\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eEntry\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eV\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003efinal\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 键\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eV\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 值\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003efinal\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehash\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 计算后的哈希值\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eEntry\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eV\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003enext\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 指向下一个元素的指针（形成链表）\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e为什么头插法\u0026amp;多线程\u0026amp;扩容会造成环形链表?\u003c/strong\u003e\u003c/p\u003e","title":"集合面试题笔记"},{"content":"521. Java如何实现跨平台的？ Java编译生成的是字节码文件.class文件，而不是特定于某个操作系统的机器码。\n不同操作系统上都有各自实现的JVM，负责将字节码翻译成特定平台的机器代码并执行。使得JAVA文件可以被不同操作系统上的JVM运行。包装了一层。\n9807. JVM的组成部分 主要组成部分：\n编译好的JAVA字节码（.class文件）准备就绪。\n类加载器子系统：将class文件加载到内存中(运行时的数据区)。 运行时数据区。 执行引擎(命令解释器)：将字节码文件翻译成机器码，并交给CPU执行； 本地方法接口：过程中会调用不同语言提供的接口，比如驱动和..，调用本地方法接口，例如操作系统级别的功能或者高性能库。 522. 编译执行和解释执行 编译执行：先将源代码编译为机器代码，再在CPU上运行。例如：C，C++；\n​\t啊\n优点：编译后运行速度快，并且运行时，不需要再进行翻译。 解释执行：运行时，解释器逐行翻译并执行例如Python。\n跨平台性好， 每个代码都是在每个平台上通过相应平台的解释器运行。 速度慢，每次执行都需要动态翻译。 =\u0026gt; Java采样编译执行和解释执行相结合的方式：\n解释执行：JVM将.JAVA文件=\u0026gt;.class字节码。 有助于程序的跨平台性； 即时编译：将经常执行的代码编译为本地机器码，避免反复解释 523. JVM的内存区域如何划分的❗? JVM运行时的数据区分为：1. 方法区 2. 堆 3. 虚拟机栈 4. 本地方法栈 5. 程序计数器。\n方法区 - 存储类\u0026amp;共享信息\n存储类信息、常量、静态变量 这些信息属于线程共享区域 Java堆 - 与JVM共存亡\n存放所有线程共享的对象实例 和 数组 (垃圾回收主要战地) 虚拟机栈\n每个线程创建一个栈：用来保存局部变量、操作数栈、方法出口信息。 局部变量：基本数据类型；以及对象引用； 栈与线程共存亡 本地方法栈\n为本地方法服务。。。 程序计数器\n保存当前线程执行的字节码指令地址或行号。 总结：Java程序与线程在JVM内存中的流程 程序启动：JVM初始化内存区域，加载类信息到方法区。 线程创建：为线程分配程序计数器、Java虚拟机栈和本地方法栈。 方法调用：线程执行方法时，创建栈帧并压入Java虚拟机栈。 对象创建：对象实例存储在Java堆中，元数据存储在方法区。 垃圾回收：JVM清理不再使用的对象和类信息。 线程结束：线程的栈和程序计数器被销毁。 程序结束：JVM释放所有内存区域并退出。 524. JVM中堆和栈的区别是什么？ 栈：主要用于存储局部变量(基本类型+对象引用)和方法的调用信息(返回地址、参数等)。线程执行时，会创建该线程的栈帧，被压入Java虚拟机栈中。 执行结束，线程栈帧被弹出(销毁)\n堆：主要用于存放对象实例和数组。\n526. Java常量池 Java中的常量池是用于存储运行时的常量或符号的区域\n运行时常量池：在每个类or接口的Class文件中存储编译生成的常量信息，并在类加载时进入JVM方法区； 字符串常量池：用于存储字符串字面量，通过String.intern()方法可以将字符串加入到字符串常量池。 🏷️常量池的作用：\n主要呢，就是用于减少重复对象的创建，节省内存并提高效率。 🏷️字符串常量池：\n直接使用字面量： String s = \u0026quot;Hello\u0026quot;; 会将\u0026quot;\u0026quot;Hello存储在常量池中，如果常量池已存在\u0026quot;Hello\u0026quot;，则不会重复创建。 使用new关键字： 使用String s = new String(\u0026quot;Hello\u0026quot;);不论常量池中是否已存在Hello，都会在堆中创建一个新的String对象。 🏷️常量池的存储内容\n常量池不仅仅存储字符串常量，还包括：\n基本类型的字面量 eg. 整数、浮点数； 类和接口的引用； 方法和字段的符号引用。 527. Java类加载器 动态加载类文件的组件。将.class文件的字节码加载到内存中，并将其转换为Class对象，以供JVM执行。\n🏷️类加载器的作用：\n动态加载类：在运行时根据需要加载类，而不是在编译时加载所有类； 隔离不同的类命名空间：通过不同的类加载器，可以隔离同名类，使得它们不会相互冲突。 🏷️扩展知识\nJDK8一共有三种类加载器\n启动类加载器(Bootstrap ClassLoader), 它属于虚拟机自身的一部分，主要负责加载 \u0026lt;JAVA_HOME\u0026gt;\\lib 目录中或被 -Xbootclasspath指定的路径中被虚拟机识别的文件。 它是所有类加载器的父亲。 扩展类加载器(Extension ClassLoader), 它是Java实现的，独立于虚拟机，主要负责加载 \u0026lt;JAVA_HOME\u0026gt;\\lib\\ext 目录中的或被 java.ext.dirs 系统变量指定路径的类库。 应用程序类加载器(Application ClassLoader), 它是Java实现的，独立于虚拟机。 主要负责加载用户类路径(classPath)上的类库，程序默认的加载器。 532. java中的强引用、软引用、弱引用和虚引用 强引用(默认) 最常见的引用类型。普通对象的对象引用就是强引用。 只要有一个对象有强引用指向它，垃圾回收期永远不会回收该对象。 软引用(常用于缓存) 当内存不足时，会被垃圾回收清理 // 弱引用、虚引用。\n533. Java中常见的垃圾收集器❗❗❗ =\u0026gt; 分为新生代收集器和老年代收集器，包括如下：\n🏷️新生代垃圾收集器：\nSerial收集器 单线程收集器，适合小型应用和单处理环境。 触发 Stop-The-World操作，所有应用线程在GC是暂停。 适合单线程应用和客户端模式。 535. 为什么Java的垃圾收集器将堆分为老年代和新生代？ 主要是为了提高垃圾回收效率，依据对象的生命周期特点来进行优化。\n对象的生命周期特点：\n大多数对象存活时间短：=\u0026gt; 分配到新生代 少部分对象存货时间长：=\u0026gt; 晋升为老年代 按照存活时间分区管理更加高效。\n不同的回收算法：\n新生代的回收：生命周期短 =\u0026gt; 新生代通常采用复制算法； 老年代的回收：存活时间长 =\u0026gt; 标记-整理算法 or 标记-清除算法。 分区后可以减少GC暂停的时间。\n","permalink":"http://121.40.252.207/posts/jobs/jvm/","summary":"\u003ch3 id=\"521-java如何实现跨平台的\"\u003e521. Java如何实现跨平台的？\u003c/h3\u003e\n\u003cp\u003eJava编译生成的是字节码文件.class文件，而不是特定于某个操作系统的机器码。\u003c/p\u003e\n\u003cp\u003e不同操作系统上都有各自实现的JVM，负责将字节码翻译成特定平台的机器代码并执行。使得JAVA文件可以被不同操作系统上的JVM运行。包装了一层。\u003c/p\u003e\n\u003ch3 id=\"9807-jvm的组成部分\"\u003e9807. JVM的组成部分\u003c/h3\u003e\n\u003cp\u003e主要组成部分：\u003c/p\u003e\n\u003cp\u003e编译好的JAVA字节码（.class文件）准备就绪。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e类加载器子系统：将class文件加载到内存中(运行时的数据区)。\u003c/li\u003e\n\u003cli\u003e运行时数据区。\u003c/li\u003e\n\u003cli\u003e执行引擎(命令解释器)：将字节码文件翻译成机器码，并交给CPU执行；\u003c/li\u003e\n\u003cli\u003e本地方法接口：过程中会调用不同语言提供的接口，比如驱动和..，调用本地方法接口，例如操作系统级别的功能或者高性能库。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cimg src=\"http://sthda9dn6.hd-bkt.clouddn.com/FtrSjvLjXEixufKxk9avjPMmQNpg\" alt=\"image-20250314162756632\" style=\"zoom:50%;\" /\u003e\r\n\u003ch3 id=\"522-编译执行和解释执行\"\u003e522. 编译执行和解释执行\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003e编译执行\u003c/strong\u003e\u003c/em\u003e：先将源代码编译为机器代码，再在CPU上运行。例如：C，C++；\u003c/p\u003e\n\u003cp\u003e​\t啊\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e优点：编译后运行速度快，并且运行时，不需要再进行翻译。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003e解释执行\u003c/strong\u003e\u003c/em\u003e：运行时，解释器逐行翻译并执行例如Python。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e跨平台性好， 每个代码都是在每个平台上通过相应平台的解释器运行。\u003c/li\u003e\n\u003cli\u003e速度慢，每次执行都需要动态翻译。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e=\u0026gt; Java采样编译执行和解释执行相结合的方式：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e解释执行：JVM将.JAVA文件=\u0026gt;.class字节码。 有助于程序的跨平台性；\u003c/li\u003e\n\u003cli\u003e即时编译：将经常执行的代码编译为本地机器码，避免反复解释\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"523-jvm的内存区域如何划分的\"\u003e523. JVM的内存区域如何划分的❗?\u003c/h3\u003e\n\u003cp\u003eJVM运行时的数据区分为：1. \u003cstrong\u003e方法区\u003c/strong\u003e 2. \u003cstrong\u003e堆\u003c/strong\u003e 3. \u003cstrong\u003e虚拟机栈\u003c/strong\u003e 4. \u003cstrong\u003e本地方法栈\u003c/strong\u003e 5. 程序计数器。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e方法区\u003c/strong\u003e - 存储类\u0026amp;共享信息\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e存储类信息、常量、静态变量\u003c/li\u003e\n\u003cli\u003e这些信息属于线程共享区域\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eJava\u003cstrong\u003e堆\u003c/strong\u003e - 与JVM共存亡\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e存放所有线程共享的对象实例 和 数组 (垃圾回收主要战地)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e虚拟机\u003cstrong\u003e栈\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e每个线程\u003c/strong\u003e创建一个栈：用来保存\u003cstrong\u003e局部变量\u003c/strong\u003e、\u003cstrong\u003e操作数栈\u003c/strong\u003e、方法出口信息。\u003c/li\u003e\n\u003cli\u003e局部变量：基本数据类型；以及对象引用；\u003c/li\u003e\n\u003cli\u003e栈与线程共存亡\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e本地方法栈\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e为本地方法服务。。。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e程序计数器\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e保存\u003cstrong\u003e当前线程\u003c/strong\u003e执行的字节码指令地址或行号。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250314165936676\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FirLgeEVeLb4N108rU7mpuX1BdPY\"\u003e\u003c/p\u003e\n\u003ch3 id=\"总结java程序与线程在jvm内存中的流程\"\u003e总结：Java程序与线程在JVM内存中的流程\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e程序启动\u003c/strong\u003e：JVM初始化内存区域，加载\u003cstrong\u003e类信息\u003c/strong\u003e到\u003cstrong\u003e方法区\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e线程创建\u003c/strong\u003e：为\u003cstrong\u003e线程\u003c/strong\u003e分配\u003cstrong\u003e程序计数器\u003c/strong\u003e、Java虚拟机\u003cstrong\u003e栈\u003c/strong\u003e和本地方法\u003cstrong\u003e栈\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e方法调用\u003c/strong\u003e：\u003cstrong\u003e线程\u003c/strong\u003e执行方法时，\u003cstrong\u003e创建栈帧并压入Java虚拟机栈\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e对象创建\u003c/strong\u003e：\u003cstrong\u003e对象实例存储在Java堆中\u003c/strong\u003e，元数据存储在方法区。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e垃圾回收\u003c/strong\u003e：JVM清理不再使用的对象和类信息。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e线程结束\u003c/strong\u003e：线程的栈和程序计数器被销毁。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e程序结束\u003c/strong\u003e：JVM释放所有内存区域并退出。\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch3 id=\"524-jvm中堆和栈的区别是什么\"\u003e524. JVM中堆和栈的区别是什么？\u003c/h3\u003e\n\u003cp\u003e栈：主要用于\u003cstrong\u003e存储局部变量(基本类型+对象引用)和方法的调用信息(返回地址、参数等)\u003c/strong\u003e。线程执行时，会创建该线程的栈帧，被压入Java虚拟机栈中。 执行结束，线程栈帧被弹出(销毁)\u003c/p\u003e","title":"JVM面试题笔记"},{"content":"1 如何创建多线程 1） 实现Runnable接口\n实现run()方法 1new Thread(MyRunnable()).start(); 2）继承Thread类\n重写run()方法 3）Callable接口\u0026amp;\u0026amp;FutureTask\n实现Callable call()方法，使用FutureTask包装Callable对象，通过Thread启动 1FutrueTask\u0026lt;ReturnType\u0026gt; task = new FutrueTask\u0026lt;\u0026gt;(MyCallable()); 2Thread(task).start 3 4ResultType res = task.get(); // 这里阻塞 4）使用线程池\n通过ExecutorService提交Runnable或者Callable任务 不同方法对比\n1Runnable vs Callable 2Callable:可以返回结果，可以抛出异常 3 4线程池的优势：避免重复创建和销毁线程，减少这部分重复带来的开销； 5ThreadPool =\u0026gt; (FixedThreadPool, CachedThreadPool, ScheduledThreadPool) 6 7虚拟线程：虚拟线程创建和切换开销更低 8Thread.startVirtualThread() ThreadPool实践\nXXXThreadPool.submit(task\u0026hellip;)\n1FixedThreadPool: 固定池中线程数量 =\u0026gt; 适合1.执行较长任务；2.控制并发度 2 3CachedThreadPool：池中线程数量不固定，根据需要动态创建线程，空的被回收，少了多创建； 4⭐适用于任务执行时间短且任务数量不确定的场景； 5 6ScheduledThreadPool：适用于需要定时执行或周期性执行任务的场景。 1// 定时任务线程池 2ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); 3// For 延迟任务 4scheduledThreadPool.schedule(() -\u0026gt; { 5 // 任务逻辑 6}, 10, TimeUnit.SECONDS); // 延迟10秒执行 7 8// For周期执行任务 9scheduledThreadPool.scheduleAtFixedRate(() -\u0026gt; { 10 // 任务逻辑 11}, 0, 1, TimeUnit.SECONDS); // 每隔1秒执行一次 Thread.sleep(0) \u0026lt;= 主动让出CPU控制权\nthread.join() \u0026lt;= 等待该线程完成\n2 创建线程池 1） Executors工厂类\nExecutors.newFixedThreadPool(10) // 2）ThreadPoolExecutor直接创建线程池\n1new ThreadPoolExecutor(corePoolSize, maximumPoolSize, KeepAliveTime,TimeUnit,new LinkedBlockingQueue\u0026lt;\u0026gt;()) 2 3LinkedBlockingQueue: 当提交的任务多于线程数时，会将多余的暂时挂起 线程池相关参数解释\ncorePoolSize：核心线程数，即线程池中始终保存的线程数量； maximumPoolSize：最大线程数，线程池中允许的最大线程数量； KeepAliveTime：线程空闲时间，非核心线程空闲超过这个时间会被销毁； workQueue：工作队列，存放待执行的任务； threadFactory：线程工厂，用于创建新线程； rejectedExecutionHandler：任务拒绝处理器，当前任务无法执行时的处理策略。 工作队列\nSynchronousQueue：不存储任务，直接提交任务给线程； LinkedBlockingQueue：链表结构的阻塞队列，大小无限； ArrayBlockingQueue：数据结构的阻塞队列； PriorityBlockingQueue：带优先级的无界阻塞队列。/ praɪˈɒrəti / 线程池的拒绝策略\n队列满且无空闲线程的添加任务的情况。\nAbortPolicy：抛异常； CallerRunsPolicy：由提交线程本身执行； DiscardOldestPolicy：删除最早提交的任务； DiscardPolicy：直接丢弃当前任务。 3 线程安全的集合 1concurrentHashMap: 同步HashMap\u0026lt;K-\u0026gt;V\u0026gt; 2数据结构=\u0026gt; 使用数组 + 链表 + 红黑树的结构; 3线程安全=\u0026gt; CAS保证操作的原子性 4 5eg:线程不安全的操作： 6// 非线程安全的操作 7int value = map.get(\u0026#34;key\u0026#34;); // 这里，如果有其他线程对key-\u0026gt;value进行了修改！，这里的value是过期了的 8map.put(\u0026#34;key\u0026#34;, value + 1); 9// ⭐保证原子性 10map.compute(\u0026#34;key\u0026#34;, (k, v) -\u0026gt; v + 1); // 一次完成 11 12// 如果是方法中创建的Map,每个线程专享，不会有线程间安全问题 13// 如果是类中，且多个线程共享同一个Class实例，则可能出现线程安全问题 14Method中创建：安全 15Class-成员变量：多个线程可能共享同一个map实例，需要保证线程安全 16Class-静态变量：所有线程共享同一个 map 实例 ，需要保证线程安全 17 18BlockingQueue： -数组实现 19LinkedBlockingQueue: 线程安全的阻塞队列-链表实现 4 线程同步 多线程情况下，避免共享资源同时访问，引发数据不一致。=\u0026gt; 加锁，限制访问。\nJAVA中，常见的同步方式：\nsynchronized 同步 // 仅限一个线程访问. 由 JVM 负责管理锁的获取和释放. 非公平锁\n生产-消费 模拟\n1Main： 2// 共享队列，用于生产者和消费者之间的数据传递 3Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); // or BlockingQueue 4int maxSize = 5; // 队列的最大容量 5 6// 创建生产者和消费者线程 7Thread producer = new Thread(new Producer(queue, maxSize), \u0026#34;Producer\u0026#34;); 8Thread consumer = new Thread(new Consumer(queue), \u0026#34;Consumer\u0026#34;); 9 10// 启动线程 11producer.start(); 12consumer.start(); 1Producer: 实现Runnable interface 2@Override 3public void run() { 4 int i = 0; 5 while (true) { 6 synchronized (queue) { // 对队列加锁 7 // 如果队列已满，生产者等待 8 while (queue.size() == maxSize) { 9 try { 10 System.out.println(\u0026#34;队列已满，生产者等待...\u0026#34;); 11 queue.wait(); // 释放锁，进入等待状态 12 } catch (InterruptedException e) { 13 e.printStackTrace(); 14 } 15 } 16 17 // 生产数据并添加到队列 18 System.out.println(\u0026#34;生产者生产数据: \u0026#34; + i); 19 queue.add(i++); 20 21 // 通知消费者可以消费了 22 queue.notifyAll(); 23 24 // 模拟生产耗时 25 try { 26 Thread.sleep(500); 27 } catch (InterruptedException e) { 28 e.printStackTrace(); 29 } 30 } 31 } 32} 1Consumer：实现Runnable接口 2@Override 3public void run() { 4 while (true) { 5 synchronized (queue) { // 对队列加锁 6 // 如果队列为空，消费者等待 7 while (queue.isEmpty()) { 8 try { 9 System.out.println(\u0026#34;队列为空，消费者等待...\u0026#34;); 10 queue.wait(); // 释放锁，进入等待状态 11 } catch (InterruptedException e) { 12 e.printStackTrace(); 13 } 14 } 15 16 // 消费数据 17 int value = queue.poll(); 18 System.out.println(\u0026#34;消费者消费数据: \u0026#34; + value); 19 20 // 通知生产者可以生产了 21 queue.notifyAll(); 22 23 // 模拟消费耗时 24 try { 25 Thread.sleep(1000); 26 } catch (InterruptedException e) { 27 e.printStackTrace(); 28 } 29 } 30 } 31} ⭐⭐⭐\nsynchronized（临界区对象） \u0026lt;= 锁住临界区\nwhile(临界区不可用) =\u0026gt; 重试 =\u0026gt; .wait() 当前线程进入等待状态让出CPU，并且释放锁\n处理完成=\u0026gt; .notifyAll() // 通知等待状态的线程\nsynchronized：通过 Object.wait() 和 Object.notify()/notifyAll() 进行线程间通信\nReentrantLock 可重入锁 Re en trant lock. 需要手动加锁和释放锁\n1lock.lock(); 2try { 3 // 临界区代码 4} finally { 5 lock.unlock(); 6} ReentrantLock：使用 Condition 对象更灵活地控制线程等待和唤醒：\n1Condition condition = lock.newCondition(); 2lock.lock(); 3try { 4 condition.await(); // 线程等待 5 condition.signal(); // 唤醒单个等待的线程 6 condition.signalAll(); // 唤醒所有等待的线程 7} finally { 8 lock.unlock(); 9} 案例\n1// 共享队列，用于生产者和消费者之间的数据传递 2Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); 3// 创建 ReentrantLock 和 Condition 4Lock lock = new ReentrantLock(); 5Condition notFull = lock.newCondition(); // 队列未满的条件 6Condition notEmpty = lock.newCondition(); // 队列非空的条件 7 8Producer: 9while(true) { 10 lock.lock() 11 try{ 12 // 13 while(queue.size == maxSize) { 14 System.out.println(\u0026#34;队列已满，生产者等待...\u0026#34;); 15 notFull.await(); // 等待队列未满的条件 16 } 17 18 queue.add(?) 19 notEmpty.signalAll() 20 21 // ... 生产耗时 22 23 }finally{ 24 lock.unlock() 25 } 26} 27 28Consumer: 29while(true) { 30 lock.lock() 31 try { 32 while(queue.size == 0) { 33 sout(\u0026#34;没东西消费\u0026#34;) 34 notEmpty.await() 35 } 36 37 queue.poll() 38 notFull.signalAll() 39 40 // ...消费时长 41 }finally{ 42\tlock.unlock() 43 } 44} ⭐⭐⭐ 关键用法：\nLock lock = new ReentrantLock(); Condition notFull = lock.newCondition(); // 队列未满的条件 Condition notEmpty = lock.newCondition(); // 队列非空的条件\nlock.lock \u0026amp;\u0026amp; lock.unlock\nnotFull.await(), notFull.signal(), notFull.signalAll()\n5 线程安全 保证多线程，乱序执行时候，无论怎么执行，都可以得到预期结果\n=\u0026gt; 通过 线程同步 (悲观锁)\n通过Synchronized 和 ReentrantLock ˈsɪŋkrənaɪzd \u0026amp; riːˈentrənt, lɒk 实现线程同步\n=\u0026gt; 通过原子操作类\nAtomicInteger əˈtɒmɪk 原子， 原子整数\n⭐⭐⭐扩展CAS（乐观锁）：（Compare And Swap，比较并交换）是一种无锁并发编程技术，常用于实现原子操作。它的基本原理是：先比较，再交换，即只有当变量的当前值等于预期值时，才会更新，否则重试。\n1// 当前值, 预期值, 新值 2boolean compareAndSwap(V, E, N) { 3 if (V == E) { // 比较当前值是否等于预期值 4 V = N; // 如果相等，更新为新值 5 return true; // 操作成功 6 } 7 return false; // 操作失败 8} 例子：最佳实践案例=\u0026gt; 线程安全的计数器\n1private AtomicInteger value = new AtomicInteger(0); 2 3// 线程安全的递增方法 4public void increment() { 5 int oldValue; 6 int newValue; 7 do { 8 oldValue = value.get(); // 获取当前值, 先获取修改值 9 newValue = oldValue + 1; // 计算新值 10 } while (!value.compareAndSet(oldValue, newValue)); // CAS 操作 11} 12// CAS compare and swap \u0026lt;=\u0026gt; 访问到修改期间，没有其他线程进行修改的话，就可以执行 13value.compareAndSet(oldValue, newValue) =\u0026gt; oldvalue == value.get() ? value = newValue ：nothing 检查第一次得到的旧值与修改时的值是否一致，判断是否被动过，没动过再改\n=\u0026gt; 线程安全的容器：concurrentHashMap or copyonWriteArrayList❌ 不懂\n=\u0026gt; 局部变量，线程专享\n=\u0026gt; ThreadLocal, 线程本地资源，线程专享\n6 线程生命周期 初始(资源) =\u0026gt; 可运行(CPU队列) =\u0026gt; 运行 =\u0026gt; 终止\n​ 阻塞\u0026amp;等待\n7 线程通信 多线程间的协同工作\n1）**共享变量：**访问共享内存变量来交换信息；\n2）同步机制：\nsynchronized() =\u0026gt; wait =\u0026gt; notify\u0026amp;notifyAll （Object中的方法）\nReentrantLock.lock =\u0026gt; condition.await =\u0026gt; condition.signal\u0026amp;signalAll\nBlockingQueue =\u0026gt; queue.put() 满则阻塞 =\u0026gt; queue.take() 空则阻塞\n1synchronized (lock) { 2 while (conditionNotMet) { 3 lock.wait(); // 释放锁，进入等待状态 4 } 5 // 执行操作 6 lock.notify(); // 唤醒等待的线程 7} 1Lock lock = new ReentrantLock(); 2Condition condition = lock.newCondition(); 3 4lock.lock(); 5try { 6 while (conditionNotMet) { 7 condition.await(); // 等待 8 } 9 // 执行操作 10 condition.signal(); // 唤醒等待的线程 11} finally { 12 lock.unlock(); 13} 1BlockingQueue\u0026lt;String\u0026gt; queue = new LinkedBlockingQueue\u0026lt;\u0026gt;(10); 2 3// 生产者 4new Thread(() -\u0026gt; { 5 try { 6 queue.put(\u0026#34;Data\u0026#34;); 7 } catch (InterruptedException e) { 8 Thread.currentThread().interrupt(); 9 } 10}).start(); 11 12// 消费者 13new Thread(() -\u0026gt; { 14 try { 15 String data = queue.take(); 16 } catch (InterruptedException e) { 17 Thread.currentThread().interrupt(); 18 } 19}).start(); 8 线程池 池化技术，预先创建并管理一组线程，避免线程重复创建和销毁带来的开销\n关键配置：核心线程数，最大线程数，空间存活时间，工作队列，拒绝策略\n=\u0026gt; 提交任务才会创建线程，或者设置preStartAllCoreThreads\n=\u0026gt; 核心线程满了不会创建线程，而是把多余的任务放到工作队列中，等待执行\n=\u0026gt; 核心线程满载且工作队列放不下了，才会新增线程执行提交的任务(\u0026lt;最大线程数)\n=\u0026gt; 工作队列满了+已最大线程数了 =\u0026gt; 拒绝策略?新任务\n=\u0026gt; 线程空闲时间超过指定时间 且有多余的非核心线程 =\u0026gt; 释放非核心线程\n工作队列：\nLinkedBlockingQueue 无界队列，链式\nArrayBlockingQueue 有界队列，数组\nPriorityBlockingQueue 带有优先级的无界阻塞队列\n线程池类型：\n1FixedThreadPool: 固定线程数 2CachedThreadPool：变化，动态新建 3SingleThreadPool：单线程的池子 4ScheduledThreadPool：定时任务的池子 shutdown与shutdownNow的区别\nshutdown：提醒关闭，会把已提交的任务执行完毕\nshutdownNow：强制停止\n9 并发工具类 ConcurrentHashMap：线程安全的HashMap，多线程修改临界区时加锁或者其他方法，=\u0026gt;安全\nAtomicInterger：əˈtɒmɪk 线程安全的整型 compareAndSet CAS方法，原子类型\nSemaphore 信号量：acquire() and release()\nBlockingQueue：阻塞队列-通信容器 queue.put() and queue.take()\nCyclicBarrier：循环屏障 barrier.await\nCountDownlatch：计时器 latch.countDown() latch.await()\n497 ReentrantLock实现 =\u0026gt; 可重入锁，允许同一个线程多次获取同一把锁的锁机制，避免线程因为重复获取锁而导致死锁\n案例：1. 递归调用中的锁保护\n1# 非公平锁 2final boolean nonfairTryAcquire(int acquires) { 3 final Thread current = Thread.currentThread(); 4 int c = getState(); 5 if (c == 0) { // 锁未被占用 6 if (compareAndSetState(0, acquires)) { // CAS 尝试获取锁 7 setExclusiveOwnerThread(current); // 设置当前线程为独占线程 8 return true; 9 } 10 } else if (current == getExclusiveOwnerThread()) { // ⭐⭐⭐锁已被当前线程占用（重入） 11 int nextc = c + acquires; // 增加重入次数 12 if (nextc \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); 13 setState(nextc); // 更新状态 14 return true; 15 } 16 return false; // 获取锁失败 17} 基于AQS实现的一个可重入锁，支持公平和非公平两种方式\n内部依靠一个State变量和两个等待队列：同步队列和等待队列\n利用CAS修改state来争夺锁\n争抢不到锁就入AQS 等待队列进行等待，AQS 等待队列是一个双向队列\n抢到锁但是条件condition不满足则入条件队列(每个condition维护一个)，单向链表\n是否公平锁 =\u0026gt; 线程获取锁 是加入同步队列尾部还是直接利用CAS争夺锁\nReentrantLock 是基于 AQS 实现的可重入独占锁，支持公平锁和非公平锁两种模式。其核心是通过 AQS 的状态管理（state）和等待队列来实现线程的阻塞和唤醒。非公平锁的性能通常优于公平锁，但公平锁可以避免线程饥饿问题。ReentrantLock 提供了比 synchronized 更灵活的锁操作，是 Java 并发编程中的重要工具\n492 Synchronized实现 依赖于JVM的监视器锁+对象头\n当synchronized修饰在方法或者代码块上时，会对特定的对象或者类加锁，确保只有一个线程能运行加锁的代码块；\nsynchronized修饰方法：方法的标志位会增加一个ACC_SYNCHRONIZED标志，检查标志再获取锁，这部分进行同步控制 synchronized修饰代码块：会在代码块前后插入monitorenter和monitorexit字节码指令，上锁+解锁 synchronized是可重入锁\n491 Synchronized和ReentrantLock 496 如何优化Java中锁的使用？ 减少锁的粒度： 减少加锁的范围，减少锁的持续时间 使用更细粒度的锁：提高并发度 hashTable: 通过方法上添加synchronized实现锁的安全，仅一个线程，性能较差 concurrentHashMap： 通过CAS+synchronized实现线程安全，允许多个线程同时读写，性能更高 减少锁的使用 通过无锁编程、CAS操作和原子类来避免锁的使用，减少锁带来的性能损失 通过减少共享资源的使用，避免对临界区的竞争。(本地变量+线程本地变量) 扩展：\n独占锁：写操作多的场景，仅允许一个线程持有锁 读写锁：允许多个线程并发读，但写的时候需要上锁，适合读多写少的场景 乐观锁和悲观锁：悲观锁每次都加锁；乐观锁假设没有冲突-CAS或版本号实现 499 读写锁 允许多个线程同时读操作，但是写操作需要加锁(单个线程)。\n=\u0026gt; 读写+写写操纵是互斥操作；⭐适合读多写少的情况\n可以利用ReadWriteLock和ReentrantReadWriteLock实现\n1# 代码示例 2 3ReentrantReadWriteLock lock = new ReentrantReadWriteLock() 4Lock readLock = lock.readLock() 5lock writeLock = lock.writeLock() 6 7// 1. 判断写锁(读写互斥)2. 判断读锁,第一个和后续 8readLock.lock() 9try{ 10 ... 11} finally { 12 readLock.unlock() 13} 14 15// 1. 有读锁或写锁且写锁不是当前线程持有，则失败 16// 2. 根据公平性策略（公平锁或非公平锁）决定是否需要阻塞 17// 3. CAS 更新状态 18// 4. 设置写锁持有者 \u0026lt;= 设置可重入 19writeLock.lock() // 互斥 写写互斥 20try{ 21 ... 22} finally { 23 writeLock.unlock() 24} 501 Java JMM java内存模型 java memory model\n用于描述线程何时从主内存中读取数据、何时把数据写回主存中\nJMM核心目标\n可见性：确保某个线程的修改，其他线程及时可见。 使用volatile关键字强制线程每次读写都直接从主内存中获取新值 有序性：指线程执行操作的顺序，JMM允许某些指令通过指令重拍提高性能，且保证线程内的操作顺序不会被破坏，通过happens-before关系保证跨线程的有序性。 **原子性：**指操作不可分割，线程不会在执行过程中被中断。 Why JMM：\n操作系统有自己的内存模型，但JAVA是跨平台实现的，因此需要自己设计一套内存模型屏蔽各操作系统之间的差异。JMM描述了多线程环境下，如何在不通过的线程之间共享变量以及变量的操作顺序。\n主内存和工作内存：\n主内存：JAVA堆内存的一部分，所有的实例变量、静态变量和数组元素都存储在主内存中； 工作内存：每个线程都有自己的工作内存，工作内存存储了主内存中的变量副本，线程的所有操作都在工作内存中进行。 线程之间的变量，必须经过主内存进行传递 506 Why ThreadLocal 每个线程自己独享的独立变量副本，避免多个线程间的变量共享和竞争，解决线程安全问题。\n每个线程维护一个ThreadLocalMap 用于存储线程独立的变量副本，ThreadLocalMap以ThreadLocal实例为键，不同线程通过自己ThreadLocal身份获取各自的变量副本。\n避免同一个ThreadLocalMap的竞争\n517 Java中wait、notify和notifyALL 这三个方法都是Object对象定义的方法，用于线程之间的通信，且需要在Synchronized修饰内使用\nwait =\u0026gt; 线程进入等待状态，释放锁 notify =\u0026gt; 唤醒一个在等待的线程 notifyALL =\u0026gt; 唤醒所有等待的线程 518 死锁 及 避免 条件互斥：独享资源 占有且等待：不放手，等别人放弃 不可抢占：文明 循环等待： A=\u0026gt;B=\u0026gt;C=\u0026gt;A 避免：\n按序申请 =\u0026gt; 锁获取的顺序相同，这样就可以在前面卡住 超时等待时间=\u0026gt;释放手中资源和锁 519 volatile关键字 主要的作用还是保证变量的可见性\n可见性：修改了volatile变量的值，该值会被立刻刷新回主内存中，及时让其他线程可见。 6304 如何知晓子线程是否执行完毕？ ThreadObj.join() 会等待对应子线程执行完毕 FutureTask+Callable futrue.get() 拿到线程执行完成的结果 回调机制：完成后，调用回调函数通知主线程，异步了 481 Semaphore 信号量 ˈseməfɔːr\n主要作用就是确保 只有指定数量的线程能够访问资源，限制同时访问特定资源的线程数量\n基本概念\n许可 permits: 可以访问资源的线程数量。\nAcquire：尝试获取许可；\nrelease：释放许可。\n公平：按照请求顺序获取许可，防止线程饥饿\n非公平：可以提高性能。\n常见用法：\n1Semaphore semaphore = new Semaphore(10); // 允许最多10个线程访问 2semaphore.acquire(); // 失败会阻塞不会往下执行了 3try { 4 // 访问共享资源 5} finally { 6 semaphore.release(); 7} 8 9Semaphore semaphore = new Semaphore(5); // 允许最多5个线程同时执行任务 10for (int i = 0; i \u0026lt; 10; i++) { 11 new Thread(() -\u0026gt; { 12 try { 13 semaphore.acquire(); // 阻塞 14 // 执行任务 15 } catch (InterruptedException e) { 16 Thread.currentThread().interrupt(); 17 } finally { 18 semaphore.release(); 19 } 20 }).start(); 21} 482 CyclicBarrier ˈsaɪklɪk ˈbæriə(r) 循环障碍 // 可以重用，当所有线程到达屏障后，刷新\n允许一组线程在执行某个任务相互等待，直到所有线程都达到了Barrier屏障后才能继续执行 // 直接全卡住\n屏障：调用barrier.await() 阻塞，等待所有线程都到达屏障； 线程数量：预指定的，当所有线程到达屏障，所有线程才被唤醒； 重用性：可以被重用。 1# 示例 2static CyclicBarrier cyclicbarrier; 3cyclicbarrier = new CyclicBarrier(parties=10, () -\u0026gt; Sout(\u0026#34;全部准备就绪\u0026#34;)) 4 5for(i ...) 6 new Thread(() -\u0026gt; { 7 Thread.sleep(i * 3000 ms) 8 sout(i+\u0026#34;玩家准备完成\u0026#34;); 9 cyclicbarrier.await() // ⭐等待全部完成 10 sout(i+\u0026#34;玩家进入游戏\u0026#34;) 11 }) 483 CountDownLatch 倒计时门闩锁 - 不可复用\n作用：使某线程等待其他线程执行完一组操作完成。每当其他线程完成一个操作，计数器\u0026ndash;，到达0则等待的ALL线程会被唤醒\n主要功能：\n等待事件完成：await()； 递减计数器：latch.countdown()； 线程同步：当计数器变为0，唤醒线程。 1CountDownLatch latch = new CountDownLatch(3) 2 3for(int i = 1; i \u0026lt;= 3; i++) { // 异步 4 new Thread(() -\u0026gt; { 5 Thread,sleep(i*3000) 6 sout(i+\u0026#34;???\u0026#34;) 7 latch.countDown(); // 这里模拟递减计数器 8 }).start() 9} 10 11sout(\u0026#34;wait all thread finish\u0026#34;) 12latch.await() // 主线程阻塞等待 13sout(\u0026#34;all thread finish\u0026#34;) // 并行计算结果的汇总\n487 如何控制多个线程的执行顺序呢？ synchronized + awit + notify, A =\u0026gt; B =\u0026gt; C 多组锁 ReentrantLock + condition 多组 Thread.join, 逐步等待 CountDownLatch，等待其他的线程countdown semaphore，限制异步为同步顺序 488 Java阻塞队列 ArrayBlockingQueue LinkedBlockingQueue PriorBlockingQueue praɪə(r) 489 原子类 AtomicInterger əˈtɒmɪk ˈɪntɪdʒə(r) AtomicStampedReference stæmpt 1.get 2.compareAndSet 3.getAndIncrement ˈɪŋkrəmənt 提问 CAS Compare and swap\n比较内存中的值 是否与 之前的预期值(之前拿到的旧值) 相等\n相等 =\u0026gt; 将该变量的值设置为新值\n=\u0026gt; 判断从之前的访问到现在的修改，中间变量的值是否变动过，没变过=\u0026gt;可以修改\n优势：\n无锁并发 + CAS是原子性的(线程安全)\n缺点：\nABA问题，如果变量值 从 A=\u0026gt;B=\u0026gt;A,CAS无法检测到这种变化 自旋(重复)开销：导致CPU资源浪费，因为一直比较，直到能够修改为止 单变量限制：仅支持修改单变量 ABA问题：引入版本号或者时间戳，每次更新变量的同时更新版本号，从而依靠版本号判断变量是否被调整过。\n做法：\n1private AtomicStampedReference\u0026lt;Integer\u0026gt; atomicStampedReference = new AtomicStampedReference\u0026lt;\u0026gt;(0, 0); // 初始值:版本号 == 0:0 2 3public void updateValue(int expected, int newValue) { 4 int[] stampHolder = new int[1]; 5 Integer currentValue = atomicStampedReference.get(stampHolder); 6 int currentStamp = stampHolder[0]; 7\t8 // 9 boolean updated = atomicStampedReference.compareAndSet(expected, newValue, currentStamp, currentStamp + 1); 10 if (updated) { 11 System.out.println(\u0026#34;Value updated to \u0026#34; + newValue); 12 } else { 13 System.out.println(\u0026#34;Update failed\u0026#34;); 14 } 15} AtomicStampedReference：\u0026lt;ObjRef =\u0026gt; stampedref\u0026gt;\n尝试更新值和版本号\nboolean updated = atomicStampedReference.compareAndSet(expected, newValue, currentStamp, currentStamp + 1);\n期望的当前值，更新值，期望的版本号，更新的版本号; 当期望的两个值相同才更新\n辅助理解\n1expected, newValue \u0026lt;= ready 2 3// 获取当前引用值和版本号 4int[] stampHolder = new int[1]; 5 6// 因为Java只能返回一个返回值，将多个结果修改数组的形式间接返回 7Integer currentValue = atomicStampedRef.get(stampHolder); 8int currentStamp = stampHolder[0]; // ⭐⭐⭐ 9 10\u0026#34;当前值: \u0026#34; + currentValue 11版本号: \u0026#34; + currentStamp 12 13atomicStampedReference.compareAndSet(expected, newValue, currentStamp, currentStamp + 1); 在CAS基础上，多判断一个版本号，检查变量是否修改过，解决ABA问题\n// ##\n自旋锁 =\u0026gt; 获取锁失败，不会阻塞，而是重复尝试获取锁 ❗非公平:饥饿；性能问题:对同一变量高并发进行CAS\n1public class SpinLock { 2 private final AtomicBoolean lock = new AtomicBoolean(false); 3 4 public void lock() { 5 while (!lock.compareAndSet(false, true)) { 6 // 自旋等待 7 } 8 } 9 10 public void unlock() { 11 lock.set(false); 12 } 13 14 } 针对自旋锁=\u0026gt;CLH\nAQS Abstract Queued Synchronizer 是同步器的基础框架， 起到抽象、封装的作用，将一些排队、入队、加锁、中断方法提供出来，具体加锁时机、入队时机等需要实现类自己控制。\n(volatile申明)state状态，可以通过CAS无锁并发方式竞争锁 AQS支持\n独占模式：只有一个线程可以执行，互斥锁； 共享模式：多个线程可以同时执行，例如信号量； 当一个线程获取锁失败时，AQS将其插入等待队列中，并阻塞线程，直到同步状态可用。\n使用AQS实现一个独占锁\n1 2public class SimpleLock { 3 private static class Sync extends AbstractQueuedSynchronizer { 4 @Override 5 protected boolean tryAcquire(int acquires) { 6 if (compareAndSetState(0, 1)) { 7 setExclusiveOwnerThread(Thread.currentThread()); 8 return true; 9 } 10 return false; 11 } 12 13 @Override 14 protected boolean tryRelease(int releases) { 15 if (getState() == 0) throw new IllegalMonitorStateException(); 16 setExclusiveOwnerThread(null); 17 setState(0); 18 return true; 19 } 20 21 @Override 22 protected boolean isHeldExclusively() { 23 return getState() == 1; 24 } 25 26 final ConditionObject newCondition() { 27 return new ConditionObject(); 28 } 29 } 30 31 private final Sync sync = new Sync(); 32 33 public void lock() { 34 sync.acquire(1); 35 } 36 37 public void unlock() { 38 sync.release(1); 39 } 40 41 public boolean isLocked() { 42 return sync.isHeldExclusively(); 43 } 44 45 public Condition newCondition() { 46 return sync.newCondition(); 47 } 48} 1# 基于AQS的独占锁 2tryAcquire: =\u0026gt; CAS(原子，比较且设置)检查是否锁可以使用 =\u0026gt; 可以则设置当前线程为独占模式 true=\u0026gt;else false 3 4tryRelease: =\u0026gt; getState =\u0026gt; 如果不为1则异常 =\u0026gt; else 关闭独占模式并释放锁(state设置为0) 5 6private final Sync sync = new Sync() // 作为锁对象 7lock: sync.acquire(1) 8unlock: sync.release(1) AQS和CAS两者可以经常一起使用，例如在ReentrantLock中，CAS用于实现锁的获取和释放操作，而AQS则管理锁的状态和等待队列。\n","permalink":"http://121.40.252.207/posts/jobs/juc/","summary":"\u003ch3 id=\"1-如何创建多线程\"\u003e1 如何创建多线程\u003c/h3\u003e\n\u003cp\u003e1） 实现\u003cstrong\u003eRunnable\u003c/strong\u003e接口\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e实现run()方法\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eThread\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMyRunnable\u003c/span\u003e\u003cspan class=\"p\"\u003e()).\u003c/span\u003e\u003cspan class=\"na\"\u003estart\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e2）继承Thread类\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e重写run()方法\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e3）Callable接口\u0026amp;\u0026amp;FutureTask\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e实现Callable call()方法，使用FutureTask包装Callable对象，通过Thread启动\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eFutrueTask\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eReturnType\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003etask\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eFutrueTask\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u0026gt;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMyCallable\u003c/span\u003e\u003cspan class=\"p\"\u003e());\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eThread\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etask\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"na\"\u003estart\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eResultType\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eres\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003etask\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 这里阻塞\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e4）使用线程池\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e通过ExecutorService提交Runnable或者Callable任务\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e不同方法对比\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eRunnable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003evs\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCallable\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"nl\"\u003eCallable\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"n\"\u003e可以返回结果\u003c/span\u003e\u003cspan class=\"err\"\u003e，\u003c/span\u003e\u003cspan class=\"n\"\u003e可以抛出异常\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e线程池的优势\u003c/span\u003e\u003cspan class=\"err\"\u003e：\u003c/span\u003e\u003cspan class=\"n\"\u003e避免重复创建和销毁线程\u003c/span\u003e\u003cspan class=\"err\"\u003e，\u003c/span\u003e\u003cspan class=\"n\"\u003e减少这部分重复带来的开销\u003c/span\u003e\u003cspan class=\"err\"\u003e；\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eThreadPool\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eFixedThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCachedThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eScheduledThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e虚拟线程\u003c/span\u003e\u003cspan class=\"err\"\u003e：\u003c/span\u003e\u003cspan class=\"n\"\u003e虚拟线程创建和切换开销更低\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eThread\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003estartVirtualThread\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eThreadPool实践\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eXXXThreadPool.submit(task\u0026hellip;)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nl\"\u003eFixedThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e固定池中线程数量\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e适合1\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003e执行较长任务\u003c/span\u003e\u003cspan class=\"err\"\u003e；\u003c/span\u003e\u003cspan class=\"n\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003e控制并发度\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eCachedThreadPool\u003c/span\u003e\u003cspan class=\"err\"\u003e：\u003c/span\u003e\u003cspan class=\"n\"\u003e池中线程数量不固定\u003c/span\u003e\u003cspan class=\"err\"\u003e，\u003c/span\u003e\u003cspan class=\"n\"\u003e根据需要动态创建线程\u003c/span\u003e\u003cspan class=\"err\"\u003e，\u003c/span\u003e\u003cspan class=\"n\"\u003e空的被回收\u003c/span\u003e\u003cspan class=\"err\"\u003e，\u003c/span\u003e\u003cspan class=\"n\"\u003e少了多创建\u003c/span\u003e\u003cspan class=\"err\"\u003e；\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e⭐\u003c/span\u003e\u003cspan class=\"n\"\u003e适用于任务执行时间短且任务数量不确定的场景\u003c/span\u003e\u003cspan class=\"err\"\u003e；\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eScheduledThreadPool\u003c/span\u003e\u003cspan class=\"err\"\u003e：\u003c/span\u003e\u003cspan class=\"n\"\u003e适用于需要定时执行或周期性执行任务的场景\u003c/span\u003e\u003cspan class=\"err\"\u003e。\u003c/span\u003e\u003cspan class=\"w\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 定时任务线程池\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eScheduledExecutorService\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003escheduledThreadPool\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eExecutors\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003enewScheduledThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"c1\"\u003e// For 延迟任务\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003escheduledThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eschedule\u003c/span\u003e\u003cspan class=\"p\"\u003e(()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 任务逻辑\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTimeUnit\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eSECONDS\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 延迟10秒执行\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"c1\"\u003e// For周期执行任务\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 9\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003escheduledThreadPool\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003escheduleAtFixedRate\u003c/span\u003e\u003cspan class=\"p\"\u003e(()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e10\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 任务逻辑\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e11\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTimeUnit\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eSECONDS\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 每隔1秒执行一次\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThread.sleep(0) \u0026lt;= 主动让出CPU控制权\u003c/p\u003e","title":"并发面试题笔记"},{"content":"617 MySQL 数据排序 实现？ Order By 命中索引(包括索引字段)，使用索引排序(有序)，效率最高效 否则使用文件排序，文件少=\u0026gt; 内存排序 sort_buffer 文件大=\u0026gt;外部排序，归并排序 内部排序细节：\n双路排序(待排序的列数据太大了)：使用row_id(回查表) + sort_field\n​\t排好序后，使用row_id将完整的记录取出来\n单路排序(待排序数据大小能接受)\n​\t直接拍，不会查表，直接把拍好的结果返回\n外部排序：\n拆分小的，外部多路归并排序，小=\u0026gt;大\n外部归并排序 =\u0026gt; 先分段排序，每一段调入内存执行快排\n​ =\u0026gt; 归并阶段，因为每子段都是有序的 =\u0026gt; 多路归并排序\n589 一条SQL的执行过程 先通过连接器校验权限 利用分析器进行SQL语句词法分析和语法分析，构建解析树 利用优化器选择合适的索引和表连接顺序，最终选择一条最佳的执行计划 利用执行器，调用引擎层查询数据，返回结果集 具体：Select * from user where id = 1;\nSQL =\u0026gt; Server层连接器，权限校验，账号是否有资格获取。无=\u0026gt; Access denied for user。 连接成功后，空闲一段时间会断开\n分析器(查询解析) =\u0026gt;\n语法分析：SQL : Select类型✔️ user表✔️ id列 ✔️拆分成词，再组装为解析树。 语义分析：语法是否有误 =\u0026gt; you have an error in your SQL syntax (字段、表|存在？) 分析解析树语法正确性 优化器(查询优化)=\u0026gt;\n优化SQL，比如：选择哪个索引、调整多个表的连接顺序 执行器（查询执行）\n校验用户对表的权限，根据存储引擎查询数据，遍历 =\u0026gt; 返回结果集\n590 MySQL 存储引擎 InnoDB\n提供事务、行级锁和外键\n提供高并发性能\nB+树索引\nMVCC\n591 MySQL的索引类型有哪些 数据结构角度：\nB+树索引： 通过树型结构 =\u0026gt; 适合范围查询between和精确查=。 叶子节点双向链表连接 比B树具备更少的IO次数 InnoDB+树索引结构上看\n聚簇索引(主键构建)： 非叶子节点存储索引值 叶子节点存储完整的数据行数据，可以直接访问完整数据 每个表只能有一个聚簇索引 非聚簇索引 (二级索引) 非叶子节点存储索引值 叶子节点存储主键和对应索引列，查询非对应索引列，则需要回表(根据主键)，增加额外的IO（SELELCT * 慎重） 索引:\n主键索引\n唯一索引\n普通索引\n单列索引 \u0026amp; 联合索引\n1主键： 2PRIMARY Key(id) 3唯一： 4Create unique index xxx on user(username); 5联合： 6Create INdex xxx on user(username, email); MySQL索引的最左前缀匹配原则？ 针对联合索引\n联合索引在B+树种的排列方式遵循“从左到右”的顺序 e.g. (first_name, last_name, age) 会按照 这个顺序进行索引\n1 (Alice, Black, 35) 2 | 3 ------------------------------------------------------------- 4 | | | | 5(Alice, Brown, 25) (Alice, Smith, 30) (Bob, Smith, 20) (Bob, White, 19) 查询时候WHERE 条件顺序最好和索引一致，否则跳过最左侧会导致无法利用该索引\n=\u0026gt; 要保证索引命中，建议索引顺序一致\n不能跳过第一个索引\n可以部分匹配但第一个一定要在\nindex: (a, b, c)\n1where a=1 ✔️ 2where a=1 and b=1 ✔️ 3where a=1 and b=1 and c=1✔️ 4 5where b=1 and a=1 ❌❌❌ 595 MySQL索引覆盖 指二级索引包含了查询所需的所有字段 - 一级索引(Primary key，唯一) ˈpraɪməri - 二级索引(其他索引)\n1# INDEX idx_name_hiredate (last_name, first_name, hire_date) 2 3SELECT ... 4WHERE last_name = ? AND first_name = ? 5 6则不需要回表查询，因为这个SQL会根据联合索引进行查询，并且查询的条件列包含所需的数据 596 MySQL索引下推 应用在联合索引上，减少回表查询。MySQL自动应用的优化技术\n主要是将条件索引列的过滤操作下推到存储引擎层，减少不必要的数据传输\n通过二级索引查到主键id后回表再进行where条件过滤\n=\u0026gt; 二级索引查到数据后直接where条件过滤一遍，再进行回表查询，减少回表的次数\n1# example 联合索引：index_age_grade 2(1, \u0026#39;Alice\u0026#39;, 18, 90), 3(2, \u0026#39;Bob\u0026#39;, 19, 85), 4(3, \u0026#39;Charlie\u0026#39;, 18, 95), 5(4, \u0026#39;David\u0026#39;, 20, 80); 6=\u0026gt; SELECT ... WHERE age = 18 and grade \u0026gt; 90 7# 没有索引下推： 81. 先根据age查找到所有结果 92. 返回所有结果数据到服务器层 103. 服务器层过滤grade\u0026gt;90的数据 11 12# 索引下推 131. 先根据age查找到所有结果 142. 存储引擎层直接过滤grade\u0026gt;90的数据 153. 返回数据给服务器层 597 建立索引注意事项 不能盲目建立，因为维护需要代价 表的修改频率远大于查询频率 =\u0026gt; 维护代价大 598 排查索引效果？ 在SQL语句前，使用EXPLAIN关键字，查看SQL语句的执行信息\n联合索引 =\u0026gt; 符合最左前缀顺序 索引中使用运算或者函数，like进行全盘扫描，对值进行了处理，则会使索引失效 破坏最左匹配 in字段 order by 为使用索引 600 MySQL的B+树查询数据的全过程 查询从跟节点出发，比较数据键值与节点中存储的索引键值，确定数据落在哪个区间，从而确定往下哪个分支走，从上到下定位到叶子节点 叶子节点存储着数据行记录，但一页的大小有16kb，存储的数据行不只一条 叶子节点中的数据行以组的形式划分，利用页目录结构，通过二分查找定位到对应的组 定位到组后，利用链表遍历=\u0026gt;row 601 为什么使用B+树作为索引结构 高效的查询性能 自平衡，根到叶子路径长度相同 O(logn) 树高长的不会过快，使得查询磁盘的IO次数减少 非叶子节点只存放索引值和页面指针 每一页中能够容纳更多的记录，减少查询的IO次数 范围查询能力强 叶子节点通过链表连接，定位到叶子节点，根据范围查询只需要顺序扫描链表 B树\n每个节点都存储了完整的数据 B树叶子节点没有连接指针 602 MySQL怎么实现事务 ❌❌❌ 通过锁、Redo Log、Undo Log、 MVCC实现事务\n利用锁(行锁、间隙锁等)机制，控制数据的并发修改，满足事务的隔离性\nRedo Log(重做日志)，它记录事务对数据库的修改，当MySQL宕机了，通过重放redo log可以恢复数据，满足事务的持久性\nUndo Log(回滚日志)，记录事务的反向操作，保持数据的历史版本，用于事务的回滚，使事务执行失败后可以恢复到之前的样子。实现原子性和隔离性\nMVCC 多版本并发控制，满足非锁读的需求，提供读写并发，实现了读已提交和可重复读两种隔离级别\n读已提交：每次查询生成新的 ReadView，可能导致多次查询结果不一致 可重复读：事务启动时生成 ReadView，保证整个事务中查询结果一致 事务工作流程：\nRedo Log(重做日志)：\n=\u0026gt; 保证事务的持久性，即使宕机了也能恢复提交的数据\n版本链示意\n​\n609 Mysql有哪些锁 粒度分类：\n全局锁：整个数据库加锁，只读\n行级锁：细粒度\n对特定的行加锁，允许其他事务并发访问不同的行，适用于高并发的场景 表级锁 粗粒度\n对整个表进行加锁，其他事务无法对该表进行操作 属性分类：\n共享锁 S锁 Shared lock\n允许多个事务并发读同一资源，但是不允许修改，只有释放共享锁后，其他事务才能获取排他锁 排他锁 Exclusive lock X锁\n只允许一个事务读写资源，互斥，独享 1-- 添加共享锁 2SELECT ... LOCK IN SHARE MODE; 3-- 共享锁 4SELECT ... FOR SHARE; 5-- 排他锁 6SELECT ... FOR UPDATE; 记录锁：锁定特定的行记录\n间隙锁\n针对索引中两个记录之间的间隙加锁，防止其他事务在这个间隙中插入新的数据，避免幻读。锁定行与行之间的空间 阻止新的记录的插入 临键锁\n锁定具体行和其前面的间隙，确保范围内不会幻读 603 MySQL长时间事务可能造成什么问题？ 问题：\n长时间事务 =\u0026gt; 长时间的锁竞争+阻塞资源 其他事务也需要对应的锁，但是这个锁长时间拿不到，阻塞 部分业务的阻塞会影响到其他服务，导致系统出现严重的服务崩盘 死锁风险 多个事务相互等待对方释放锁，导致系统无法继续执行 回滚导致时间的浪费 执行了很长，但是快结束出现异常 =\u0026gt; 事务回滚需要很长的时间 长时间事务如何解决\n拆分成一小份一小份的短事务\n时间？ 创造索引条件，得到表的主键最大值和最小值，切分成一小份一小份的区间在执行\n删除大量的数据 =\u0026gt; 在新的表中插入相对小的数据\n604 MVCC [数据版本控制隐藏字段和指针、事务视图ReadView]\nMulti-Version Concurrency Control 多版本并发控制 =\u0026gt; 允许事务同时读写数据库，而无需相互等待\n提高并发性能 \u0026amp; 避免读写冲突 \u0026amp; 减少锁竞争 MVCC中，为每个事务创建一个数据快照，当数据被修改时，MySQL不会立即覆盖原有数据，而是生成新版本的记录。每个记录都保留着相应的版本号\n读写冲突：传统读写或互斥。解决方法：多版本方式，读旧版本数据，写在新版本上，从而避免读写冲突。 锁竞争：传统方式需要竞争锁，解决方式：通过版本控制替代锁。 事务隔离级别实现：传统机制：锁。解决方式：版本控制。 MVCC为每条数据维护多个版本\n每个版本包括：\n版本号：标识创建版本的事务ID 时间戳：创建时间 数据内容 读操作：\n根据事务的隔离级别和当前时间戳，选择合适的数据版本。\n在读已提交下隔离级别下：读操作会读取已提交的最新版本 在可重复读隔离级别下：读操作会读取事务开始时的数据版本 写操作:\n=\u0026gt; 创建新的数据新版本，而不是修改旧版本数据 旧版本数据会被保留，直到没有任何事务引用 \u0026lt;= 垃圾回收 MVCC优势：\n高并发； 灵活的隔离级别； 减少锁竞争； 一致性视图 隐藏字段：\n每行记录除了自己定义的字段外，还有一些重要的隐藏字段\ndb_row_id： 没有定义Primary Key，默认用这个为Index db_trx_id：最近对这个记录修改的事务ID db_roll_ptr: 回滚指针，指向这个记录的上一个版本，指向Undo Log中的上一个快照版本的地址 多版本之间串联起来形成一条版本链。 不同事务可以无锁的读取不同版本的数据(普通读)。普通读和写不会阻塞\n写操作可以继续写，就是新的数据版本不会立即对其他事务可见，只有事务提交后，新版本的记录才会可见\nMySQL InnoDB通过Undo Log 操作 和 ReadView实现\nUndo Log 记录数据修改之前的状态的日志，作用如下：\n事务回滚：撤销未提交的事务修改 实现MVCC：提供历史版本数据，支持一致性读 =\u0026gt; 当事务修改数据时，InnoDB会将数据的旧版本写入Undo Log中\n=\u0026gt; 当Undo Log没被任务事务引用时，会被垃圾回收\nReadView 读视图\n事务某时刻创建的数据库快照，用于确定哪些数据版本对事务可见 =\u0026gt; 实现事务隔离性\n核心字段\nm_ids: 当前活动事务ID列表 min_trx_id: m_ids中最小事务的ID max_trx_id creator_trx_id: 创建该ReadView事务的ID 可见性规则\n对于每条数据的版本，ReadView会根据一下规则判断是否可见\n当数据版本的事务ID \u0026lt; min_trx_id\n=\u0026gt; 数据版本以及提交(过去的事务)，可见\n当数据版本的事务ID \u0026gt;= max_trx_id\n​\t=\u0026gt; 说明数据版本是未来事务创建的，不可见\n​\t3. 数据版本的事务ID 在 m_ids中 ⭐⭐⭐\n​\t=\u0026gt; 说明他是由未提交的事务创建的， 不可见, 否则可见\n如果当前数据版本的 trx id 大小在 min trx id 和 max trx id 之间，此时 trx id 若在 m ids 中，说明修改这条数据的事务此时还未提交，所以不可见，若不在m ids 中，表明事务已经提交，可见。\r​\t4. 数据版本的事务ID == creator_trx_id\n​\t=\u0026gt; 自己创建的，可重入，当然可见了\n​\t可见性取决于ReadView的快照机制 =\u0026gt; ReadView创建时间 决定了事务能看到哪些已提交的数据。\nMVCC\n解决脏读：事务只能读取已提交的数据记录；可见性控制 =\u0026gt; 去UndoLog中找历史记录\n解决不可重复读：ReadView\n❗不能解决幻读：比当前事务Id小的事务提交了，那么新出现的记录可以被看到，特别是范围查询的时候\n使用场景：\nMVCC：读多写少的场景 =\u0026gt; 商品库存查询？ 读事务不会被写事务阻塞 对于银行金额变更场景 =\u0026gt; 锁 事务隔离级别 事务的ACID特性：Atomicity, Consistency, Isolation, Durability\n数据一致性问题：\n脏读：事务A读取了事务B尚未提交的数据，此时事务B回滚，那么A读的数据是脏数据(无效) 幻读：同一事务中，多次执行的相同查询，得到的结果集不一致。 其他事务插入新的数据并提交 不可重复读：同一事务，多次读取的同一数据，结果不一致 因为事务执行期间，其他事务对结果进行了修改 事务隔离级别：避免上述数据不一致问题\n读未提交：允许事务读取其他事务未提交的数据。 会引起：脏读、幻读、不可重复读； 读已提交：事务只能读取其他事务已提交的数据。避免了：在脏读；(默认) 可重复读：加锁(行锁)，确保事务多次读取同一数据的一致性。避免了：脏读、不可重复读；可能：幻读 串行化：事务完全串行执行：锁定整个表或者范围来实现。避免：脏读、幻读、不可重复读 MySQL主从复制 核心是基于二进制日志(BinLog File)进行数据同步\n主库(Master)记录变更 任何对数据库进行变更的操作都会被记录到BinLog中。Update Delete Insert 从库Slave获取Binlog 从库通过IO线程连接主库，读取Binlog，并存入本地中继日志中(Relay log) 从库Slave 回放Binlog 从库SQL线程解析Relay Log，执行相同的SQL语句，进而保持与主库相同的数据 一主多从\n一个主库，多个从库，每个从库独立同步主库数据 主从复制的优势\n数据冗余 =\u0026gt; 更安全 读写分离 =\u0026gt; 主库写，从库读，提高性能 高可用性 =\u0026gt; 主库故障 切换从库，提高系统可靠性 610 MySQL乐观锁\u0026amp;悲观锁 乐观锁：比如CAS机制，不加锁实现并发。并发性能高。 比较版本号和时间戳实现\n悲观锁：每次操作都加锁，互斥操作，数据一致性要求高的场景。并发性能低\n​\n616 MySQL SQL调优 通过分析慢SQL，利用explain分析查询语句的执行计划，识别性能瓶颈，优化查询语句\n合理设计索引，利用联合索引进行覆盖索引的优化\n覆盖索引：让常用的字段都在索引中，这样就可以减少回表查询的开销 索引下层：过滤掉不符合查询条件的数据，减少回表操作 自动的 避免 SELECT *，只查询必要的字段\n避免在SQLWHRER中执行函数计算，使得索引失效\n避免%LIKE，导致全屏扫描\n注意联合索引需满足最左匹配原则\n不要对无索引字段进行排序\n通过业务的优化，进行缓存，减少对数据库的访问\n减少多表查询的情况\nJOIN操作，数据量大时，容易导致查询速度慢，影响数据库性能 避免频繁使用JOIN多张大表，而是分步查询或缓存 必要时使用冗余存储，减少JOIN。 一次查大量数据的优化方式\n分页查询\n使用LIMIT和OFFSET，每次只查一部分数据\n1SELECT ... FROM ... WHERE ... LIMIT ??? OFFSET ... 分批次查询：\n```sql\rSELECT ... FROM ... WHERE id \u0026gt; 1000 ORDER BY id LIMIT 100;\r```\r回答：索引相关：\n查询的时候，满足最左前缀匹配原则 最小查询，只查询所需要的必要信息。减少回表情况 利用好索引，加速检索。 避免全盘扫描的情况 避免 Like % 全盘匹配 避免WHere中对字段进行函数操作，使得索引失效 不要对无关字段进行排序 利用好缓存，直接减少数据库的访问 619 MySQL实现读写分离 读操作次数远大于写操作\n将读操作分摊到从数据库中。主数据库负责写操作。然后通过主从复制，同步数据。\n数据一致性要求高的场景\n⭐1. 关键事务必须强制从主库中读取数据\n支付订单状态 扣减库存等等 2.半同步控制\n当事务提交后，至少有一个从库确认接收到数据，才认为数据写入成功\n3.业务层解决，将数据写入Redis中，优先从缓存中读取数据\n读写分离 =\u0026gt; 将压力分摊到子库中，提高性能\n同步 =\u0026gt; 数据一致性 =\u0026gt; 全同步， 半同步 620 MySQL主从复制机制 应用场景数据备份or主从数据同步\n同步复制：将binlog file复制到所有从库，等所有从库响应了，主库才响应客户端 （性能差，数据一致性高） 半同步复制：主库等待至少一个从库确认收到数据（性能折中，数据一致性较高） 异步复制：主库不用等待从库确认（性能高，数据一致性差） 如何实现同步过程\n提交事务请求 =\u0026gt; 主库 =\u0026gt; 同时写入binlog file，更新数据并相应客户端，并推送binlog更新事件 binlog file 被主库的dump线程发送给从库 从库IO线程接收binlog，并写入Relay log(中继日志)中，缓冲 从库SQL线程从Relay log重写事件到从库数据库中。 622 数据库进行分库分表以及带有的问题 分库分表策略\n**水平分表：**将一张表的数据，放在两个表中。例如根据ID **垂直分表：**将一张表不同列拆分到多个表中，⭐减少每张表的字段数提高查询效率。例如，用户表可以拆分为基本信息和详细信息表。 **水平分库：**将相同表结构复制一份到另一张表中，减少单一数据库的读写压力。 **垂直分库：**根据业务功能，将表分到不同数据库中。例如将用户数据、商品数据分别存储到不同的数据库中。 为什么需要分库分表？\n随着用户越来越多，导致表数据量大(数据堆积)，读写请求多(并发量高)。\n=\u0026gt;导致 性能瓶颈，单一数据库性能有限。\n分表：100w中找，和1w中找还是不一样的。可以先hash计算到底在哪个数据库，再具体执行。 分库：可以按业务or功能不同，将请求分配到多态服务器上，降低单一服务器压力。 624 数据库分库分表可能引发的问题 单机 =\u0026gt; 分布式\n事务问题：会出现事务的数据不一致问题，需要使用分布式事务解决。 JOIN连表问题： 跨服务器无法JOIN表，业务中实现关联，或者使用冗余字段。 **全局唯一ID问题：**单机，使用自增长的ID即可，分布式必须使用全局唯一ID发号器生成唯一ID。 **排序问题：**上推到业务中实现。 **count问题：**业务代码中累加。 625 MySQL获取数据，从磁盘中写的吗？ MySQL中，并不总是从磁盘中读取。利用缓存机制，提高读取性能。\nmysql8.0中有查询缓存，只有sql相同时才会命中，命中率低，在8.0后移除了\nbuffer pool(old sublist, young sublist), 里面存储了一个一个的数据页，mysql会从buffer pool中找，找到就返回。\n=\u0026gt; 一块内存空间，访问某个数据(磁盘中)时，会将包括该数据的页加载到内存中。页大小16KB，局部性原理，以后对该页的修改和访问都在buffer pool中进行。\n=\u0026gt; 内存淘汰策略：变体的LRU(least recently used最近最少使用)。 buffer pool将数据分为年轻代和老年代(默认5:3)，当数据从磁盘调到内存中时，因为空间时间局部性，新的数据会放在老年队列中，当1s中没有再次访问时才转到年轻队列中。\n=\u0026gt; 如果直接放在年轻代中，可能会把热点数据淘汰掉\n=\u0026gt; 1s，时间窗口，渡过这个时间还被访问认为是热点数据。\n629 为什么不推荐多表JOIN 数据量大的时候，多表JOIN，数据库需要对联接的每个表进行扫描，会消耗大量的CPU和内存资源。 性能比较低\n数据库往往是我们系统的弱点，很多情况性能瓶颈都在数据库，因此我们需要尽可能避免把压力放在数据库上。\nJOIN连接表的时候，需要关注被驱动表的查询是否能够命中索引，不然会导致全表扫描。\n尽可能让小表做驱动表，因为驱动表需要全表扫描，而被驱动表是通过索引查询的。且被驱动表最好能够命中索引。\n例子\n1SELECT * FROM ... a1 join ... a2 on (a1.a == a2.a) 小表有A行，大表有B行。每次扫描A，每行都需要去大表里面查，时间LogB(命中索引)，假设存在回表，那么为2*LogB的查询时间。有A行，那么查B表的时间为=\u0026gt;A*2*LogB；查A表的时间为A,total =\u0026gt; A+A*2*LogB。\nJOIN SQL查询的流程\n扫描A表(小表) 读取A表的所有行，及A次操作 查询B表 A行 * LogB(命中索引的查询时间) * 2(回表时间) =\u0026gt; A + A*2*LogB 630 MySQL中解决深度分页问题 深度分页是指数据量很大的时候，按照分页访问后面的数据，例如limit 99999, 10，这回使得数据库扫描前面的99999条数据，才能得到最终的10条数据。\n1LIMIT num1, num2; -- 偏移量， 返回行数。 会扫描起点到num1整段记录 2LIMIT num1; -- 返回行数 解决方法：\n子查询： 子查询 + 记录上一次查询的 Last ID 1SELECT id, name 2FROM tabel 3WHERE name = \u0026#39;A\u0026#39; 4and id \u0026gt;= (SELECT id FROM tabel WHERE name = \u0026#39;A\u0026#39; order by id limit 99999, 1) 5order by id limit 10; 6 7-- 传递上一次查询的最后一个ID 8SELECT * FROM users WHERE id \u0026gt; last_id ORDER BY id LIMIT 10; 1418 数据库视图 数据库视图是虚拟表，作用：简化复杂查询、安全性、数据抽象、可重用性\n1CREATE VIEW employee_salaries AS 2SELECT 3 e.employee_id, 4 CONCAT(e.first_name, \u0026#39; \u0026#39;, e.last_name) AS full_name, 5 d.department_name, 6 e.salary 7FROM 8 employees e 9JOIN 10 departments d ON e.department_id = d.department_id; 11 12-- CREATE VIEW view__ AS 1479 什么情况下，不推荐为数据库建立索引 有以下几种情况：\n原因 数据量小的表 建议索引并不会显著提高查询性能，反而增加复杂性 频繁更新的表 每个插入删除操作，都需要更新索引，导致过高的维护索引的开销 高度重复的列 例如，性别，索引效果不明显，反而增加存储空间 长文本字段 这些类型的列包含大量数据，添加索引，导致无法使用内存排序，需要利用磁盘，导致大量IO 3179 数据库不停服迁移 通过数据双写实现\n**旧数据同步：**采用主从同步方式，将新库作为旧库的从库，实现历史数据的迁移； **新数据同步：**采用数据双写方式，将新数据同时写入新旧两个库中。 **一致性检查：**定时任务，抽检两个库的数据一致性； 灰度切流： 逐渐将用户的数据请求，迁移到新库中。 4040 MySQL数据库的性能优化方法 SQL 和 库表两部分设计，优化MySQL性能问题。\nSQL优化:\n避免 SELECT * ，只查询必要字段； 避免在SQL中进行函数等计算操作，导致索引失效； 避免使用 %Like，导致全表扫描； 注意联合索引需要满足最左匹配原则； 不要对无索引字段进行排序。 库表设计\n合理表结构：合理的数据类型； 合理冗余字段：冗余设计，减少关联查询； 索引优化：根据查询频率和条件，创建合适的索引； 分库分表：提高读写性能。 1219 数据库三大范式 第一范式：原子性，字段只包含单一数据项；\n第二范式：非主键必须依赖于整个主键；\n第三范式：非主键字段只依赖于主键，不应该相互依赖。\n数据库中存储金额数据使用的数据类型：bigint and decimal\nsql:java\nbigint: long;\ndecimal:BigDecimal\n1482 MySQL中EXISTS和IN的区别是什么 EXISTS ɪɡˈzɪsts 判断子查询是否返回任何行，通常用于检查某个条件是否满足; 满足条件后则返回，大数据量时性能好 IN 检查某个值是否在指定集合中； EXISTS 外=\u0026gt;内判断，满足即停止。最好子表有索引。\nIN =\u0026gt; 先内， 再外匹配内。\n11175 SQL中SELECT、FROM\u0026hellip; 的执行顺序是什么？ FROM WHERE： 淘汰的单位是行 GROUP BY HAVING：聚合数据，淘汰的单位是整组 SELECT ORDER BY LIMIT B+树、聚簇索引、主键索引、二级索引 B+树：数据结构\n聚簇索引（主键索引）：叶子节点存储了整行数据，一张表只能有一张(Primary Key)。 使用B+树实现\n二级索引：叶子和非叶子都只存储了Index比较需要的数据。使用B+树实现。因此，索引完，SELECT有其他字段，需要回表根据Primary Key再查一次\n=\u0026gt; 索引覆盖：将SELECT 所需的字段均放置在Index中，就不用回表查询了\n","permalink":"http://121.40.252.207/posts/jobs/mysql/","summary":"\u003ch3 id=\"617-mysql-数据排序-实现\"\u003e617 MySQL 数据排序 实现？\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eOrder By 命中索引(包括索引字段)，使用索引排序(有序)，效率最高效\u003c/li\u003e\n\u003cli\u003e否则使用文件排序，文件少=\u0026gt; 内存排序 sort_buffer\u003c/li\u003e\n\u003cli\u003e文件大=\u0026gt;外部排序，归并排序\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e内部排序细节：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e双路排序(待排序的列数据太大了)\u003c/strong\u003e：使用row_id(回查表) + sort_field\u003c/p\u003e\n\u003cp\u003e​\t\t排好序后，使用row_id将完整的记录取出来\u003c/p\u003e\n\u003cp\u003e单路排序(待排序数据大小能接受)\u003c/p\u003e\n\u003cp\u003e​\t直接拍，不会查表，直接把拍好的结果返回\u003c/p\u003e\n\u003cp\u003e外部排序：\u003c/p\u003e\n\u003cp\u003e拆分小的，外部多路归并排序，小=\u0026gt;大\u003c/p\u003e\n\u003cp\u003e外部归并排序 =\u0026gt; 先分段排序，每一段调入内存执行快排\u003c/p\u003e\n\u003cp\u003e​                        =\u0026gt; 归并阶段，因为每子段都是有序的 =\u0026gt; 多路归并排序\u003c/p\u003e\n\u003ch3 id=\"589-一条sql的执行过程\"\u003e589 一条SQL的执行过程\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e先通过\u003cstrong\u003e连接器\u003c/strong\u003e校验权限\u003c/li\u003e\n\u003cli\u003e利用\u003cstrong\u003e分析器\u003c/strong\u003e进行SQL语句词法分析和语法分析，构建解析树\u003c/li\u003e\n\u003cli\u003e利用\u003cstrong\u003e优化器\u003c/strong\u003e选择合适的索引和表连接顺序，最终选择一条最佳的执行计划\u003c/li\u003e\n\u003cli\u003e利用\u003cstrong\u003e执行器\u003c/strong\u003e，调用引擎层查询数据，返回结果集\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e具体：Select * from user where id = 1;\u003c/p\u003e\n\u003cimg src=\"http://sthda9dn6.hd-bkt.clouddn.com/FssKKPCKzeVJv4TEPdMldct1M8z4\" alt=\"image-20250305222939319\" style=\"zoom:50%;\" /\u003e\r\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSQL =\u0026gt; Server层\u003cstrong\u003e连接器\u003c/strong\u003e，权限校验，账号是否有资格获取。无=\u0026gt; Access denied for user。  连接成功后，空闲一段时间会断开\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e分析器(查询解析)\u003c/strong\u003e =\u0026gt;\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e语法分析：SQL  : Select类型✔️ user表✔️ id列 ✔️拆分成词，再组装为解析树。\u003c/li\u003e\n\u003cli\u003e语义分析：语法是否有误 =\u0026gt; you have an error in your SQL syntax (字段、表|存在？)   分析解析树语法正确性\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e优化器\u003c/strong\u003e(查询优化)=\u0026gt;\u003c/p\u003e","title":"MySQL面试题笔记"},{"content":"637 常见的数据类型 String Set Hash List Zset （Sorted Set） BitMap =\u0026gt; 位图，考勤，或者xxx分配情况\nHyperLogLog =\u0026gt; 用户访问的独立用户数量\nGEO =\u0026gt; 地理\n应用场景：\n缓存 实时系统 消息队列 分布式锁 计数器：页面访问量、点赞数、评论数 651 Redis 主从复制的实现原理 ➡️主节点-从节点 的数据同步\nWhy 需要主和从\n数据冗余\u0026amp;故障恢复，某个节点宕机了，但是其他节点还活着； 提供负载均衡，配合读写分离策略，主节点写操作，从节点提供读操作； 高可用：主从复制是Redis的高可用的基础，也是哨兵和集群实施的基础。 复制流程： 全量 \u0026amp; 增量\n主节点发送SYNC命令与从节点进行连接，开始同步， 主从之间建立联系；\n全量复制(第一次连接)： 主节点把全部数据复制到从节点，主节点将当前数据生成RDB文件，发送给从节点；\n发送的期间，主节点缓存(Replication backlog buffer-复制积压缓冲区)所有写命令。\n发送缓存的写命令给从节点。\n持续同步，持续把写命令同步给从节点。\n保持连接与断线重连\nRedis中，主节点会和从节点保持长连接，以确保数据的持续同步；\n当连接断开后，重连，请求增量复制，避免全量复制带来的大量开销。\n数据一致性和复制延迟\n由于网络延迟，主从之间会存在短暂的数据不一致。 ⭐对于数据一致性严格的任务，要求访问主节点。\n652 Redis集群实现的原理 ➡️通过多个Redis实例实现，每个实例存储部分数据，且这些数据是不重复的。类似于将数据库分库，按业务功能\n➡️具体为采用Hash Slot哈希槽，将键的空间划分为16384个槽。每个Redis实例只负责一部分槽。\n客户端 =\u0026gt; 任意Redis实例 =\u0026gt; 数据是否在本机上，在返回，否则返回目标节点信息，客户端再路由到其他Redis中。\n\u0026lt;= 将单个Redis的压力，分摊到多台Redis实例上，提高并发性能。\n特性\n实现数据分布式存储，对数据进行分片，将不同数据储存在不同节点中 去中心化思想，无中心节点，访问任意一个即可。访问正确则响应数据，否则响应对应的节点信息，客户端再次访问。 内置高可用性：分为N组，每组提供不同的数据缓存服务，每组中又有一个主节点和K个从节点(主提供读写，从提高读，并进行数据同步功能) 布局：\n集群有多个master，每个master保存不同的数据(海量数据) 每个master有多个slave (支持高并发读) master之间通过ping检查彼此的健康度 客户端请求可以访问集群任意节点，最终都会被转发到正确的节点(路由规则) 存储与读取\n分片集群引入hash slot，一共有16384个槽 不同实例处理不同的槽 读写数据：根据有效部分计算hash值，对16384取余，得到插槽，寻找插槽所在实例。 传统哈希\n1hash(key)%N N:服务器数量， N一旦变了，大部分数据都需要重新映射到新的服务器上 一致性哈希❌❌❌\n635 Redis为什么快 存储方式、线程模型、IO模型、数据结构\n基于内存\n单线程事件驱动(避免线程切换开销，避免锁竞争,数据一致性) 结合 IO多路复用(单线程同时处理多个客户端连接)\n高效数据结构 =\u0026gt; （String，List， Set）\n多线程引入 =\u0026gt; 网络处理并发请求，减少网络IO等待影响 (网络IO可能成为性能瓶颈)\nRedis主线程很快，但是网络IO处理不一定更得上它的速度，可能成为累赘。\n使用多个IO进程加快网络IO速度(数据序列号\u0026amp;反序列化，客户端请求的解析\u0026hellip;)\n638 跳表 多层链表实现，底层链表保存所有元素，每层链表都是下一层的子集 (有序链表的基础上添加多级索引)\n特性\n快查找某个元素 \u0026amp; 范围查询 复杂度O(logn) 1Level 3: 1 ---------------\u0026gt; 9 ----------------\u0026gt; 20 2Level 2: 1 ------\u0026gt; 5 -----\u0026gt; 9 ----\u0026gt; 13 -----\u0026gt; 20 3Level 1: 1 -\u0026gt; 3 -\u0026gt; 5 -\u0026gt; 7 -\u0026gt; 9 -\u0026gt; 11 -\u0026gt; 13 -\u0026gt; 15 -\u0026gt; 20 4Level 0: 1 -\u0026gt; 2 -\u0026gt; 3 -\u0026gt; 4 -\u0026gt; 5 -\u0026gt; 6 -\u0026gt; 7 -\u0026gt; 8 -\u0026gt; 9 -\u0026gt; 10 -\u0026gt; 11 -\u0026gt; 12 -\u0026gt; 13 -\u0026gt; 14 -\u0026gt; 15 -\u0026gt; 16 -\u0026gt; 20 从高层开始往下找\n插入时候呢 插入的随机层级：概率函数决定从下(level-0)到上(level-n) 概率为 0.25(n)\n跳表结构\n1Class SkipNode{ 2 int value; 3 SkipNode[] forward;// 指向不同层级的后继， 下一个level节点 4 5 public SkipNode(int value, int level) { 6 this.value = value; 7 this.forward = new SkipNode[level + 1]; // 0 到 level 层 每一个节点，动态的数据长度 8 } 9} 1class SkipList { 2 private static final int MAX_LEVEL = 16; // 最大层数 3 private int level; // 当前层数 4 private SkipListNode header; // 头节点 5 private Random random; // 随机数生成器，用于决定节点层数 6\t7 // 初始化头节点，其中有[0,...,MAX_LEVEL]的节点 8 public SkipList() { 9 this.level = 0; 10 this.header = new SkipListNode(Integer.MIN_VALUE, MAX_LEVEL); 11 this.random = new Random(); 12 } 13 14 // 插入节点 15 public void insert(int value) { 16 SkipListNode[] update = new SkipListNode[MAX_LEVEL + 1]; // 记录每层需要更新的节点位置 17 SkipListNode current = header; 18 19 // 从最高层开始查找插入位置 20 for (int i = level; i \u0026gt;= 0; i--) { 21 // 找到插入节点的位置 22 while (current.forward[i] != null \u0026amp;\u0026amp; current.forward[i].value \u0026lt; value) { 23 current = current.forward[i]; 24 } 25 update[i] = current; // 记录插入节点的位置 26 } 27 28 // 随机生成新节点的层数 29 int newLevel = randomLevel(); 30 31 // 如果新节点的层数大于当前层数，更新 update 数组和当前层数 32 if (newLevel \u0026gt; level) { 33 for (int i = level + 1; i \u0026lt;= newLevel; i++) { 34 update[i] = header; 35 } 36 level = newLevel; 37 } 38 39 // 创建新节点 40 SkipListNode newNode = new SkipListNode(value, newLevel); 41 42 // 更新每层的指针 43 for (int i = 0; i \u0026lt;= newLevel; i++) { 44 newNode.forward[i] = update[i].forward[i]; 45 update[i].forward[i] = newNode; 46 } 47 48 System.out.println(\u0026#34;Inserted: \u0026#34; + value); 49 } 50 51 52} 13 []=\u0026gt;^ 22 [] =\u0026gt; [] =\u0026gt;^ 31 []=\u0026gt;[]=\u0026gt;[] =\u0026gt;^ 40 []=\u0026gt;[]=\u0026gt;[] =\u0026gt;^ 5 -1 3 6 6 7update 记录每一层的插入位置 8SkipListNode newNode = new SkipListNode(value, newLevel); 每个节点数组长度为newLevel+1 639 Redis Hash 键值对集合\nObjKey =\u0026gt; {k1:v1, k2:v2}\n642 Redis数据过期删除策略 定时删除 =\u0026gt; 定时任务，多少时间检查，删除过期的键 惰性删除 =\u0026gt; 访问时，判断，过期了才删 内存回收机制\n当内存使用达到限制了，主动删除不常用的数据。 LRU算法 643 Redis内存淘汰策略 设置了过期时间的数据 淘汰策略\nrandom ttl lru 最近最少使用 least recent used lfu 最不常用 least frequency used 644 Redis Lua脚本 核心\n原子性，避免并发修改带来的安全问题 减少网络往返次数 复杂操作 Lua本身不具备原子性，但是Redis线程是单线程，因此Lua任务会一同执行，其他任务会被阻塞\n646 Redis BigKey问题，以及解决 Big Memory Key，key对应的value超级大\n内存分配不均，在集群模式下，如何某个实例的大key过多，负担不均衡 客户端超时 阻塞其他任务 解决\n开发方面\n开发时，数据压缩 大化小，拆成几份 选择合适的数据结构存储 业务方面\n仅存储必要信息 数据分布方面\n大Key拆分成小key，分散到不同redis实例中 647 如何解决redis中的热点key问题 问题：某个key被频繁访问，导致redis压力过大\n热点key拆分：将多个热点数据分散到多个key中，例如通过前缀，使不同请求分散到多个key中，且分布在多实例中，避免集中访问单一key。\n全量拷贝，key:datainfo =\u0026gt; key:datainfo_1, key:datainfo_2, key:datainfo_3 Key拆分，每个key只存一部分 例如：热点库存key =\u0026gt; stock:product_123,这个key被大量访问\n=\u0026gt; 对其进行拆分 4份\n1stock:product_123:1 2stock:product_123:2 3stock:product_123:3 4stock:product_123:4 5 6# 业务层 7int shardIndex = (productId.hashCode() \u0026amp; Integer.MAX_VALUE) % shardCount; 8String shardKey = \u0026#34;stock:product_123:\u0026#34; + shardIndex; 将请求拆分成多个key，分摊压力\n⭐数据一致性：需要同步所有相关的key\n多级缓存：在Redis前，增加其他缓存层，如(CDN,本地缓存)，分担redis的压力； CDN(Content Delivery Network 内容分发网络)；\n读写分离：通过Redis主从复制，将读请求分发到多个从节点，分摊压力；\n限流和降级：应用限流策略，减少对redis的请求，必要时回传空值或降级数据。\n648 Redis的持久化机制 RDB(redis database)快照 通过生成某一时刻的数据快照来实现持久化，间隔一定时间 二进制文件，数据紧凑，恢复数据快 AOP(Append only file)日志 AOP通过将每个写操作追加到日志中实现持久化，以便根据操作日志进行恢复，重放 恢复精确，但文件体积大 操作记录什么时候写回磁盘 立即，每个操作 =\u0026gt; 间隔, 间隔一定时间=\u0026gt; 写AOF 缓冲区满，再写AOF 混合RDB+AOP 利用RDB文件快和AOF的精确 备份的时候，先生成RDB，再将新增的写操作加到AOF文件后面 649 Redis在生成RDB快照时，如何处理请求 写时复制技术\nRDB快照并不会复制数据，而是复制页表(相当于指针) 当Redis处理写请求时，会复制对应的页数据，这样RDB快照和当前数据的页表部分指向将变化了，进行错开. RDB快照在利用fork子进程存储快照 650 Redis哨兵机制 sentinel ˈsentɪn(ə)l =\u0026gt; 系统能够在长时间运行中保持较高的可用性和稳定性，即使在出现故障时仍然能快速恢复，确保业务不中断。\n一种高可用性(稳健)解决方案，用于监控Redis主从集群，自动完成主从切换，以及故障自动恢复和通知\n监控：哨兵会不断的Ping redis主节点和从节点，定时Ping Redis实例，检查存活状态 自动故障转移：主节点宕机了，会选择一个从节点晋升为新的主节点，并通知客户端 通知，向管理员或其他服务发送通知，以便快速处理redis实例的变化 Redis主节点选举\n优先级， 通过配置文件， slave_priority\n优先级相同，则看同步状态offset(数据同步，复制偏移)，数据越一致，越可能成为主节点\n同步状态一致，则比较ID号\n选好master redis后，sentinel会把其他redis实例变为master redis的slave，将新主节点的IP和端口通知给客户端\n主观下线和客观下线\n1） sentinel每个1s Ping所有节点，当超过一段时间没收到对于节点的Pong，主观认为下线。\n2）客观下线(主节点而已)：如果主节点宕机了，它向其他哨兵发起投票，只有当下线的投票数大于一半的时候，才认为主节点宕机了。\n653. Redis集群脑裂问题 在网络分区的情况下，可能导致同一个集群出现多个主节点。\n分布式系统中，由于网络分区问题导致系统多个节点误认为自己是主节点，导致多个主节点提供写入服务，导致数据不一致。\n🏷️避免脑裂问题：\n【min-slaves-to-write】设置主节点至少有指定的从节点的情况下才执行写操作。 【min-slaves-max-lag】设置从节点的最大延迟，如果从节点的延迟超过这个值，则不计入min-slaves-to-write。 这样当脑裂后，某个主节点的从节点数量不够或者延迟较大，就无法写入，避免多个主节点写入造成的数据不一致。 【并不能完全解决】\n655 实现分布式锁 set ex nx (set expire_time not-exists) 命令 + lua脚本实现\n加锁：SET lock_key uniqueValue EX expire_time NX 解锁如下 1if redis.call(\u0026#34;GET\u0026#34;,KEYS[1]) == ARGV[1] # 避免别人删了这把锁 2then 3 return redis.call(\u0026#34;DEL\u0026#34;,KEYS[1]) 4else 5 return 0 6end 656 分布式锁在未完成业务时，过期了怎么办 =\u0026gt; 逻辑途中，给它续期\n扩展知识 - 看门狗机制\n抢到锁之后，启动后台定时任务，定时向redis进行锁的续期。比如每过1/3锁的过期时间，给锁续期\n业务完成，再把这个后台定时任务给结束\n并且分布式锁需要满足谁上锁谁解锁 释放锁时,需要1.检查锁是不是自己上的,再释放锁. 两步=\u0026gt; Lua脚本 654 Redis 订阅\u0026amp;发布 1 =\u0026gt; Subscriber 1 2publisher =\u0026gt; channel =\u0026gt; Subscriber 2 3 =\u0026gt; Subscriber 3 消息的订阅和推送 - 阻塞式消息拉取\nSUBSCRIBE channel\rPUBLISH channel message\rUNSUBSCRIBE channel 658 Redis 实现分布式锁可能遇到的问题有哪些? 分布式锁需要满足的要求\n锁的互斥: Redis setnx+redis单线程 可重入性:一个线程可以重复拿到同一把锁 锁的性能: 需要基于内存 会出现问题:\n锁误解 =\u0026gt; 需要确保锁自己自己解锁, 或者过期(线程ID判断下)\n锁的有效时间 =\u0026gt; Watchdog机制,给锁定期续时间\n单点故障问题 =\u0026gt; RedLock =\u0026gt;\n需要保证一半以上的节点加锁成功才算拿到这把锁 可重入锁\n1-- tryLock.lua 2-- KEYS[1] 锁的Key 3-- ARGV[1] 当前线程标识 4-- ARGV[2] 锁的过期时间 5 6local lockValue = redis.call(\u0026#39;get\u0026#39;, KEYS[1]) 7if lockValue == false then 8 // 锁不存在 9 redis.call(\u0026#39;setex\u0026#39;, KEYS[1], ARGV[2], ARGV[2]) 10 return true 11else 12 // 锁存在 13 local parts = {} 14\tlocal index = 0 15 for match in (localValue .. \u0026#34;:\u0026#34;):gmatch(\u0026#34;(.-):\u0026#34;) do 16 parts[index] = match 17 index = index + 1 18 end 19 if parts[0] == ARGV[1] then 20 -- 锁由当前线程所有,重入次数+1 21 local count = tonumber(parts[1]) + 1 22 redis.call(\u0026#39;setex\u0026#39;, KEYS[1], ARGV[2], ARGV[1] .. \u0026#34;:\u0026#34; .. count) 23 return true 24 end 25end 26return false 659 Redis中的缓存击穿、缓存穿透和缓存雪崩 概念\n缓存击穿： 某个热点Key数据在缓存中失效，导致大量的请求直接访问数据库。 瞬间的高并发，可能导致数据库崩溃； \u0026ndash; 热点过期\\删除 缓存穿透： 指查询一个不存在的数据，缓存中没有存储，直接二次映射到数据库中查询，造成数据库负担； 缓存雪崩： 指多个缓存数据在同一时间过期，导致大量请求同时访问数据库，从而造成数据库瞬间负载激增。 \u0026ndash; 批量过期 解决\n缓存击穿：\n1 加互斥锁，保证同一请求只有一个请求来重新构建缓存，其他线程等待。\n2 热点数据永不过期\n3 双重检查\n1String data = redisTemplate.opsForValue().get(\u0026#34;hot_key\u0026#34;) 2if(data == null) { // 数据没缓存 3 synchronized(this) { // 加速，仅一个线程取构建缓存 4 String data = redisTemplate.opsForValue().get(\u0026#34;hot_key\u0026#34;) // 这里再次判断，这样其他进入同步块的就不用重新访问DB构建缓存了 5 if(data == null){ 6 data = queryFromDB(); 7 redisTemplate.opsForValue().set(\u0026#34;hot_key\u0026#34;, data, 30, TimeUnit.MINUTES); 8 } 9 } 10} 缓存穿透(避免二次路由到数据库，拦截它)：\n使用布隆过滤器，过滤掉不存在的请求，避免直接访问数据库; hash(where condition)\n实现// 快速判断一个元素是否在BitMap中，将字符串用多个Hash函数映射到不同的二进制位置，将对齐位置设置为1；当查询的时候，需要所有位置都置1，那么该数据才可能存在。因为不会重置为0；\n对查询结果进行缓存，即使不存在的数据，也可以换成个标识(空数据，较短的过期时间)，减少对数据库的请求\n缓存雪崩(多个过期)\n数据预热，提前将热门的数据加载到缓存中，避免高并发出现大量的数据库访问。 采用随机分布的方式设置缓存失效时间，避免多个缓存数据同时过期(批量过期)；添加随机值，进行偏移 双缓存策略，将数据同时储存在两层缓存中。 在Redis之前，添加一层本地缓存，减少对Redis的依赖。 ​\t⭐Caffeine高性能缓存库 LRU淘汰策略\n1@Service 2public class CacheService { 3 @Resource 4 private Cache\u0026lt;String, String\u0026gt; localCache; 5 6 public void put(String key, String value) { 7 localCache.put(key, value); 8 } 9 10 public String get(String key) { 11 return localCache.getIfPresent(key); 12 } 13} 14 15@Configuration 16@EnableCaching 17public class CaffeineCacheConfig { 18 19 @Bean 20 public com.github.benmanes.caffeine.cache.Cache\u0026lt;String, String\u0026gt; localCache() { 21 return Caffeine.newBuilder() 22 .maximumSize(1000) // 最大缓存条目 23 .expireAfterWrite(10, TimeUnit.MINUTES) // 10 分钟自动过期 24 .build(); 25 } 26 27 @Bean 28 public CacheManager cacheManager() { 29 CaffeineCacheManager cacheManager = new CaffeineCacheManager(); 30 cacheManager.setCaffeine(Caffeine.newBuilder() 31 .expireAfterWrite(10, TimeUnit.MINUTES) 32 .maximumSize(1000)); 33 return cacheManager; 34 } 35} 36 37// # ----------- 用法 38@Cacheable(value = \u0026#34;users\u0026#34;, key = \u0026#34;#id\u0026#34;) 39public String getUserById(String id) { 40 System.out.println(\u0026#34;查询数据库：\u0026#34; + id); 41 return \u0026#34;User_\u0026#34; + id; 42} 本地缓存+Redis （多级缓存）\n1public String getData(String key) { 2 // 1. 先查本地缓存 3 String value = localCache.getIfPresent(key); 4 if (value != null) return value; 5 6 // 2. 查 Redis 7 value = redisTemplate.opsForValue().get(key); 8 if (value != null) { 9 // 回写本地缓存 10 localCache.put(key, value); 11 return value; 12 } 13 14 // 3. 查询数据库（模拟） 15 value = queryFromDB(key); 16 17 // 4. 回写 Redis 和本地缓存 18 redisTemplate.opsForValue().set(key, value, 10, TimeUnit.MINUTES); 19 localCache.put(key, value); 20 return value; 21} 660 Redis与MySQL的一致性策略 主要就是网络问题，和请求并发问题造成的不一致性\n⭐ 让redis和mysql数据一样⭐\n先更新Redis，再更新MySQL ❌不推荐 先更新MySQL，再更新Redis ❌不推荐 先删除Redis，再更新MySQL，最后写回Redis ❌不推荐 先更新MySQL，再删除Redis，等请求重新缓存(惰性) ✔️推荐 缓存双删除策略。更新MySQL之前，删除一次Redis；更新完MySQL后，再进行一次延迟删除 ✔️推荐 数据库没问题，但是缓存有问题，等待一段实践\n使用Binlog异步更新缓存，监听数据库的binlog变化，通过异步方式更新Redis缓存 ✔️推荐 # ==========================\nGPT版本：\n📌方案一： 延迟双删(最终一致性)，核心思路如下： 删除Redis缓存 更新MySQL数据 等待一小会时间 再次删除Redis缓存，防止并发请求写回脏数据 1// 1. 先删除 Redis 2redisTemplate.delete(key); 3 4// 2. 更新 MySQL 5databaseService.updateDataInMySQL(key, newValue); 6 7// 3. 延时再删除一次 Redis（解决并发问题） 8new Thread(() -\u0026gt; { 9 try { 10 TimeUnit.MILLISECONDS.sleep(500); 11 redisTemplate.delete(key); 12 } catch (InterruptedException e) { 13 e.printStackTrace(); 14 } 15}).start(); ✅ 适用场景\n✔ 适用于读多写少的场景（如商品详情页） ✔ 不影响数据库写入性能 ✔ 代码简单，容易实现\n🔴 缺点\n❌ 存在 500ms 的数据不一致窗口 ❌ 不能保证强一致性\n📌方案2：异步消息队列（最终一致性）。核心思路如下：\n更新MySQL数据 发送消息到RabbitMQ 消息消费者监听更新，删除Redis缓存 1public void updateData(String key, String newValue) { 2 // 1. 更新 MySQL 3 databaseService.updateDataInMySQL(key, newValue); 4 5 // 2. 发送消息到 MQ，通知消费者删除 Redis 6 rabbitTemplate.convertAndSend(\u0026#34;cache_update_queue\u0026#34;, key); 7} 8 9@RabbitListener(queues = \u0026#34;cache_update_queue\u0026#34;) 10public void processCacheUpdate(String key) { 11 redisTemplate.delete(key); 12} ✅ 适用场景\n✔ 适用于高并发场景 ✔ 避免了 Redis 和 MySQL 直接耦合 ✔ 保证最终一致性\n🔴 缺点\n❌ 需要额外的 MQ 服务（Kafka、RabbitMQ） ❌ 增加系统复杂度\n📌方案3：监听MySQL Binlog（强一致性）。\n✅核心思路如下：\n监听MySQL Binlog日志 实时解析SQL变更 删除Redis缓存 保证Redis和MySQL强一致性 ✅实现方式\nCanal 阿里巴巴开源 1public void onMessage(String binlogData) { 2 String changedKey = parseBinlog(binlogData); 3 redisTemplate.delete(changedKey); 4} ✅ 适用场景\n✔ 适用于高一致性要求的业务（如金融、电商支付） ✔ 高吞吐，低延迟，实时清理缓存 ✔ 适用于分布式系统\n🔴 缺点\n❌ 依赖 Canal，运维成本较高 ❌ 需要解析 Binlog，代码实现复杂\n评论：\n661 Redis String 类型底层实现 ❌ Redis String类型底层实现主要基于 SDS(Simple dynamic string)结构，并结合编码方式进行优化存储\n1struct __attribute__ ((__packed__)) sdshdr64 { 2 uint64_t len; /* used */ 3 uint64_t alloc; /* excluding the header and null terminator */ 4 unsigned char flags; /* 3 lsb of type, 5 unused bits */ 5 char buf[]; 6}; flags: SDS类型，SDS有5个类型 =\u0026gt; sdshdr5, sdshdr8 sdshdr16 sdshdr32 sdshdr64\n// simple dynamic string header =\u0026gt; sdshdr\n662 如何使用Redis快速实现排行榜 [(userInfo, liked_star), \u0026hellip;, ]\n利用Sorted Set(跳表实现) 存储分数和成员 663 如何利用Redis实现布隆过滤器 利用BitMap: (setBit, getBit)\n1// 添加元素到布隆过滤器 2public void add(String value) 3 for(SimpleHash hashFunc : hashFuncs) { 4 xxx.setbit(BLOOM_FILTER_KEY, hashFUnc(Value)) 5 } 6 7// 检查某个元素是否存在于布隆过滤器中 8public boolean mightContain(String value) { 9 for(SimpleHash hashFunc : hashFuncs) { 10 if(xxx.getBit(BLOOM_FILTER_KEY, hashFunc(value)) !=1) { 11 return false; 12 } 13} 布隆过滤器的适用场景\n爬虫：URL去重\n黑名单：判断\n分布式系统：判断数据是否在某个节点上\n推荐系统：判断用户是否看过某个内容\n664 如何利用Redis统计大量用户唯一访问量 =\u0026gt; HyperLogLog\nPFADD key element =\u0026gt; ADD HyperLogLog中 PFCOUNT key =\u0026gt; return unique number 665 Redis中的Geo数据结构 GEOADD key longitude latitude member GEODIST key member1 member2 GEORADIUS key longitude latitude radius unit; 668 Redis 性能瓶颈 扩容内存、读写分离、集群模式、多级缓存(本地、redis、mysql)\n885 Redis Cluster模式 和Sentinel模式 集群与哨兵模式\n集群 =\u0026gt; 数据切片,每个集群负责一部分数据, 集群内又分为主从模式;\n哨兵：高可用性，当master宕机，根据规则选择最优的slave并晋升为新的master\n1.Cluster集群模式:集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移(如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了哨兵逻辑) 2.Sentinel哨兵模式: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点.\n6305 Redisson分布式锁的原理 Redisson是基于Redis+lua脚本实现的分布式锁, 使用redis的原子操作来确保多线程\u0026hellip;， 只能有一个线程能够获取到锁，实现互斥。\n主要包括：\n获取锁：(setNX + 过期时间) 自动续期：(Watchdog 机制) 可重入性：(线程ID计数器，当值为0表示才真正的删除锁) 释放锁：(Lua脚本保证原子性) 1// ### get lock 2RLock lock = redisson.getLock(\u0026#34;lock:key\u0026#34;) 3// =\u0026gt; SET mylock thread-id NX PX 30s; thread-id保证可重入 4lock.lock() 5 6// ### 自动续期 watchdog 7// 如果线程未主动释放锁，redisson则每隔10s续期30s 8PEXPIRE lock:key 30s 9 10// ### 可重入性 11// 第一次加锁 12lock.lock(); 13 14// 同一线程再次加锁 15lock.lock(); 16 17// 释放锁 18lock.unlock(); 19lock.unlock(); // 只有 count=0 时才真正释放 分布式锁最佳实践\n1RLock lock = redisson.getLock(\u0026#34;myLock\u0026#34;); 2 3try { 4 // 尝试获取锁，最多等待 5 秒，10 秒后自动释放（防止死锁） 5 if (lock.tryLock(5, 10, TimeUnit.SECONDS)) { 6 try { 7 // 执行业务逻辑 8 // ... 9 } finally { 10 lock.unlock(); // 释放锁 11 } 12 } else { 13 System.out.println(\u0026#34;获取锁失败\u0026#34;); 14 } 15} catch (InterruptedException e) { 16 e.printStackTrace(); 17} ","permalink":"http://121.40.252.207/posts/jobs/redis/","summary":"\u003ch3 id=\"637-常见的数据类型\"\u003e637 常见的数据类型\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eString\u003c/li\u003e\n\u003cli\u003eSet\u003c/li\u003e\n\u003cli\u003eHash\u003c/li\u003e\n\u003cli\u003eList\u003c/li\u003e\n\u003cli\u003eZset （Sorted Set）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBitMap =\u0026gt; 位图，考勤，或者xxx分配情况\u003c/p\u003e\n\u003cp\u003eHyperLogLog =\u0026gt; 用户访问的独立用户数量\u003c/p\u003e\n\u003cp\u003eGEO =\u0026gt; 地理\u003c/p\u003e\n\u003cp\u003e应用场景：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e缓存\u003c/li\u003e\n\u003cli\u003e实时系统\u003c/li\u003e\n\u003cli\u003e消息队列\u003c/li\u003e\n\u003cli\u003e分布式锁\u003c/li\u003e\n\u003cli\u003e计数器：页面访问量、点赞数、评论数\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"651-redis-主从复制的实现原理\"\u003e651 Redis 主从复制的实现原理\u003c/h3\u003e\n\u003cp\u003e➡️主节点-从节点 的数据同步\u003c/p\u003e\n\u003cp\u003eWhy 需要主和从\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e数据冗余\u0026amp;故障恢复，某个节点宕机了，但是其他节点还活着；\u003c/li\u003e\n\u003cli\u003e提供负载均衡，配合读写分离策略，主节点写操作，从节点提供读操作；\u003c/li\u003e\n\u003cli\u003e高可用：主从复制是Redis的高可用的基础，也是哨兵和集群实施的基础。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e复制流程： 全量 \u0026amp; 增量\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e主节点发送SYNC命令与从节点进行连接，开始同步， 主从之间建立联系；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e全量复制(第一次连接)： 主节点把全部数据复制到从节点，主节点将当前数据生成RDB文件，发送给从节点；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e发送的期间，主节点缓存(Replication backlog buffer-复制积压缓冲区)所有写命令。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e发送缓存的写命令给从节点。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e持续同步，持续把写命令同步给从节点。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e\n\u003cp\u003e保持连接与断线重连\u003c/p\u003e\n\u003cp\u003eRedis中，主节点会和从节点保持长连接，以确保数据的持续同步；\u003c/p\u003e\n\u003cp\u003e当连接断开后，重连，请求增量复制，避免全量复制带来的大量开销。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e数据一致性和复制延迟\u003c/p\u003e\n\u003cp\u003e由于网络延迟，主从之间会存在短暂的数据不一致。 ⭐对于数据一致性严格的任务，要求访问主节点。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch3 id=\"652-redis集群实现的原理\"\u003e652 Redis集群实现的原理\u003c/h3\u003e\n\u003cp\u003e➡️通过多个Redis实例实现，每个实例存储部分数据，且这些数据是不重复的。\u003cstrong\u003e类似于将数据库分库，按业务功能\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e➡️具体为采用Hash Slot哈希槽，将键的空间划分为16384个槽。每个Redis实例只负责一部分槽。\u003c/p\u003e\n\u003cp\u003e客户端 =\u0026gt; 任意Redis实例 =\u0026gt; 数据是否在本机上，在返回，否则返回目标节点信息，客户端再路由到其他Redis中。\u003c/p\u003e\n\u003cp\u003e\u0026lt;= 将单个Redis的压力，分摊到多台Redis实例上，提高并发性能。\u003c/p\u003e\n\u003cp\u003e特性\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e实现数据分布式存储，对数据进行分片，将不同数据储存在不同节点中\u003c/li\u003e\n\u003cli\u003e去中心化思想，无中心节点，访问任意一个即可。访问正确则响应数据，否则响应对应的节点信息，客户端再次访问。\u003c/li\u003e\n\u003cli\u003e内置高可用性：分为N组，每组提供不同的数据缓存服务，每组中又有一个主节点和K个从节点(主提供读写，从提高读，并进行数据同步功能)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250307175456538\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/Fo9jCIPyRQ866mnZdasVsUwqao1j\"\u003e\u003c/p\u003e","title":"Redis面试题笔记"},{"content":"415 序列化\u0026amp;反序列化 将Object转为字节流，或反之\n普通：实现serializable接口 ˈsɪərɪəlaɪzəbl 使用Jackon，Obj =\u0026gt; json格式 416 Java中的不可变类 final 修饰，例如String类\n🎉优点：\n线程安全 缓存友好 缺点\n性能问题，因为不能修改，所有每次状态变化，都需要生成新的对象。 411 多态特性 继承 方法重载，函数名相同，但是函数签名需要有差异(参数类型\u0026amp;数量) 重写，子类重写父类方法，通过父类调用方法时，调用的是子类重写后的函数。 412 Java参数传值是副本还是引用呢？ 基本类型是传值副本，int\u0026hellip; 引用数据类型是传引用副本。 including：obj，array 425 Java中 包装类型和基本类型 🏷️基本类型 =\u0026gt; int long float double \u0026hellip; 位于栈上(局部变量的话) ，性能好，但不支持为null\n（局部变量在栈上，成员变量在堆上，静态字段在方法区）\n🏷️包装类型 =\u0026gt; 每一个基本类型都对应一个包装类型。包装类型是类，在堆中，支持null\nJVM内存模型 ❗❗❗内存堆和数据结构堆不是同一个东西(不是堆的结构)\n1+--------------------------------------------+ 2| 方法区（Method Area） | ← 线程共享 3| - 类元数据（Class 信息） | 4| - 静态变量（static 变量） | 5| - 常量池（字符串常量等） | 6+--------------------------------------------+ 7 ↑ ↑ 8 | | 9+----------------+ +-----------------+ 10| 栈（Stack） | | 堆（Heap） | ← 线程共享 11| - 局部变量 | | - Java 对象实例 | 12| - 方法调用栈 | | - 数组 | 13+----------------+ +-----------------+ 413 interface \u0026amp; abstract class interface(自上而下) 知晓某一种行为，基于这些行为约束定义的接口， 一些类需要有这些行为的话，需要实现这些接口 abstract class(自下而上): 有许多类，它们有共同点，很多代码可以复用，因此将公共逻辑封装为抽象对象。 100 hashCode \u0026amp; equals \u0026amp; == hashCode用于散列表(hashMap)用于计算hash值，从而计算存储位置；\nequals比较对象内容是否相等，默认是==。 可能需要重写equals方法逻辑，实现对象成员变量的比较；\n== 引用类型比较两个引用是否指向同一个对象(内存地址)，基本类型则比较值。\n431 Java注解 注解就是一个标记，提供元数据机制，给予代码添加说明信息。可以在类，方法，成员变量\u0026hellip;上标记，标记本身可以设置一些值。\n1 @Target(Class,...) 2@Retention(RetentionPolicy.RUNTIME) // 注解保留时间 3public @interface MyInterface { 4 String value(); 5} 6 7// 运行时，通过反射机制拿到对应的注解 -- 结合AOP做事情 8...Obj.getAnnotation(\u0026#34;MyInterface\u0026#34;)... 432 Java反射 运行时获取类的信息，并操作对象\n1Person person = new Person(\u0026#34;Emma\u0026#34;, 28); 2Class\u0026lt;?\u0026gt; cls = person.getClass(); 3 4// 调用无参方法 5Method greetMethod = cls.getDeclaredMethod(\u0026#34;greet\u0026#34;); 6greetMethod.invoke(person); 7 8// 调用有参方法 9Method setAgeMethod = cls.getDeclaredMethod(\u0026#34;setAge\u0026#34;, int.class); 10setAgeMethod.invoke(person, 35); 11 12System.out.println(person); // Person{name=\u0026#39;Emma\u0026#39;, age=35} 434 Java泛型 通过在编译时检查类型安全，使得代码更加通用和灵活，避免运行时发生类型转换错误。 简单理解=\u0026gt; 将运行时的类型转换异常上升到编译时候\n类型安全 代码重用 消除显示类型转换，一开始指定好 🏷️泛型类\n1public class Box\u0026lt;T\u0026gt; { 2 private T value; 3 public Box(T value) { this.value = value; } 4 public T getValue() { return value; } 5} 6// 这样的话 getValue()就不需要(Type)getValue()了， 直接告诉调用者返回类型 =\u0026gt; 避免类型转换,且提高代码复用性 🏷️泛型方法\n1// 泛型方法 2public static \u0026lt;T\u0026gt; T getFirst(T[] array) { 3 return array[0]; 4} 5 6// \u0026lt;T\u0026gt; 是申明T是泛型哦， 不然谁知道它是不是一个类的名称 7// 🎉更加灵活 8String[] words = {\u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;}; 9Integer[] numbers = {1, 2, 3}; 10 11System.out.println(getFirst(words)); // Hello 12System.out.println(getFirst(numbers)); // 1 🏷️限制参数类型 防止非法类型使用\n1class Calculator\u0026lt;T extends Number\u0026gt; 6306 Java泛型擦除 Java编译器在编译代码的时候，将所有泛型信息删除的过程。 擦除是为了确保与旧版本兼容\n1Class Box\u0026lt;T\u0026gt; {} =\u0026gt; class Box {} (T =\u0026gt; Object) 2Class Box\u0026lt;T extends Number\u0026gt; {} =\u0026gt; class Box {} (T =\u0026gt; Number) 泛型类型上界 ? extends T\n泛型类型下届 ? super T\n限制类型\n436 Java深拷贝\u0026amp;浅拷贝 深拷贝：不仅复制当前对象本身，而且递归的复制对象内的引用。 重写clone方法，或许序列化和反序列化生成新的对象； 浅拷贝：只复制对象的本身和基本类型的成员变量，而不复制引用类型的对象。 Object.clone()； 引用拷贝：仅复制对应引用 **Object o1 = o2; ** 。 438 Java类加载过程 类加载过程：\n加载：二进制流读入内存，生成Class对象 连接 验证：格式是否规范 准备：为静态变量设置初始值，为它们在方法区开辟。 解析：将常量池的符号引用转化为直接引用。 初始化：执行静态代码块，为静态变量赋值(代码逻辑里面的)。 440 BigDecimal 高精度的计算类，处理任意精度的数值。 涉及到钱，用这个\n442 Java中的final、finally final修饰符，指类和变量不能再修改。\n1class final MyClass { 2 3} 不论是否异常，都会执行finally代码块\n1try{ 2 3}catch() { 4 5} finally { 6 7} 825 Java调用外部可执行程序 使用Runtime.exec()\n1try { 2 // 执行命令 3 Process process = Runtime.getRuntime().exec(\u0026#34;notepad.exe\u0026#34;); 4 // 等待外部进程结束 5 int exitCode = process.waitFor(); 6 // 检查执行情况 7 if ... else ... 8} 使用ProcessBuilder\n1// 配置程序信息 2ProcessBuilder builder = new ProcessBuilder(\u0026#34;cmd.exe\u0026#34;, \u0026#34;/c\u0026#34;, \u0026#34;dir\u0026#34;); 3// builder.xxx() ... 配置信息 4 5// 启动进程 6Process process = builder.start(); 7 8// 获取进程输出 9InputStream is = process.getInputStream(); 10// ... 11 12// 等待结束 13int code = process.waitFor() 14 15// 检查执行情况 938 如果一个线程在Java中被两次调用start方法，会发生什么？ 报错 =\u0026gt; Java中，一个线程只能被启动一次。\n943 IO流 读取数据和输出数据\n字节流，用于处理二进制文件, InputStream\u0026amp;OutputStream; InputStream 子类如下： FileInputStream BufferedInputStream // 提供缓冲区，提高性能 字符流，用于处理文本。 Reader\u0026amp;Writer； Reader 子类如下： FileReader BufferedReader 945 Java网络编程 🏷️用于网络通信，网络编程基本概念\nIP地址 端口号 socket(ip:port) 协议，TCP \u0026amp; UDP 等等 TCP实践\n1// 服务器代码 2class ServerThread extends Thread { 3 private Socket socket = new ServerSocket(\u0026#34;localhost\u0026#34;, 8080); 4 5 @overwrite 6 public void run() { 7 try { 8 PrintWriter out = new PrintWriter(socket.getOutputStream() ... ); 9 BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream())); 10 11 String message = in.readLine(); 12 out.println(\u0026#34;Hello, client!\u0026#34;); 13 } 14 } 15} 16 17// Client 18Socket socket = new Socket(\u0026#34;localhost\u0026#34;, 8080) 19 20// ServerSocket \u0026amp; Socket 949 Java中的自动装箱和拆箱 自动装箱/拆箱让 Java 更加易用，减少了手动转换的冗余代码，同时保持了类型安全\n自动拆箱和装箱 , 解决泛型不支持基本类型 1List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // ✅ 使用包装类 Integer 2 3// 手动装箱和拆箱 4list.add(Integer.valueOf(10)); // int =\u0026gt; Integer 5int a = list.get(0).intValue(); // Integer =\u0026gt; int 手动实现 6 7// 自动装箱和拆箱 8list.add(10) 9int a = list.get(0) 基本类型当作对象使用 1Map\u0026lt;Integer,String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); 2map.put(1, \u0026#34;One\u0026#34;) \u0026lt;= 自动装箱 3String value = map.get(1) \u0026lt;= 自动装箱 简化基本类型和包装类型 1public static int add(Integer a, Integer b) { 2 return a + b; // 这里的 a 和 b 需要自动拆箱 3} 4 5// 手动拆箱 6public static int add(Integer a, Integer b) { 7 return a.intValue() + b.intValue(); // 这里的 a 和 b 需要自动拆箱 8} 988 Java中的迭代器 Iterator ɪtəˈreɪtə 作用用于遍历集合\nhasNext(): 返回是否存在下一个元素 next(): 返回下一个元素 1Iterator iterator = list.iterator() 2while(iterator.hasNext()) { 3 // ... 4 iterator.next(); 5} 993 Java特性 封装：将对象的状态和行为封装在一个类内部，并通过公开的接口与外部进行交互。只暴露必要功能。\n继承：子类继承父类，可以继承它的属性和方法，提高代码重用和扩展。\n多态：重写\u0026amp;重载\n994 Java中访问修饰符 public：All private：当前类 protected：当前类，同一包(package声明一致)，子类 default，当前类，同一包 995 静态方法\u0026amp;实例方法 静态方法 static声明：属于类而非具体的实例，通过类名调用。\n工厂方法，工具类 当类的字节码文件加载到内存，类方法的入口地址就会被分配完成，所以类方法不仅仅被该类的对象调用，也可以直接通过类名称完成调用，类方法的入口地址只有程序退出才消失。 实例方法：属于实例，通过实例调用；\n当类的字节码加载到内存中的时候，类的实例方法并没有被分配到入口地址，只有当类的对象创建之后，实例方法才分配了入口地址，从而实例方法可以被类创建的所有的对象所调用，还有一点要注意，当我们创建第一个类的对象时，实例方法的入口地址会完成分配，当后续在创建对象时，不会被分配新的入口地址，该类的所有的对象共享实例方法的入口地址，当该类的所有的对象被销毁，入口的地址才会消失。 990 java中for和for-each for，下标遍历 for-each，遍历集合，不提供下标，且不能修改集合，否则报错 5900 wait()和sleep() wait() 需要和 notify()搭配使用。 用于在同步代码块同，阻塞和唤醒\nsleep() 使线程进行休眠状态，让出CPU使用权，时间到了自动恢复为就绪态等待系统分配CPU\n5908 Java Object类有什么方法及对应作用 hashCode() 计算哈希值\nequals() 默认引用是否一致\n根据需求重写这个，实现指定对象属性比较 toString() 默认返回对象的类名+hashCode的16进制表示\n重写使其更有描述意义。 getClass() 返回对象的Class类对象\nwait() 挂起当前线程，使其变为等待状态。\nnotify\u0026amp;notifyAll() 唤醒在对象监视器上等待的一个or全部线程\nclone() 浅拷贝对象，其中引用属性不拷贝\n重写实现深拷贝，保证完整性 5909 Java字节码是什么？❌ 处于 源代码.java 和 JVM.bin 执行的机器代码.exe(windows)之间的中间表示。\n.class 文件 可以被JVM解释器编译为机器码\n🎉通过Java反射Api，可以在运行时动态生成或者修改字节码，从而创建代理对象或实现动态方法调用\n166 BIO、NIO、AIO BIO:人一直盯着水烧开，水烧开之后亲自关火 NIO:人在烧水的时候去干别的事情，时不时看着水烧没烧开，烧开之后亲自关火 AIO:人找了一个帮手，帮手在烧水的时候一直盯着，水烧开之后帮手关火，然后提醒人水烧开了。人全程不管烧水的事情\nBIO：Blocking IO。传统阻塞式IO模式，调用方调用BIO会被阻塞，直到IO服务完成才被唤醒。 场景：同步、阻塞，适合并发连接较少的场景，小型服务。 1// 客户端 2// 1. 创建服务器 socket，监听端口 3serverSocket = 创建 ServerSocket(端口); 4 5// 2. 服务器循环等待客户端连接 6while (true) { 7 // 3. 阻塞等待客户端连接 8 socket = serverSocket.accept(); ⭐这里会卡住 9 10 // 4. 每个连接创建新线程 11 启动新线程(() -\u0026gt; { 12 inputStream = socket.getInputStream(); 13 outputStream = socket.getOutputStream(); 14 15 while (true) { 16 // 5. 读取数据（阻塞） 17 data = 读取数据(inputStream); 18 if (data == null) break; 19 20 // 6. 处理数据 21 处理数据(data); 22 23 // 7. 响应客户端（阻塞） 24 outputStream.write(响应数据); 25 } 26 // 8. 关闭连接 27 socket.close(); 28 }); 29} 30 31 32// 客户端 33// 1. 创建 Socket 连接服务器 34socket = 创建 Socket(服务器IP, 端口); 35 36// 2. 获取输入输出流 37inputStream = socket.getInputStream(); 38outputStream = socket.getOutputStream(); 39 40// 3. 发送数据（阻塞） 41outputStream.write(请求数据); 42outputStream.flush(); 43 44// 4. 读取服务器响应（阻塞） 45response = 读取数据(inputStream); 46 47// 5. 处理响应 48处理数据(response); 49 50// 6. 关闭连接 51socket.close(); 一连接一线程\nNIO：Non-blocking IO。非阻塞IO模式，调用方发起IO操作即返回，不论任务是否完成。通常结合IO多路复用技术，使得一个线程可以同时管理多个连接。 1// 1. 创建 Selector（事件选择器） 2selector = 创建 Selector(); 3 4// 2. 创建非阻塞 ServerSocketChannel，绑定端口 5serverChannel = 创建 ⭐ServerSocketChannel(端口)⭐; 6serverChannel.configureBlocking(false); 7 8// 3. 注册到 Selector，监听 \u0026#34;accept\u0026#34; 事件 9serverChannel.register(selector, OP_ACCEPT); 10 11// 4. 服务器循环监听事件 12while (true) { 13 // 5. 轮询监听已准备好的 I/O 事件， 监视多个Channel 14 selector.select(); 15 16 // 6. 遍历所有发生事件的通道 17 for (key : selector.selectedKeys()) { 18 if (key.isAcceptable()) { // 7. 处理新连接 19 socketChannel = serverChannel.accept(); 20 socketChannel.configureBlocking(false); 21 socketChannel.register(selector, OP_READ | OP_WRITE); 22 } 23 else if (key.isReadable()) { // 8. 读取数据 24 socketChannel = key.channel(); 25 buffer = 创建 ByteBuffer(); 26 bytesRead = socketChannel.read(buffer); 27 if (bytesRead \u0026gt; 0) { 28 处理数据(buffer); 29 } 30 } 31 else if (key.isWritable()) { // 9. 响应客户端 32 socketChannel = key.channel(); 33 buffer = 创建 ByteBuffer(响应数据); 34 socketChannel.write(buffer); 35 } 36 } 37} 38 39 40// 客户端 41// 1. 创建 Selector（事件管理器） 42selector = 创建 Selector(); 43 44// 2. 创建非阻塞 SocketChannel 45socketChannel = 创建 ⭐SocketChannel()⭐; 46socketChannel.configureBlocking(false); 47 48// 3. 连接服务器（非阻塞） 49socketChannel.connect(服务器IP, 端口); 50 51// 4. 注册到 Selector，监听 \u0026#34;连接完成\u0026#34; 事件 52socketChannel.register(selector, OP_CONNECT | OP_READ | OP_WRITE); 53 54// 5. 轮询 Selector 监听事件 55while (true) { 56 selector.select(); // 轮询等待事件 57 for (key : selector.selectedKeys()) { 58 if (key.isConnectable()) { // 6. 处理连接完成事件 59 if (socketChannel.finishConnect()) { 60 socketChannel.register(selector, OP_READ | OP_WRITE); 61 } 62 } 63 else if (key.isWritable()) { // 7. 发送数据 64 buffer = 创建 ByteBuffer(请求数据); 65 socketChannel.write(buffer); 66 } 67 else if (key.isReadable()) { // 8. 读取服务器响应 68 buffer = 创建 ByteBuffer(); 69 bytesRead = socketChannel.read(buffer); 70 if (bytesRead \u0026gt; 0) { 71 处理数据(buffer); 72 } 73 } 74 } 75} ​\nAIO：Asynchronous IO 异步IO 利用回调or通知的方式告知调用方 1// 1. 创建异步 ServerSocketChannel 2serverChannel = 创建 AsynchronousServerSocketChannel(端口); 3serverChannel.bind(端口); 4 5// 2. 监听客户端连接（异步回调） 6serverChannel.accept(null, new CompletionHandler\u0026lt;\u0026gt;() { 7 // 3. 处理新连接 8 completed(socketChannel, attachment) { 9 // 4. 继续监听新的客户端 10 serverChannel.accept(null, this); 11 12 // 5. 读取数据（异步回调） 13 buffer = 创建 ByteBuffer(); 14 socketChannel.read(buffer, buffer, new CompletionHandler\u0026lt;\u0026gt;() { 15 // 6. 读取完成，处理数据 16 completed(bytesRead, buffer) { 17 if (bytesRead \u0026gt; 0) { 18 处理数据(buffer); 19 20 // 7. 响应客户端（异步回调） 21 socketChannel.write(ByteBuffer.wrap(响应数据), null, new CompletionHandler\u0026lt;\u0026gt;() { 22 completed(bytesWritten, attachment) { 23 // 响应完成 24 } 25 }); 26 } 27 } 28 }); 29 } 30}); 31 32// 客户端 33// 1. 创建异步 SocketChannel 34socketChannel = 创建 AsynchronousSocketChannel(); 35 36// 2. 连接服务器（异步回调） 37socketChannel.connect(服务器IP, 端口, null, new CompletionHandler\u0026lt;\u0026gt;() { 38 // 3. 连接成功回调 39 completed(attachment) { 40 // 4. 发送数据（异步） 41 buffer = 创建 ByteBuffer(请求数据); 42 socketChannel.write(buffer, buffer, new CompletionHandler\u0026lt;\u0026gt;() { 43 completed(bytesWritten, buffer) { 44 // 5. 继续读取服务器响应（异步） 45 buffer.clear(); 46 socketChannel.read(buffer, buffer, new CompletionHandler\u0026lt;\u0026gt;() { 47 completed(bytesRead, buffer) { 48 处理数据(buffer); 49 } 50 }); 51 } 52 }); 53 } 54}); 439 Java双亲委派模型 ❌❌❌ Java类加载机制的设计模式之一。 核心思想：类加载器在加载某个类时，先委派父类去加载，父类无法加载时，才由当前类加载器加载。 自定义ClassLoader继承系统的\u0026amp;重写findClass即可\nGPT: 双亲委派模型（Parent Delegation Model） 是 Java 类加载机制 的一个规则。 当一个类加载器要加载某个类时，先让父类加载器尝试加载，只有当父类加载器无法加载该类时，才由自身加载\n1【Bootstrap ClassLoader】（引导类加载器） 2 ↑ 加载-1，不行的话到2 3【ExtClassLoader】（扩展类加载器） 4 ↑ 加载-2，不行的话到3 5【AppClassLoader】（应用类加载器） 6 ↑ 加载-3，不行的话到4 7【自定义 ClassLoader】（用户自定义加载器） 加载-4 8 9// 倒着的U字形 它解决的问题\n避免类重复加载，如果没有该机制 =\u0026gt; 每个类加载器都可以自行加载同一个类，可能导致 ClassCastException（类转换异常） 1ClassLoader cl1 = new MyClassLoader(); // 自定义类加载器 2ClassLoader cl2 = new MyClassLoader(); 3 4Class\u0026lt;?\u0026gt; class1 = cl1.loadClass(\u0026#34;com.example.MyClass\u0026#34;); 5Class\u0026lt;?\u0026gt; class2 = cl2.loadClass(\u0026#34;com.example.MyClass\u0026#34;); 6 7// class1 和 class2 虽然名字相同，但是两个不同的类 8Object obj = class1.newInstance(); 9MyClass myObj = (MyClass) obj; // 可能抛出 ClassCastException 10// 每个类加载器都有自己独立的类加载空间。如果你使用多个类加载器加载同一个类，它们会认为这是两个不同的类，尽管类的名字和内容完全相同。 保证Java核心类的安全 因为委托父类加载\n例如\n1package java.lang; 2public class String { 3 public static void hack() { 4 System.out.println(\u0026#34;Java 被黑了！\u0026#34;); 5 } 6} 如果没有双亲委派，那么加载的是自定义的类，可能导致安全漏洞。\n","permalink":"http://121.40.252.207/posts/jobs/java/","summary":"\u003ch3 id=\"415-序列化反序列化\"\u003e415 序列化\u0026amp;反序列化\u003c/h3\u003e\n\u003cp\u003e将Object转为字节流，或反之\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e普通：实现serializable接口 ˈsɪərɪəlaɪzəbl\u003c/li\u003e\n\u003cli\u003e使用Jackon，Obj =\u0026gt; json格式\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"416-java中的不可变类\"\u003e416 Java中的不可变类\u003c/h3\u003e\n\u003cp\u003efinal 修饰，例如String类\u003c/p\u003e\n\u003cp\u003e🎉优点：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e线程安全\u003c/li\u003e\n\u003cli\u003e缓存友好\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e缺点\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e性能问题，因为不能修改，所有每次状态变化，都需要生成新的对象。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"411-多态特性\"\u003e411 多态特性\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e继承\u003c/li\u003e\n\u003cli\u003e方法重载，函数名相同，但是函数签名需要有差异(参数类型\u0026amp;数量)\u003c/li\u003e\n\u003cli\u003e重写，子类重写父类方法，通过父类调用方法时，调用的是子类重写后的函数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"412-java参数传值是副本还是引用呢\"\u003e412 Java参数传值是副本还是引用呢？\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e基本类型是传\u003cstrong\u003e值副本\u003c/strong\u003e，int\u0026hellip;\u003c/li\u003e\n\u003cli\u003e引用数据类型是传\u003cstrong\u003e引用副本\u003c/strong\u003e。 including：obj，array\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"425-java中-包装类型和基本类型\"\u003e425 Java中 包装类型和基本类型\u003c/h3\u003e\n\u003cp\u003e🏷️基本类型 =\u0026gt; int long float double  \u0026hellip;  位于栈上(局部变量的话) ，性能好，但\u003cstrong\u003e不支持为null\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e（局部变量在栈上，成员变量在堆上，静态字段在方法区）\u003c/p\u003e\n\u003cp\u003e🏷️包装类型 =\u0026gt; 每一个基本类型都对应一个包装类型。\u003cstrong\u003e包装类型是类，在堆中，支持null\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eJVM内存模型\u003c/strong\u003e  ❗❗❗内存堆和数据结构堆不是同一个东西(不是堆的结构)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+--------------------------------------------+\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e               \u003c/span\u003e\u003cspan class=\"n\"\u003e方法区\u003c/span\u003e\u003cspan class=\"err\"\u003e（\u003c/span\u003e\u003cspan class=\"n\"\u003eMethod\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eArea\u003c/span\u003e\u003cspan class=\"err\"\u003e）\u003c/span\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"err\"\u003e←\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e线程共享\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e类元数据\u003c/span\u003e\u003cspan class=\"err\"\u003e（\u003c/span\u003e\u003cspan class=\"n\"\u003eClass\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e信息\u003c/span\u003e\u003cspan class=\"err\"\u003e）\u003c/span\u003e\u003cspan class=\"w\"\u003e                   \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e静态变量\u003c/span\u003e\u003cspan class=\"err\"\u003e（\u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e变量\u003c/span\u003e\u003cspan class=\"err\"\u003e）\u003c/span\u003e\u003cspan class=\"w\"\u003e                  \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e常量池\u003c/span\u003e\u003cspan class=\"err\"\u003e（\u003c/span\u003e\u003cspan class=\"n\"\u003e字符串常量等\u003c/span\u003e\u003cspan class=\"err\"\u003e）\u003c/span\u003e\u003cspan class=\"w\"\u003e                   \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e+--------------------------------------------+\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"err\"\u003e↑\u003c/span\u003e\u003cspan class=\"w\"\u003e              \u003c/span\u003e\u003cspan class=\"err\"\u003e↑\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e              \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 9\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e+----------------+\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e+-----------------+\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e10\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"n\"\u003e栈\u003c/span\u003e\u003cspan class=\"err\"\u003e（\u003c/span\u003e\u003cspan class=\"n\"\u003eStack\u003c/span\u003e\u003cspan class=\"err\"\u003e）\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"n\"\u003e堆\u003c/span\u003e\u003cspan class=\"err\"\u003e（\u003c/span\u003e\u003cspan class=\"n\"\u003eHeap\u003c/span\u003e\u003cspan class=\"err\"\u003e）\u003c/span\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"err\"\u003e←\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e线程共享\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e11\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e局部变量\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eJava\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e对象实例\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e12\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e方法调用栈\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e数组\u003c/span\u003e\u003cspan class=\"w\"\u003e         \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e13\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e+----------------+\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e+-----------------+\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"413-interface--abstract-class\"\u003e413 interface \u0026amp; abstract class\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003einterface(自上而下) 知晓某一种行为，基于这些行为约束定义的接口， 一些类需要有这些行为的话，需要实现这些接口\u003c/li\u003e\n\u003cli\u003eabstract class(自下而上): 有许多类，它们有共同点，很多代码可以复用，因此将公共逻辑封装为抽象对象。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"100-hashcode--equals--\"\u003e100 hashCode \u0026amp; equals \u0026amp; ==\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ehashCode用于散列表(hashMap)用于计算hash值，从而计算存储位置；\u003c/p\u003e","title":"Java面试题笔记"},{"content":"高频SQL50题 查询 Where\u0026amp;GroupBy\u0026amp;HAVING 1SELECT id, revenue # 某个用户2021年可能有多项记录 2FROM users 3Where year = 2021 4 5SELECT id, SUM(revenue) 6FROM users 7Where year = 2021 # 1. 先筛选出此年份所有记录 8Group By id # 2. 再根据id分组 3. 必须结合SUM() 或者其他聚合函数，因此这个有多列，需要处理为单值。 9 10SELECT id 11FROM users 12Where year = 2021 # 1. 先筛选记录 13Group By id # 2. 分组 14HAVING SUM(revenue) \u0026gt; 1000 # 3. 聚合分组字段记录 并 判断 查找没买过东西的顾客 1# 1. NOT EXISTS 2SELECT `name` AS `Customers` 3FROM `Customers` AS c 4WHERE NOT EXISTS ( 5 SELECT `customerId` 6 FROM `Orders` AS o 7 Where o.customerId = c.id 8) 1# 2. Left Join 2# example 3SELECT c.id AS id, c.name, o.id AS oid 4FROM customers AS c LEFT JOIN orders AS o 5on c.id = o.customerId 6 7SELECT `name` as `Customers` 8FROM customers AS c LEFT JOIN orders AS o 9on c.id = o.customerId 10WHERE o.id is NULL 计算特殊奖金 编写解决方案，计算每个雇员的奖金。如果一个雇员的 id 是 奇数 并且他的名字不是以 'M' 开头，那么他的奖金是他工资的 100% ，否则奖金为 0 。\n返回的结果按照 employee_id 排序。\nIF用法 IF(condition, True, False) AS alias\n1select `employee_id`, IF(name not like \u0026#39;M%\u0026#39; and employee_id%2 = 1, salary, 0) AS `bonus` 2from Employees 3Order by employee_id ASC 购买了产品 A 和产品 B 却没有购买产品 C 的顾客 Where 中 多重 判断\n1select customer_id, customer_name 2from Customers as c 3where exists ( 4 select o.customer_id 5 from Orders as o 6 where o.customer_id=c.customer_id and product_name = \u0026#39;A\u0026#39; 7) and exists ( 8 select o.customer_id 9 from Orders as o 10 where o.customer_id=c.customer_id and product_name = \u0026#39;B\u0026#39; 11) and not exists ( 12 select o.customer_id 13 from Orders as o 14 where o.customer_id=c.customer_id and product_name = \u0026#39;C\u0026#39; 15) 16Order By c.customer_id ASC 连表，分组判断\n1SELECT c.customer_id, c.customer_name 2FROM `Orders` as o left join `Customers` as c 3on o.customer_id = c.customer_id 4Group By o.customer_id 5HAVING SUM(product_name = \u0026#39;A\u0026#39;) \u0026gt; 0 and SUM(product_name = \u0026#39;B\u0026#39;) \u0026gt; 0 and SUM(product_name = \u0026#39;C\u0026#39;) = 0 6Order By c.customer_id ASC 1[o.id, o.customerId, o.product_name, c.customerId, c.name] 2 1 1 \u0026#39;A\u0026#39; 1 X 3 2 1 \u0026#39;B\u0026#39; 1 X 4 3 2 \u0026#39;A\u0026#39; 2 Y 5 4 2 \u0026#39;B\u0026#39; 2 Y 6 5 2 \u0026#39;C\u0026#39; 2 Y 7 8 Group By c.customerId 9 1 1 \u0026#39;A\u0026#39; 1 X 10 2 1 \u0026#39;B\u0026#39; 1 X 11 12 3 2 \u0026#39;A\u0026#39; 2 Y 13 4 2 \u0026#39;B\u0026#39; 2 Y 14 5 2 \u0026#39;C\u0026#39; 2 Y 15 16 SUM(express condition) ? condition # 对于String是统计条数 每位学生成绩最好的科目 所有有相同科目成绩一样，选择科目id小的\n1+---------------+---------+ 2| Column Name | Type | 3+---------------+---------+ 4| student_id | int | 5| course_id | int | 6| grade | int | 7+---------------+---------+ # 1\n1# 查某学生成绩最好的那些科目，因为可能有重复的 2SELECT student_id, MAX(grade) AS grade 3From Enrollments 4Group By student_id # 2\n1# 查某学生最好的那些科目中 courseId最小的 2SELECT student_id, MIN(courseId) AS course_id, grade 3From Enrollments 4# 行 =\u0026gt; 最好的那些科目 5Where (student_id, grade) in ( 6\tSELECT student_id, MAX(grade) AS grade 7\tFrom Enrollments 8\tGroup By student_id 9) 10Group By student_id 11Order By student_id ASC 连接 Left Join\n拓展左边，即使右表某些行不存在（会出现重复行）\n=\u0026gt; **Right Join **同理\n1SELECT * 2FROM `customers` as c 3LEFT JOIN orders as o 4ON c.id = o.customerId Inner Join =\u0026gt; 只展示左右表均成功对接上的行\n没有卖出的商家 写一个解决方案, 报告所有在 2020 年度没有任何卖出的卖家的名字。\n返回结果按照 seller_name 升序排列。\n1SELECT seller_name 2FROM Seller 3WHERE seller_id not in ( 4 SELECT DISTINCT Orders.seller_id 5 FROM Orders 6 WHERE Orders.sale_date like \u0026#39;2020%\u0026#39; 7) 8ORDER By seller_name ASC 排名靠前的旅行者 返回的结果表单，以 travelled_distance 降序排列 ，如果有两个或者更多的用户旅行了相同的距离, 那么再以 name 升序排列 。\n1SELECT name, COALESCE(SUM(distance), 0) AS travelled_distance 2From Users Left join Rides 3On Rides.user_id = Users.id 4Group By Rides.user_id 5ORDER BY travelled_distance DESC, name ASC; # 使用别名排序 607. 销售员 编写解决方案，找出没有任何与名为 “RED” 的公司相关的订单的所有销售人员的姓名。\n1SELECT name 2FROM SalesPerson 3WHERE sales_id not in ( 4 SELECT DISTINCT Orders.sales_id 5 FROM Orders LEFT JOIN Company 6 ON Orders.com_id = Company.com_id 7 WHERE name = \u0026#39;RED\u0026#39; 8) 计算布尔表达式的值 输入：\rVariables 表:\r+------+-------+\r| name | value |\r+------+-------+\r| x | 66 |\r| y | 77 |\r+------+-------+\rExpressions 表:\r+--------------+----------+---------------+\r| left_operand | operator | right_operand |\r+--------------+----------+---------------+\r| x | \u0026gt; | y |\r| x | \u0026lt; | y |\r| x | = | y |\r| y | \u0026gt; | x |\r| y | \u0026lt; | x |\r| x | = | x |\r+--------------+----------+---------------+\r输出:\r+--------------+----------+---------------+-------+\r| left_operand | operator | right_operand | value |\r+--------------+----------+---------------+-------+\r| x | \u0026gt; | y | false |\r| x | \u0026lt; | y | true |\r| x | = | y | false |\r| y | \u0026gt; | x | true |\r| y | \u0026lt; | x | false |\r| x | = | x | true |\r+--------------+----------+---------------+-------+ 1SELECT e.left_operand, e.operator, e.right_operand, 2CASE e.operator 3 WHEN \u0026#39;\u0026gt;\u0026#39; THEN IF(v1.value\u0026gt;v2.value, \u0026#39;true\u0026#39;, \u0026#39;false\u0026#39;) 4 WHEN \u0026#39;\u0026lt;\u0026#39; THEN IF(v1.value\u0026lt;v2.value, \u0026#39;true\u0026#39;, \u0026#39;false\u0026#39;) 5 ELSE IF(v1.value=v2.value, \u0026#39;true\u0026#39;, \u0026#39;false\u0026#39;) 6END value 7 8FROM Expressions e 9LEFT JOIN Variables v1 ON e.left_operand = v1.name 10LEFT JOIN Variables v2 ON e.right_operand = v2.name 考点：多重连表 e.(\u0026hellip;)v1.(\u0026hellip;)v2.(\u0026hellip;)\n条件判断表达式\ncase [sign]\n​\twhen exp then result[if(exp, true, false)]\n​\twhen exp then result\n​\telse result\nend\n查询球队积分 分别查询主队得分和客队得分。再进行汇总统计\nIFNULL(SUM(num_points), 0) # IFNULL(Origin, NULL-value)\n1SELECT t.team_id, t.team_name, IFNULL(SUM(num_points), 0) as num_points 2FROM Teams AS t 3LEFT JOIN ( 4 SELECT host_team AS team_id, 5 CASE 6 WHEN host_goals \u0026gt; guest_goals THEN 3 7 WHEN host_goals = guest_goals THEN 1 8 END AS num_points 9 FROM Matches 10 UNION ALL 11 SELECT guest_team AS team_id, 12 CASE 13 WHEN guest_goals \u0026gt; host_goals THEN 3 14 WHEN host_goals = guest_goals THEN 1 15 END AS num_points 16 FROM Matches 17) AS m ON t.team_id = m.team_id 18Group By t.team_id 19Order BY num_points DESC, t.team_id ASC # 1. LEFT JOIN 将相关的右表补充至左表 ！若1vN则产生重复记录(聚合该记录)\n# 2. UNION(ALL) 两张表需字段相同，上下拼接为一张表，ALL则保留重复记录\n# 3. case 空条件\n​\twhen ? then x\n​\t\u0026hellip;\n​\tELSE y\n​\tend\n聚合函数 2020最后一次登录 1SELECT MAX(Feild) # \u0026lt;= 只要组内最大的记录 2\tMin(Feild) # \u0026lt;= 只要组内最小的记录 3... 4 5Group By 仓库经理 1SELECT Warehouse.name AS warehouse_name, 2SUM(units*Products.Width*Products.Length*Products.Height) AS volume # 聚合组内数据 3FROM Warehouse 4LEFT JOIN Products ON Warehouse.product_id = Products.product_id # 补齐信息 5Group By Warehouse.name # 分组 订单最多的客户 1SELECT customer_number 2FROM Orders 3GROUP BY customer_number 4ORDER BY COUNT(*) DESC # 对组进行排序 5LIMIT 1 # Top位置 6 7 8SELECT o.customer_number 9FROM ( 10\tSELECT customer_number, COUNT(*) AS count_number 11\tFROM Orders 12\tGROUP BY customer_number 13) o 14ORDER BY o.count_number DESC 15LIMIT 1 查找每个员工花费的总时间 多次分组 \u0026amp; 聚合\n1SELECT `day`, emp_id, SUM(out_time-in_time) 2FROM Employees 3GROUP BY emp_id, event_day 及时食物配送 考点：计算公式\n#1 ROUND(X*100, 2) 33.33\n#2 SUM(IF(X, 1, 0)) / COUNT(ID)\n按列操作\n1SELECT ROUND((SUM(IF(order_date = customer_pref_delivery_date, 1, 0)))/COUNT(delivery_id)*100, 2) AS immediate_percentage 2FROM Delivery 苹果和桔子 1SELECT sale_date, 2(SUM(IF(fruit=\u0026#39;apples\u0026#39;, sold_num, 0)) - SUM(IF(fruit=\u0026#39;oranges\u0026#39;, sold_num, 0))) AS diff 3FROM Sales 4Group By sale_date ⭐ 分别聚合组内不同条件的记录\n两个人的通话记录 考点，多次分组进行聚合统计。\n题干中，呼叫与接收不分。\n1SELECT from_id AS person1, to_id AS person2, COUNT(*) AS call_count,SUM(duration) AS total_duration 2 3FROM ( 4 5 SELECT IF(from_id \u0026lt; to_id, from_id, to_id) AS from_id, IF(from_id \u0026lt; to_id, to_id, from_id) AS to_id, duration 6 7 FROM Calls 8 9) AS c 10 11Group BY from_id, to_id 排序和分组 银行账户概要 II 编写解决方案, 报告余额高于 10000 的所有用户的名字和余额. 账户的余额等于包含该账户的所有交易的总和\n1SELECT name, balance 2FROM Users 3LEFT JOIN ( 4 SELECT account, SUM(amount) AS balance 5 FROM Transactions 6 Group BY account) AS trans On Users.account = trans.account 7Where balance \u0026gt; 10000 查找重复的电子邮箱 编写解决方案来报告所有重复的电子邮件\n1SELECT email AS Email 2FROM Person 3Group By email 4HAVING count(*) \u0026gt; 1 合作过至少三次的演员和导演 编写解决方案找出合作过至少三次的演员和导演的 id 对 (actor_id, director_id)\n1SELECT actor_id, director_id 2FROM ActorDirector 3GROUP BY actor_id, director_id 4HAVING COUNT(*) \u0026gt;= 3 消费者下单频率\n67月，每个月均消费至少100的用户\n1SELECT o.customer_id, name 2FROM () AS o 3LEFT JOIN Customers ON o.customer_id = Customers.customer_id 4 5 6# 其中 7SELECT customer_id, order_date, (quantity*price) AS cost 8FROM Orders 9LEFT JOIN Product ON Orders.product_id = Product.product_id 10WHERE month(order_date) in (6,7) 11Group BY customer_id 12HAVING SUM(IF(month(order_date) = 6, cost, 0)) \u0026gt;= 100 and 13 SUM(IF(month(order_date) = 7, cost, 0)) \u0026gt;= 100 可以放心投资的国家 分步实现：\n1️⃣ 将呼叫\\接听联合\n2️⃣ 将对应人员及其国家准备好\n3️⃣ 再次连接，并按国家分组且聚合(HAVING进行条件筛选)\n1SELECT name as country 2FROM 3( 4 SELECT caller_id AS call_id, duration FROM Calls 5 UNION ALL 6 SELECT callee_id AS call_id, duration FROM Calls 7) a 8LEFT JOIN 9( 10 SELECT id, Country.name 11 FROM Person 12 LEFT JOIN Country on SUBSTR(phone_number, 1, 3) = country_code 13) b 14ON a.call_id = b.id 15Group BY name 16HAVING AVG(duration) \u0026gt; (SELECT AVG(duration) FROM Calls) 高级查询和连接 HAVING 子句用来对 聚合结果 进行过滤，而 HAVING 子句无法直接使用非聚合列\n页面推荐 编写解决方案，向user_id = 1 的用户，推荐其朋友们喜欢的页面。不要推荐该用户已经喜欢的页面。\n先find他的所有朋友。 他-\u0026gt;朋友 and 朋友 -\u0026gt;\n1SELECT DISTINCT page_id as recommended_page 2FROM (SELECT user2_id as user_id 3 FROM Friendship 4 WHERE user1_id = 1 5 UNION 6 SELECT user1_id as user_id 7 FROM Friendship 8 WHERE user2_id = 1) AS fs 9LEFT JOIN Likes ls ON fs.user_id = ls.user_id 10WHERE page_id not in ( 11 SELECT page_id 12 FROM Likes 13 WHERE user_id = 1 14) 15ORDER BY recommended_page ASC 树节点 CASE \u0026hellip; END 按列来，每次处理列的一个元素\n1SELECT id AS `id`, 2CASE 3 WHEN id = 1 THEN \u0026#34;Root\u0026#34; 4 WHEN id in (SELECT atree.p_id FROM tree atree) THEN \u0026#34;Inner\u0026#34; 5 ELSE \u0026#34;Leaf\u0026#34; 6END AS type 7FROM Tree 游戏玩法分析 III 编写一个解决方案，同时报告每组玩家和日期，以及玩家到 目前为止 玩了多少游戏。也就是说，玩家在该日期之前所玩的游戏总数。详细情况请查看示例。\n利用笛卡尔积， 自己跟自己所有的记录进行连接。暴力遍历\n1SELECT a1.player_id, a1.event_date, SUM(a2.games_played) AS games_played_so_far 2FROM Activity a1, Activity a2 # 笛卡儿积，o(n) x o(n) = o(n^2) 条纪录 3WHERE a1.player_id = a2.player_id and a1.event_date \u0026gt;= a2.event_date # 只要自己和自己进行连接的记录 4GROUP BY a1.player_id, a1.event_date 大满贯数量 编写解决方案，找出每一个球员赢得大满贯比赛的次数。结果不包含没有赢得比赛的球员的ID 。\n思路： 行 -\u0026gt; 列 再聚合\nPlayers 表：\r+-----------+-------------+\r| player_id | player_name |\r+-----------+-------------+\r| 1 | Nadal |\r| 2 | Federer |\r| 3 | Novak |\r+-----------+-------------+\rChampionships 表：\r+------+-----------+---------+---------+---------+\r| year | Wimbledon | Fr_open | US_open | Au_open |\r+------+-----------+---------+---------+---------+\r| 2018 | 1 | 1 | 1 | 1 |\r| 2019 | 1 | 1 | 2 | 2 |\r| 2020 | 2 | 1 | 2 | 2 |\r+------+-----------+---------+---------+---------+\r输出：\r+-----------+-------------+-------------------+\r| player_id | player_name | grand_slams_count |\r+-----------+-------------+-------------------+\r| 2 | Federer | 5 |\r| 1 | Nadal | 7 |\r+-----------+-------------+-------------------+ 1SELECT res.player_id, ps.player_name, res.grand_slams_count 2FROM ( 3 SELECT player_id, COUNT(*) AS grand_slams_count 4 FROM ( 5 SELECT Wimbledon player_id 6 FROM Championships 7 UNION ALL 8 SELECT Fr_open player_id 9 FROM Championships 10 UNION ALL 11 SELECT US_open player_id 12 FROM Championships 13 UNION ALL 14 SELECT Au_open player_id 15 FROM Championships 16 ) AS rec 17 GROUP BY rec.player_id 18) AS res 19LEFT JOIN Players AS ps ON res.player_id = ps.player_id 应该被禁止的 Leetflex 账户 编写解决方案，查找那些应该被禁止的Leetflex帐户编号 account_id 。 如果某个帐户在某一时刻从两个不同的网络地址登录了，则这个帐户应该被禁止。\nLogInfo table:\r+------------+------------+---------------------+---------------------+\r| account_id | ip_address | login | logout |\r+------------+------------+---------------------+---------------------+\r| 1 | 1 | 2021-02-01 09:00:00 | 2021-02-01 09:30:00 |\r| 1 | 2 | 2021-02-01 08:00:00 | 2021-02-01 11:30:00 |\r| 2 | 6 | 2021-02-01 20:30:00 | 2021-02-01 22:00:00 |\r| 2 | 7 | 2021-02-02 20:30:00 | 2021-02-02 22:00:00 |\r| 3 | 9 | 2021-02-01 16:00:00 | 2021-02-01 16:59:59 |\r| 3 | 13 | 2021-02-01 17:00:00 | 2021-02-01 17:59:59 |\r| 4 | 10 | 2021-02-01 16:00:00 | 2021-02-01 17:00:00 |\r| 4 | 11 | 2021-02-01 17:00:00 | 2021-02-01 17:59:59 |\r+------------+------------+---------------------+---------------------+ 1AND ((a.login between b.login and b.logout) OR (a.logout between b.login and b.logout)) GROUP BY 分组\nHAVING 作用于组，挑选指定的组\n子查询 各部门最高收入的员工 (可能有多个) 1SELECT d.name AS Department, e1.name AS Employee, e1.salary AS Salary 2FROM Employee e1 3LEFT JOIN Department d ON e1.departmentId = d.id 4WHERE e1.salary = ( 5 SELECT MAX(salary) 6 FROM Employee e2 7 GROUP BY e2.departmentId 8 HAVING e2.departmentId = e1.departmentId 9) 效率不高！！！\n优化：\n1SELECT d.name AS Department, e1.name AS Employee, e1.salary AS Salary 2FROM Employee e1 3LEFT JOIN Department d ON e1.departmentId = d.id 4WHERE (e1.departmentId,e1.salary) in ( 5 SELECT e2.departmentId, MAX(salary) 6 FROM Employee e2 7 GROUP BY e2.departmentId 8) 生成临时表（避免子查询 重复的执行）\n1WITH MaxSalaries AS ( 2 SELECT departmentId, MAX(salary) AS max_salary 3 FROM Employee 4 GROUP BY departmentId 5) 每件商品的最新订单 可能有多个\n1With LatestDate AS ( 2 SELECT product_id, MAX(order_date) AS order_date 3 FROM Orders 4 GROUP BY product_id 5) 6 7 8SELECT p.product_name, o.product_id, o.order_id, o.order_date 9FROM Orders AS o 10LEFT JOIN LatestDate AS ld ON o.product_id = ld.product_id 11LEFT JOIN Products AS p ON o.product_id = p.product_id 12WHERE o.order_date = ld.order_date 13ORDER BY p.product_name ASC, o.product_id ASC, o.order_id ASC 最近的三笔订单 学习， 可分组打index标记，标记按照ORDER顺序\n1ROW_NUMBER() OVER ( 2\tPARTITION BY ? 3 ORDER BY ? 4) 1WITH ORDER_INFO AS ( 2 SELECT c.name, c.customer_id, o.order_id, o.order_date, 3 ROW_NUMBER() OVER ( 4 PARTITION BY o.customer_id 5 ORDER BY o.order_date DESC 6 ) AS row_num 7 FROM Orders AS o 8 LEFT JOIN Customers AS c ON o.customer_id = c.customer_id 9) 10 11SELECT name AS customer_name, customer_id, order_id, order_date 12FROM ORDER_INFO AS o 13WHERE o.row_num \u0026lt;= 3 14ORDER BY customer_name ASC, customer_id ASC, order_date DESC 先生成临时表，避免重复生成子查询\n每天的最大金额 先筛选出每天的最大金额，再执行后续的判断\n1WITH MAX_AMOUNT AS ( 2 SELECT DATE(`day`) AS `day`, MAX(amount) max_amount 3 FROM Transactions AS t 4 GROUP BY DATE(`day`) 5) 6 7 8SELECT transaction_id 9FROM Transactions AS t 10LEFT JOIN MAX_AMOUNT AS ma ON DATE(t.day) = ma.day 11WHERE (DATE(t.day), t.amount) = (ma.day, ma.max_amount) 12ORDER BY transaction_id ASC 直接给每天的 订单，按照金额， 打index标记\n❗ RANK 相同值会获得相同的排名\n1RANK() OVER ( 2) 而 ROW_NUMBER，idx严格递增\n1WITH Temp AS ( 2 SELECT transaction_id, `day`, amount, 3 rank() OVER ( 4 PARTITION BY DATE(`day`) 5 ORDER BY amount DESC 6 ) AS idx 7 FROM Transactions AS t 8) 9 10SELECT transaction_id 11FROM Temp as t 12WHERE idx = 1 13ORDER BY transaction_id ASC 窗口函数和公共表表达式 项目员工 III 找出每个项目 经验最丰富的员工(可能有多个)\n直接1. 分项目 2. 项目内按经验程度进行RANK 3. 再筛选\n1WITH Temp AS ( 2 SELECT p.project_id, p.employee_id, 3 RANK() OVER ( 4 PARTITION BY p.project_id 5 ORDER BY e.experience_years DESC 6 ) AS idx 7 FROM Project AS p 8 LEFT JOIN Employee as e ON p.employee_id = e.employee_id 9) 10 11 12SELECT project_id, employee_id 13FROM Temp 14WHERE idx = 1 每位顾客最经常订购的商品 主SQL GROUP BY 之后，与 RANK() 的操作\n1SELECT 2 customer_id, 3 product_id, 4 COUNT(*) AS order_count, 5 RANK() OVER (ORDER BY COUNT(*) DESC) AS RK 6FROM Orders 7GROUP BY customer_id, product_id; 结果：\n添加 PARTITION BY customer_id 进行隔离\n1SELECT 2 customer_id, 3 product_id, 4 COUNT(*) AS order_count, 5 RANK() OVER (PARTITION BY customer_id ORDER BY COUNT(*) DESC) AS RK 6FROM Orders 7GROUP BY customer_id, product_id; 结果：\n=\u0026gt; 结论。 1. 先执行主SQL的GROUP BY，进行分区，再RANK(), RANK()按照 ORDER BY(必须聚合为单行)进行排序， 利用PARTITION进行排序隔离。\n答案\n1WITH Temp AS ( 2 SELECT 3 customer_id, 4 product_id, 5 COUNT(*) AS order_count, 6 RANK() OVER (PARTITION BY customer_id ORDER BY COUNT(*) DESC) AS RK 7 FROM Orders 8 GROUP BY customer_id, product_id 9) 10 11SELECT t.customer_id, t.product_id, p.product_name 12FROM Temp AS t 13LEFT JOIN Products AS p ON t.product_id = p.product_id 14WHERE RK = 1 # 最高的 NO.1 访问日期之间最大的空档期 LEAD(column, offset, defualt) OVER (PARTITION BY \u0026hellip; ORDER BY \u0026hellip;) 找后面的行。其中LEAD表示引领。\nLAG(\u0026hellip;) 找前面的行， 滞后\n1SELECT user_id, MAX(DATEDIFF(after_day, visit_date)) AS biggest_window 2FROM ( 3 SELECT user_id, visit_date, 4 LEAD(visit_date, 1, \u0026#39;2021-1-1\u0026#39;) OVER (PARTITION BY user_id ORDER BY visit_date ASC) AS after_day 5 FROM UserVisits AS uv 6) AS t 7GROUP BY user_id 考点：行之间的差值\nCTE Common Table Expression\n向公司 CEO 汇报工作的所有人 查询树状结构节点 列转行\n依次暴力枚举\n1SELECT employee_id 2FROM ( 3 SELECT employee_id 4 FROM Employees 5 WHERE manager_id = 1 and employee_id != 1 6 UNION 7 SELECT employee_id 8 FROM Employees 9 WHERE manager_id in ( 10 SELECT employee_id 11 FROM (SELECT employee_id 12 FROM Employees 13 WHERE manager_id = 1 and employee_id != 1) AS e1 14 ) 15 UNION 16 SELECT employee_id 17 FROM Employees 18 WHERE manager_id in ( 19 SELECT employee_id 20 FROM (SELECT employee_id 21 FROM Employees 22 WHERE manager_id in ( 23 SELECT employee_id 24 FROM (SELECT employee_id 25 FROM Employees 26 WHERE manager_id = 1 and employee_id != 1) AS e2 27 )) e3 28 ) 29) AS e 太低效了！！！ SB操作，疯狂连续查询\n优化\n1SELECT employee_id 2FROM ( 3 SELECT employee_id 4 FROM Employees 5 WHERE manager_id = 1 and employee_id != 1 # ✔️ 6 UNION 7 8 SELECT employee_id 9 FROM Employees 10 WHERE manager_id in ( 11 SELECT employee_id 12 FROM Employees 13 WHERE manager_id = 1 and employee_id != 1 14 ) 15 UNION 16 17 SELECT employee_id 18 FROM Employees 19 WHERE manager_id in ( 20 SELECT employee_id 21 FROM Employees 22 WHERE manager_id in ( 23 SELECT employee_id 24 FROM Employees 25 WHERE manager_id = 1 and employee_id != 1 26 ) 27 ) 28) AS e 利用连接来计算\n1SELECT DISTINCT e4.employee_id 2FROM Employees e1 3LEFT JOIN Employees e2 ON e1.employee_id = e2.manager_id 4LEFT JOIN Employees e3 ON e2.employee_id = e3.manager_id 5LEFT JOIN Employees e4 ON e3.employee_id = e4.manager_id 6WHERE e1.employee_id = 1 and e4.employee_id != 1 11 Boss =\u0026gt; { 2 1 Boss =\u0026gt; { 3 1 Boss =\u0026gt; { 4 1 Boss 5 2 Bob 6 77 Robert 7 } 8 2 Bob =\u0026gt; 4 Daniel 9 77 Robert =\u0026gt; null 10 } 11 2 Bob =\u0026gt; 4 Daniel =\u0026gt; null 12 77 Robert =\u0026gt; null =\u0026gt; null 13} 寻找连续区间的开始和结束位置 思路：\n1data: 1,2,3,7,8,10 2idx : 1,2,3,4,5, 6 3diff: 0,0,0,3,3, 4 \u0026lt;= GROUP BY diff =\u0026gt; MIN(idx) AS Start_ID, MAX(idx) AS End_ID 1WITH Temp AS ( 2 SELECT log_id, 3 ROW_NUMBER() OVER (ORDER BY log_id ASC) AS idx 4 FROM Logs 5) 6 7SELECT MIN(log_id) AS start_id, MAX(log_id) AS end_id 8FROM ( 9 SELECT log_id, (log_id-idx ) AS diff 10 FROM Temp 11) AS t 12GROUP BY diff 查找处于成绩中游的学生 参加的考试，没有一科是最高分或者最低分。科科中等\n逻辑： 1. 判断每一科，再统计所有科目\n1WITH MAXMIN AS ( 2 SELECT exam_id, MIN(score) min_score, MAX(score) max_score 3 FROM Exam 4 GROUP BY exam_id 5) 6 7 8SELECT s.student_id, s.student_name 9FROM ( 10 SELECT e.exam_id, e.student_id, 11 CASE 12 WHEN score != min_score and score != max_score THEN 1 13 ELSE 0 14 END AS is_medium 15 FROM Exam AS e 16 LEFT JOIN MAXMIN m ON e.exam_id = m.exam_id 17) AS t 18LEFT JOIN Student AS s ON t.student_id = s.student_id 19GROUP BY t.student_id 20HAVING SUM(t.is_medium) = COUNT(t.is_medium) 21ORDER BY student_id ASC 反过来： 将尖子生和垫底生排除在外即可\n寻找没有被执行的任务对 1with recursive all_subtask(task_id, subtask_id) as ( 2 SELECT task_id, subtasks_count 3\tFROM Tasks 4 UNION ALL 5\t6 SELECT task_id, subtask_id-1 7\tFROM all_subtask 8\twhere subtask_id-1 \u0026gt; 0 9) 10 11 12SELECT task_id, subtask_id 13From all_subtask 14WHERE (task_id, subtask_id) not in (SELECT task_id, subtask_id FROM Executed) 1with recursive TableName(param1, param2) AS ( 2\tSELECT param1, param2 // 基础结果 3\tFROM BaseTable 4 UNION ALL 5 // 下面式子会被重复递归 6 SELECT param1, param2-1 // 新的结果 7 FROM TableName // 上一轮的结果 8 where param2-1 \u0026gt; 0 // 递归终止条件 9) ","permalink":"http://121.40.252.207/posts/leetcode/leetcode_sql/","summary":"\u003ch2 id=\"高频sql50题\"\u003e高频SQL50题\u003c/h2\u003e\n\u003ch3 id=\"查询\"\u003e查询\u003c/h3\u003e\n\u003ch4 id=\"wheregroupbyhaving\"\u003eWhere\u0026amp;GroupBy\u0026amp;HAVING\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-mysql\" data-lang=\"mysql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erevenue\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e# 某个用户2021年可能有多项记录\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eusers\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eWhere\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eyear\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e2021\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eSUM\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erevenue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eusers\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eWhere\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eyear\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e2021\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e# 1. 先筛选出此年份所有记录\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eGroup\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eBy\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"c1\"\u003e# 2. 再根据id分组 3. 必须结合SUM() 或者其他聚合函数，因此这个有多列，需要处理为单值。\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 9\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e10\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e11\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eusers\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e12\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eWhere\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eyear\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e2021\u003c/span\u003e\u003cspan class=\"w\"\u003e          \u003c/span\u003e\u003cspan class=\"c1\"\u003e# 1. 先筛选记录\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e13\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eGroup\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eBy\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e                \u003c/span\u003e\u003cspan class=\"c1\"\u003e# 2. 分组\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e14\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eHAVING\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eSUM\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erevenue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e#  3. 聚合分组字段记录 并 判断\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"查找没买过东西的顾客\"\u003e查找没买过东西的顾客\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-mysql\" data-lang=\"mysql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 1. NOT EXISTS\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eCustomers\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eCustomers\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eWHERE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eEXISTS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ecustomerId\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eOrders\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eWhere\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecustomerId\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cimg src=\"http://sthda9dn6.hd-bkt.clouddn.com/FlT4eqfOPSYMmcNCB5mh_bpamx5B\" alt=\"Image\" style=\"float:left; margin-right: 10px;\" /\u003e\r\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-mysql\" data-lang=\"mysql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 2. Left Join \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# example\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eoid\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecustomers\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eLEFT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eJOIN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eorders\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eon\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecustomerId\u003c/span\u003e\u003cspan class=\"w\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eas\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eCustomers\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecustomers\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eLEFT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eJOIN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eorders\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 9\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eon\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecustomerId\u003c/span\u003e\u003cspan class=\"w\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e10\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eWHERE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eo\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eis\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"计算特殊奖金\"\u003e\u003ca href=\"https://leetcode.cn/problems/calculate-special-bonus/\"\u003e计算特殊奖金\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003e编写解决方案，计算每个雇员的奖金。如果一个雇员的 id 是 \u003cstrong\u003e奇数\u003c/strong\u003e 并且他的名字不是以 \u003ccode\u003e'M'\u003c/code\u003e \u003cstrong\u003e开头\u003c/strong\u003e，那么他的奖金是他工资的 \u003ccode\u003e100%\u003c/code\u003e ，否则奖金为 \u003ccode\u003e0\u003c/code\u003e 。\u003c/p\u003e","title":"高频SQL50题刷题笔记"},{"content":"minGPT author: karpathy Andrej\nwork flow\n1String: [\u0026#39;X1\u0026#39;, \u0026#39;X2\u0026#39;, ..., \u0026#39;Xn\u0026#39;] =[dictionary]=\u0026gt; [k1, k2, ..., kn] # word2index 2 3# Train: 4X = [X1, X2, X3, Y1, Y2], Y = [-1, -1, Y1, Y2, Y3] 5Model = {(WordEmbed+PosEmbed) =\u0026gt; (CausalSelfAttention+FFN)xN =\u0026gt; (ClassHead)} 6# attn = A B C 7# A √ × × uni-directional 8# B √ √ × 9# C √ √ √ 10 11Z = Model(X) =\u0026gt; [Z1, Z2, Z3, Z4, Z5] 12Y = [-1, -1, Y1, Y2, Y3] 13# Equal to Parallel Train 14(X1,X2,X3) =predict=\u0026gt; Y1 15(X1,X2,X3,Y1) =predict=\u0026gt; Y2 16(X1,X2,X3,Y1,Y2) =predict=\u0026gt; Y3 17 18loss = crossentropy(Z, Y, ignore=-1) # Zi =\u0026gt; {P1,...,Pclass} multi-class task 19 20# Test: Serial generation 21give inp = [X1, X2, X3] 22Step 1: 23 Z = Model(inp) = [Z1,Z2,Z3] 24 Y = [-1,-1,Y1] 25 inp = inp + Y[-1] = [Z1,Z2,Z3,Y1] 26Step 2: 27 Z = Model(inp) = [Z1,Z2,Z3,Z4] 28 Y = [-1,-1,-1,Y2] 29 inp = inp + Y[-1] = [Z1,Z2,Z3,Y1,Y2] 30Step 3: 31 Z = Model(inp) = [Z1,Z2,Z3,Z4,Z5] 32 Y = [-1,-1,-1,-1,Y3] 33 inp = inp + Y[-1] = [Z1,Z2,Z3,Y1,Y2,Y3] 34 35out: [Z1,Z2,Z3,Y1,Y2,Y3] minBert work flow\npre-trainning\n1# Data preparation 2data = [{\u0026#34;S1\u0026#34;, \u0026#34;S2\u0026#34;, ..., \u0026#34;Sn\u0026#34;}, [{k1, k2, ..., kn}, 3 {\u0026#34;S1\u0026#34;, \u0026#34;S2\u0026#34;, ..., \u0026#34;Sn\u0026#34;}, =vocabulary=\u0026gt; [{k1, k2, ..., kn}, 4 {\u0026#34;S1\u0026#34;, \u0026#34;S2\u0026#34;, ..., \u0026#34;Sn\u0026#34;}] [{k1, k2, ..., kn}, 5 6# Mask-Word \u0026amp; Predict isNext 7while positive != batch_size / 2 or negative != batch_size / 2: # isNext,notIsNext sample number is equality 8\trandom-sentence-A, random-sentence-B =\u0026gt; tokens_a, tokens_b 9 input_ids = [word_dict[\u0026#39;CLS\u0026#39;]] + tokens_a + [word_dict[\u0026#39;SEP\u0026#39;]] + tokens_b + [word_dict[\u0026#39;SEP\u0026#39;]] 10 seg_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1) 11 12 # fixed input length =\u0026gt; padding [\u0026#39;Pad\u0026#39;] 13 input_ids extend [word_dict[\u0026#39;Pad\u0026#39;]] * num_pad 14 seg_ids extend [0] * num_pad 15 16 =\u0026gt; masked_pos, masked_tokens 17 =\u0026gt; isNext 18=\u0026gt; [{input_ids,seg_ids,masked_pos,masked_tokens,isNext}, 19 {...}...] 20 21attn_pad_mask = [0,..,0,1,..,1] 22 23Bert = {(Token_embed+Pos_embed+Seg_embed) =\u0026gt; {MHSA[attn_pad_mask]=\u0026gt;FFN}xN 24 =\u0026gt; {head1(dim_token-\u0026gt;2)-o1:isNext, head2(dim_token-\u0026gt;vocab_len)-o2:predict_masked_word}} 25# attn = A B P P-\u0026gt;Padding 26# A √ √ × bi-directional 27# B √ √ × 28# P √ √ × 29 30loss1 = CrossEntropyLoss(o1,isNext) 31loss2 = CrossEntropyLoss(o2,masked_tokens) fine-tuning\ninput: [CLS] + Token-A + [SEP], get [CLS] # 单独 input: [CLS] + Token-A + [SEP] + Token-B + [SEP], get =\u0026gt; [SEP] + Token-B + [SEP] # 关联关系 minUnet work flow\n1# Model U-shape feature-flow 2input =\u0026gt; [Enc1] =\u0026gt; [Dec6] =\u0026gt; output # Pixel-Level semantic token =\u0026gt; binary classification 3 [Enc2] =\u0026gt; [Dec5] 4 [Enc3] =\u0026gt; [Dec4] 1# Training: 2for data in dataloader: 3 inp, mask = data 4 oup = model(inp) 5 6 loss = BCELoss(oup, inp) 7 ... minYolo 1X:(1,3,H,W) =\u0026gt; Model =\u0026gt; Y:(K,K,B*5+C) 2 3[k1,k2,k3] 4[k4,k5,k6] =\u0026gt; [X,Y,W,H,Confidence,C1,...,Cn] 5[k7,k8,k9] 6 7# Inference (x, y) (w, h) confidence prob-class[0,...,79]{80-category} 8# Step 1 9conf_mask = (prediction[:, :, 4] \u0026gt; confidence).float().unsqueeze(2) # 根据confidence判断该锚框是否存在对象 10prediction = prediction * conf_mask 11# Step 2 12# 处理x,y,w,h =\u0026gt; (x1,y1,x2,y2) 13 14# 若B\u0026gt;1: =\u0026gt; 重塑为 (KK+N,5+C) 15 16# 整理成 [X1,Y1,X2,Y2,idx_class,class_score] \u0026lt;= 存在对象 17 18# 进行NMS非极大值抑制 19for img : per_img: 20 # 根据 class_score 排序 21 # 计算当前预测框与后续预测框的IoU 22 # 根据 iou ? nms_conf 进行去除冗余的框 23 24锚框数据：[X1,Y1,X2,Y2,idx_class,class_score] 25 26 27# Inference 28label: [[idx_class,x,y,w,h],[...]] =\u0026gt; [[X,Y,W,H,Confidence,C1,...,Cn],[...]] 29# Yolo-v1: 将锚框均匀的等分为7×7的Cell 30 31X:(1,3,H,W) =\u0026gt; Model =\u0026gt; P:(K,K,5+C) Y:(K,K,5+C) 32 33# Loss 34分三步： 351. 锚框Loss : x,y and w,h 362. Confidence-Loss: obj and noobj 373. class-loss: Ci 38 39# 具体做法就是 401. 按照Confidence\u0026gt;0.5 =\u0026gt; 是否存在对象 412. 收集所需要的Cell =\u0026gt; 分别计算Loss ","permalink":"http://121.40.252.207/posts/learning/minibaseline_learning/","summary":"\u003ch3 id=\"mingpt\"\u003eminGPT\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eauthor: karpathy Andrej\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ework flow\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 1\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;X1\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;X2\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e...\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Xn\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edictionary\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ek1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ek2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e...\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ekn\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# word2index\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 2\u003c/span\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 3\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Train:    \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 4\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eX1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eX2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eX3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 5\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eModel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{(\u003c/span\u003e\u003cspan class=\"n\"\u003eWordEmbed\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ePosEmbed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eCausalSelfAttention\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003eFFN\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"n\"\u003exN\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eClassHead\u003c/span\u003e\u003cspan class=\"p\"\u003e)}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 6\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e#  attn =   A B C\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 7\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e#         A √ × ×       uni-directional\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 8\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e#         B √ √ ×  \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e 9\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e#         C √ √ √\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e10\u003c/span\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e11\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eZ\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eZ4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eZ5\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e12\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eY\u003c/span\u003e             \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e13\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Equal to        Parallel Train\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e14\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eX2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eX3\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e        \u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eY1\u003c/span\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e15\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eX2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eX3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eY2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e16\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eX2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eX3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eY3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e17\u003c/span\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e18\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eloss\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecrossentropy\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eZ\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eignore\u003c/span\u003e\u003cspan class=\"o\"\u003e=-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# Zi =\u0026gt; {P1,...,Pclass} multi-class task\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e19\u003c/span\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e20\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Test:  Serial generation\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e21\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003egive\u003c/span\u003e \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eX1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eX2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eX3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e22\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eStep\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e23\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eZ\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einp\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e24\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eY\u003c/span\u003e              \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e25\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e26\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eStep\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e27\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eZ\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einp\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ4\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e28\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eY\u003c/span\u003e              \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e29\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e30\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eStep\u003c/span\u003e \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e31\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eZ\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einp\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ5\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e32\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eY\u003c/span\u003e              \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e33\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einp\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e34\u003c/span\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"ln\"\u003e35\u003c/span\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eZ1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eZ3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eY3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch3 id=\"minbert\"\u003eminBert\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003ework flow\u003c/strong\u003e\u003c/p\u003e","title":"DL基准模型训练伪代码"},{"content":"图示 卷积注意力 自注意力 学习 Norm Loss Cross Entropy $$ Loss = -\\sum_{i}^{C}y_ilog(p(x_{i})), where \\ y_i\\ is label,p(x_i)\\ is\\ predict. $$\nBCE Loss $$ Loss = −\\sum_{i}^{c}(y_ilog(p(x_i)+(1−y_i)log(1−p(x_i)) \\ where \\ y_i \\in [0, 1] \\\npos_partition = -log(p(x_i))\\ neg_partition = -log(1-p(x_i)) $$\nFocal Loss $$ Loss = -α_t(1-p_t)^γlog(p_t)\\\n# Multi-Label:\\ 1.\\ pos_loss = α(1-p(x_i))^γ\\ \\ -log(p_t)\\ 2.\\ neg_loss = (1-α)p(x_i)^γ\\ \\ -log(1-p_t) $$\n论文 Mlp-mixer - NIPS 2021 title: Mlp-mixer: An all-mlp architecture for vision\n⭐ channel-mixing MLPs and token-mixing MLPs.\n① 融合Patches间的特征信息\n② 融合Patches内的特征信息\n❌ 易过拟合\n**Transformer ** - NIPS 2017 Transformer Encoder\nMulti-Head Self Attention ⭐每段用不一样的α权重\t\u0026ndash; 分段融合Token间信息\n​\t多组注意力权重α\nToken分段，并行计算每段的权重α，多头注意力允许模型共同关注来自不同位置的不同表示子空间的信息。\n⭐⭐⭐ 并行多个头，增强表示能力，融合不同子空间(低纬空间)\nToken间信息融合，比例是相似度权重\nFeed-Forward Networks 卷积 深度可分离卷积计算成本比标准卷积小 8 到 9 倍，而精度仅略有降低 - MobileNetV2\n✨使用共享内核在局部区域内进行信息交互\n标准卷积 输入特征图和模板卷积核\n输出像素 - 融合局部空间通道信息\n瓶颈结构 - Resnet 减少参数数量\n逐点卷积降维 -\u0026gt; 标准卷积 -\u0026gt; 逐点卷积升维\n​\t残差连接\n压缩 - 卷积 - 扩张\n深度可分离卷积 倒残差结构 - MobileNet 扩充通道的原因，是为了能够提取到更多的信息\nReLU 激活函数可能会崩溃掉某些通道信息。然而，如果我们有很多通道，那么信息可能仍然保留在其他通道中。\n逐点卷积升维 -\u0026gt; 分组卷积 -\u0026gt; 逐点卷积降维\n​\t残差连接\n扩张- 卷积 - 压缩\nLinear 作用等同于1×1逐点卷积，实现线性映射\nViT - CVPR 2020/10 Vision Transformer - Patching 化为互不重叠的区域，输出通道数为Token的长度。⭐ 将image拆分为16×16×3的patch\n经过Conv2D提取Token，# Token中每元素均有局部宽高及通道信息\n所有标记之间的盲目相似性比较\nPVT - ICCV 2021 Pyramid Vision Transformer A Versatile Backbone for Dense Prediction without Convolutions\n创新点：在ViT（patch embed大小固定）基础上，仿照CNN网络的特征图变化\n⭐使用“渐进”收缩策略通过补丁嵌入层来控制特征图的尺度\nCNNs: 特征图变化 通道×2，宽高÷2\nViT: patch embed不变\nPVT： 渐进式缩小特征图，减少token数量\nPVT框架：\n①特征图 - patch_embed -\u0026gt; token token map -\u0026gt; token -\u0026gt; token map\n​\t⭐proj = Conv2d(in_channel, dim_token[i], kernel_size[i], stride[i])\ndim_token = [64, 128, 256, 512]\nkernel_size = [4, 2, 2, 2]\nstride= [4, 2, 2, 2]\t@ 渐进式缩小特征图\t\u0026ndash; 融合局部token的感觉\ntoken数量⬇，token维度⬆(信息更加丰富)\n多次Patch Embed\n②Transformer Encoder 对 token 进行信息提取 MHSA处进行调整：引入Spacial Reduction操作\nSpacial Reduction：将token折叠回特征图，使用Conv2d对特征图进行局部信息融合的处理，再保持通道维度不变的情况下，缩小宽高空间大小，再拆分成token，减少token数量。\n对Token Key和Value的部分进行SR处理，shape=(*num_token, dim_token)\nQuery shape=(num_token, dim_token)\nα = softmax(Q@SR(K).T / √d) shape=(num_token, *num_token)\nα@V\tshape=(num_token, dim_token)\n⭐图示操作：\n利用conv局部性，将相邻的Token进行合并 | 或者利用Pool进行窗口内Token合并\n计算量降低sr_ratio平方倍 \u0026ndash; Conv2D中的stride\n③将token折叠回特征图\nCvT - ICCV 2021 CvT: Introducing Convolutions to Vision Transformers\n很像PVT - 前置论文Bottle neck Transformer @ 在resnet末尾将后三层Conv3×3替换为MHSA （Conv结构中引入Attension全局建模）\n目的：\n①将卷积神经网络 (CNN) 的理想特性引入 ViT 架构（即移位、尺度和失真不变性），同时保持 Transformer 的优点（即动态注意力、全局上下文和更好的泛化）\n②将具有图像域特定归纳偏差的卷积引入 Transformer 来实现两全其美\n③空间维度下采样，通道增加。Token数量少了，但每个Token变长了，增强了携带信息的表示的丰富性\n⭐删除位置嵌入：为每个 Transformer 块引入卷积投影，并结合卷积令牌嵌入，使我们能够通过网络对局部空间关系进行建模。使其具有适应需要可变输入分辨率的各种视觉任务的潜在优势。\n总体结构\rConvolutional Token Embedding 重叠式的嵌入，使用标准Conv2D\n并且在每个Stage最后，将Token集合折叠回Token Map\nConvolutional Projection \u0026ndash; Conv生成QKV 而非通常的nn.Linear 利用 分组卷积 将K与V的Token Map下采样，性能换效率\n局部空间上下文的附加建模，相比于普通卷积(更复杂的设计和额外的计算成本)，DWConv性价比更高\n(b): 可参考MobileViT，先利用卷积局部融合信息，再执行窗口级注意力\nSwin - ICCV 2021 Swin transformer: Hierarchical vision transformer using shifted windows\n层级式ViT\n创新点：\n①patch embed尺寸逐步增大，检测小目标更好\n总体结构\n窗口级的Token特征融合操作： Swin Transformer Block 数量为偶数 ①窗口内的Token信息融合\nMHSA限制在窗口内进行 \u0026ndash; 降低计算复杂度\n②窗口间的Token信息融合 \u0026ndash; 滑动窗口策略 \u0026ndash; 间接看到全局信息\n蓝线表示窗口内Token信息融合，红线表示窗口间信息融合\n❗❗❗⭐⭐⭐MHSA依然限制在窗口内进行\n❗为了规整统一窗口大小，便于批量计算\n进行一次循环位移，使窗口大小统一\n⭐使用window-mask将本该不进行自注意计算的部分遮挡掉，在计算注意力α时，在其中softmax中，将mask的值设为-100，则e^{-100} / Σ e^{i} 为 0\n滑动窗口Mask示例：\n给窗口编号，再使用torch.roll 滑动 （ window_size // 2 ） 个像素\n$$ \\text{softmax}(z)i = \\frac{e^{z_i}}{\\sum{j=1}^{K} e^{z_j}}, \\quad \\text{for } i = 1, 2, \\ldots, K \\\\e^{-100} ≈ 0 $$\n相对位置编码： 因为计算Window-MHSA是并行的，没有位置顺序信息\n⭐注意力权重 加上 相对位置偏置\n✨相对位置信息 \u0026ndash; 压缩\u0026amp;复用\n① relative position bias table 自学习的位置标量偏置 \u0026ndash; 压缩\n② relative position bias index 索引 \u0026ndash; 不同位置的token使用相同的相对位置偏置 \u0026ndash; 复用\n给定窗口大小，index是固定值，table是可学习的位置信息\n一维情况：\nPatch Mergeing 目的： 宽高减半，通道翻倍\n整幅特征图分4部分，合并不同部分，相同位置的Token\nMobilevit - CVPR 2021 title: Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer\n在资源受限设备上运行ViT \u0026ndash; 混合CNN和Transformer\nMV2: MobileNetv2 中的倒残差块 ⬇2： 下采样2倍，控制stride步幅\nMobileViT Block:\t\u0026ndash; 间接融合 用二维卷积局部融合(重叠区域)，输出的特征图中每个像素都会看到 MobileViT 块中的所有其他像素\n红色像素使用变压器关注蓝色像素\n由于蓝色像素已经使用卷积对有关相邻像素的信息进行了编码，因此红色像素可以对图像中所有像素的信息进行编码\nunfold和fold 将特征图转为Token集合，改排序，不等于patch embed(用conv2d)\n原论文 最后的通道维度融合，使用的Conv3x3卷积。 # 模块对称。\nCrossViT - ICCV 2021 CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification\n双分支 - 多尺度patch嵌入\n互换分支的CLS Token 实现分支间的信息通信\n总体结构\r交互示例\r详细\rDeiT - CVPR 2021 Training data-efficient image transformers \u0026amp; distillation through attention\n⭐纯Transformer版本的知识蒸馏\n引入distillation token来进行知识蒸馏，执行的目标不同。一个与label计算loss，一个与Teacher label计算蒸馏损失。反向传播优化时，梯度不一样\nT2T - ICCV 2021 Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet\n重叠嵌入，信息更全面。融合Token，删除冗余\nsoft split\t重叠融合(图示是堆叠在通道维度)\nBiFormer - CVPR 2023 BiFormer: Vision Transformer with Bi-Level Routing Attention\n一种动态的、查询感知的稀疏注意力机制。 关键思想是在粗糙区域级别过滤掉大部分不相关的键值对，以便只保留一小部分路由区域，再进行细粒度的注意力计算\n注意力区域对比\r路由方式建立跨窗口信息交互\n通过化为window，各Token均值为代表整window的Token，计算区域相似性关系图，借此为窗口间链接通信\n将窗口串起来\nBi-Routing Self-Attention\r总体结构\rDWConv 3×3 作用：\n​\t在开始时使用 3×3 深度卷积来隐式编码相对位置信息。\nSMT - ICCV 2023 Scale-Aware Modulation Meet Transformer\n“模拟随着网络变得更深而从捕获局部依赖关系到全局依赖关系的转变“（串行渐变结构） =联想到=\u0026gt; 浅层网络捕获形态特征，深层部分捕获高级节律特征\nSMT1D 生硬的训练ECG 中等效果，但计算量小！\n层级式ViT结构\n总体结构\rEvolutionary Hybrid Network 结构取名为“进化混合网络” Evolutionary Hybrid Network - 局部到全局建模的过渡\n两种融合模块的堆叠方式\r性能对比\rSAM Block scale-aware modulation\rMulti-Head Mixed Convolution 将通道分割为多个头(组)，每个头使用不同大小的卷积核（目的：捕捉多个尺度的各种空间特征。增强网络的建模能力“局部远程依赖”）\n例：\nScale-Aware Aggregation 倒残差结构 - 融合通道\n在MHMC结构中，多头由于卷积核大小不同，更大的卷积核看到的感受野更大。 将多头各个卷积依次打包成组，进行组间通道融合，每组既有小感受野的信息，又有大感受野信息，多样 multi-scale\n可视化模块效果 \u0026ndash; 画的卷积调制权重 深度可分离卷积作为注意力权重\n① 每个不同的卷积特征图都学习以自适应方式关注不同的粒度特征\n②多头更准确地描绘前景和目标对象\n③网络变深，多头仍然可以呈现目标物体的整体形状。与细节相关的信息在单头卷积下会丢失\n⭐⭐表明 MHMC 在浅层阶段有能力比单头更好地捕获局部细节，同时随着网络变得更深，保持目标对象的详细和语义信息。\n增强了语义相关的低频信号，精确地聚焦于目标对象最重要的部分。\n更好的捕获和表示视觉识别任务的基本特征的能力。\nConv2Former - CVPR 2022 Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition\n创新点： 用卷积操作 模拟近似 注意力 \u0026ndash; 更低的计算代价 略低的性能下降\nHadamard product == 矩阵按元素相乘\n使得每个空间位置(h,w)能够与以(h,w)为中心的k×k正方形区域内的所有像素相关。通道之间的信息交互可以通过线性层来实现。\n※重点： ConvNeXt中表明，卷积核不是越大越好，超过7x7，计算代价远远大于性能收益\n⭐本文实验提出，将卷积特征作为权重，能比传统方式更有效地利用大内核\nConvNeXt - CVPR 2022 ConvNeXt 将CNN搭建成SwinT的风格，性能超越SwinT\nInceptionNext 多尺度版本的ConvNeXt\nShunted SA - CVPR 2022 Shunted Self-Attention via Multi-Scale Token Aggregation\nPVT 和类似的模型往往会在这种空间缩减中合并太多的标记，使得小物体的细粒度信息与背景混合并损害模型的性能；\n同时保留粗粒度和细粒度的细节，同时保持对图像标记的全局依赖性建模；\n观察到PVT和ViT在同一个Encoder中token尺度是固定的，创新结合二者。用Conv将Token Map局部融合成多幅Token Map，使每个汇聚的Token代表着不同区域，不仅观察到小物体，也能看到大物体。 ViT：小区域\nPVT： 大区域\nShunted : 结合大小区域\n灵感源于：\n做法：\n​\t不同头的长度不同，以捕获不同粒度的信息。\n原始特征图x，卷积局部融合得到x1， x2 (HW均变小)\n❗注意：Q的线性映射维度不变，而不同尺度的KV通过线性映射时维度缩减率为SR特征图的数量（QKV维度一致）\n两种做法\n细粒度 - pixel token || 粗粒度 - patch token\nGC-ViT - ICML 2023 Global Context Vision Transformers\n与SwinT的区别：\n不通过滑动窗口实现全局信息建模 =\u0026gt; 直接生成全局信息Token，使用这组携带全局信息的TokenSet来实现全局信息建模 SwinT 层数堆不够的话，全局信息建模不强 与SwinT的共同点：\n都属于window-wise attention\n位置编码都采用相对位置偏置bias\n基本单元：局部窗口内计算 + 全局信息建模；（窗口内 + 窗口间）\n思路：\nGlobal query tokens generation\nMBConv - FeatureExtract\n代码分析\n1X: [batch, num_token, dim_token] 2x-window: [batch*num_windows, num_token//num_windows, dim_token] 3x-window-head:[batch*num_windows, num_heads, num_token//num_windows, dim_token//num_heads] 4 5 6Query: [batch × num_window, num_heads, num_tokens, dim_head] 7Key-Global: [batch, repeat , num_heads, num_tokens, dim_head] 图示最后的复制，是让每个窗口内的token与全局token表示进行信息融合 （复制窗口维度的大小）\nfunny: 公司{多部门} =\u0026gt; [部门内部成员进行讨论] =\u0026gt; [部门之间领导进行讨论]\nToken Sparsification - CVPR 2023 Making Vision Transformers Efficient from A Token Sparsification View\n动机：\n*观察到注意力后期，仅部分核心Token起着主要作用*![image-20240407143751781](http://sthda9dn6.hd-bkt.clouddn.com/Fq2bA5CegUx5LXr1CkJytYjIeE4d)\r对Token进行瘦身 - 与利用CLS Token进行级联删除不用的策略\n方法：\tSparse Token Vision Transformer\nSemantic Token Generation Module 1️⃣ Base Module 学习浅层特征\n2️⃣ 进行Spatial Pooling聚合区域，生产空间簇中心TokenSet\n**Conv( GELU( LayerNorm( DWConv( X ))))** *- 深度可分离*\r创新：**Intra and inter-window** spatial pooling\r目的：聚合窗口信息(代表) + 疏远窗口间信息(不可被替代)\r3️⃣ 融合生成Semantic Token Set\t- Global Initial Center G 是可学习的参数 $$ \\overline{S^{1}} = MHA(P, X, X) + P,\\ \\ \\ S^{1} = FFN(\\overline{S^{1}}) + \\overline{S^{1}} \\\\ \\overline{S^{2}} = MHA(S^{1} + G, Concat(S^{1}, X), Concat(S^{1}, X)) + P,\\ \\ \\ S^{2} = FFN(\\overline{S^{2}}) + \\overline{S^{2}} \\ S^{2} = Semantic\\ \\ Token $$\nRecovery Module $$ \\overline{X} = MHA(X, S, S) + P,\\ \\ \\ X = FFN(\\overline{X}) + \\overline{X} $$ 融合操作的逆过程\n从语义级TokenSet中恢复空间信息\nFirst layer attention maps\nHiLo Attention - NeurIPS 2022 Fast Vision Transformers with HiLo Attention\n图像中的高频捕获局部精细细节，低频关注全局结构，而多头自注意力层忽略了不同频率的特征。 因此，我们建议通过将头部分为两组来解开注意力层中的高频/低频模式，其中一组通过每个局部窗口内的自注意力对高频进行编码，另一组通过在每个局部窗口内执行全局注意力来对低频进行编码，输入特征图中每个窗口和每个查询位置的平均池化低频键和值。\n创新点：\n将自注意力分为高频和低频 高频捕捉局部精细细节（轮廓、边缘） 低频捕获整体结构or趋势 high部分是window级别的attn low部分是space reduce(经过pool)的粗糙级别的attn 图示：\n伪代码：\n1HiLoAttention(): 2 def high(x): 3 # window-partition 4 [batch, num_token, dim_token] =\u0026gt; [batch, num_window, window_size, dim_token] 5 # multi-head 6 [batch, num_window, window_size, dim_token] =\u0026gt; [batch, num_window, num_head, window_size, dim_head] 7 8 # do attention 9 # reshape to restore 10 11 def low(x): 12 B, L, C = x.shape 13 x_ = x.transpose(-2, -1)\t# [batch, channel, length] 14 x_ = self.sr_cnn(x_) # [batch, channel, _length] reduce length || avgpool or dwconv 15 16 q = self.q(x).reshape() =\u0026gt; [batch, num_head, num_token, dim_head] 17 k, v = self.kv(x).reshape()[...] =\u0026gt; [batch, num_head, *num_token, dim_head] 18 19 # do attention 20 # reshape to restore 21 22 def forward(x): 23 x1 = high(x) 24 x2 = low(x) 25 26 x = torch.cat([x1, x2], dim=-1) 27 x = self.proj(x) CMT - CVPR 2022 CMT: Convolutional Neural Networks Meet Vision Transformers\n注重点：与之前基于 CNN 和基于 Transformer 的模型相比，在准确性和效率方面获得了更好的权衡。\n⭐ 由于 patch 大小固定，Transformer 很难显式地提取低分辨率和多尺度特征 =\u0026gt; 图像是二维的（即具有宽度和高度），并且在图像中的每个像素位置都与其周围的像素有关。这种空间局部信息非常重要，例如，边缘检测、纹理分析等都依赖于这种局部关系。=\u0026gt; Patchfiy 后削弱了pixel之间的关系，只补充了Patch间的位置信息。\nCNN、Transformer 、CNN\u0026amp;Transformer\n在每个阶段，产生层次表示 \u0026ndash; 金字塔结构\n定制的Stem Block内部混合CNN和MHSA ❤️ [DWConv(Skip-con) + SR-MHSA(Skip-con) + IRFFN(Skip-Conv)] Conformer - 2020 Conformer: Convolution-augmented Transformer for Speech Recognition\n集成了 CNN 和 Transformer 组件以进行端到端识别的架构\n分析：\n虽然 Transformer 擅长对远程全局上下文进行建模，但它们提取细粒度局部特征模式的能力较差； 卷积神经网络（CNN）利用局部信息，在本地窗口上学习共享的基于位置的内核，能够捕获边缘和形状等特征。使用本地连接的限制之一是需要更多的层或参数来捕获全局信息。 ⭐ 将卷积与自注意力有机结合起来。 我们假设全局和局部交互对于参数效率都很重要。 为了实现这一目标，我们提出了一种自注意力和卷积的新颖组合，将实现两全其美\narchitecture\nConvolution Module\nFeed Forward Module\nPathFormer - ICLR 2024 PATHFORMER: MULTI-SCALE TRANSFORMERS WITH ADAPTIVE PATHWAYS FOR TIME SERIES FORECASTING\narchitecture\nDual-Attention\nMobile-Former - CVPR 2022 Mobile-Former: Bridging MobileNet and Transformer\n动机：\n如何设计高效的网络来有效地编码本地处理和全局交互？\n最近工作：串联组合卷积和视觉变换器的好处，无论是在开始时使用卷积还是将卷积交织到每个变换器块中\n视觉变换器（ViT）[10,34]展示了全局处理的优势，并实现了比 CNN 显着的性能提升，如何在计算资源或者参数量有限的情况下充分挖掘结合两者的优势，=\u0026gt; parameters efficient\n贡献：\n并行设计 + 双路桥接； 利用了 MobileNet 在本地处理和 Transformer 在全局交互方面的优势；实现局部和全局特征的双向融合 全局Token只有初始化为0的很少的Token，利用Cross Attention 进行交互 ⭐大概就是在MobileNet为主干的基础上添加ViT全局Token的信息注入 architecture\nInteraction\npseudo code\n1q = FC(token).view(), k, v = x.view()\t# shape =\u0026gt; batch, num_token, dim_token; 2do Local2Global-CrossAttn() 3 4token =\u0026gt; MHSA() 5 6x = MobileNetBlock() 7 8q = x.view(), k, v = FC(token).view() 9do Global2Local-CrossAttn() ViT Adapter - ICLR 2023 VISION TRANSFORMER ADAPTER FOR DENSE PREDICTIONS\n动机\n在不改变原有ViT的基础上(利用大规模预训练参数)，添加辅助器帮助Transformer学习弱项；【使用现成的预训练 ViT 适应密集的预测任务】\nViT 单尺度和低分辨率表示的弱点 =\u0026gt; 注入一些多尺度特征(CNN)给单尺度的ViT\n\u0026hellip;表明卷积可以帮助 Transformer 更好地捕获局部空间信息，对与补丁嵌入层并行的图像的局部空间上下文进行建模，以免改变 ViT 的原始架构。\n贡献\nViT Adapter: [Spatial Prior Module, Spatial Feature Injector, Multi-Scale Feature Extractor] paradigm compare\narchitecture\n（c）用于根据输入图像对局部空间上下文进行建模的空间先验模块， Adapter: Spatial feature token set; ViT: origin feature map; （d）用于将空间先验引入ViT的空间特征注入器 （e）用于从单个图像重新组织多尺度特征的多尺度特征提取器 -ViT 的尺度特征 采用稀疏注意力来降低计算成本\npseudo code\n1# Spatial prior module 2X_vit = ResnetBlock(x) 3x1 = PointConv(Conv(X_vit))\t# down-sample: HW/8^2 and project channel to D dimension 4x2 = PointConv(Conv(x2))\t# down-sample: HW/16^2\tto D dimension 5x3 = PointConv(Conv(x3))\t# down-sample: HW/32^2\tto D dimension 6X_vit = torch.cat([x1, x2, x3], dim=num_token) 7 8# injector // spatial feature to ViT 9q = FC(X_vit).view(...), k, v = FC(X_spm).view(...)\t# spm: spatial prior module 10do Cross-Attn() 11 12# Multi-Scale Feature Extractor 13q = FC(X_spm).view(...), k, v = FC(X_vit).view(...)\t# analyze：\n⭐ 研究表明，ViT 呈现出学习低频全局信号的特征(整体、模糊和粗糙)，而 CNN 则倾向于提取高频信息（例如局部边缘和纹理） visualize\n傅里叶变换特征图的傅里叶频谱和相对对数幅度（超过 100 张图像的平均值） =\u0026gt; 表明 ViT-Adapter 比 ViT 捕获更多的高频信号\n我们还可视化了图5（b）（c）中的stride-8特征图，这表明ViT的特征是模糊和粗糙的\nInception Transformer - NeurIPS 2022 Inception Transformer\n动机：\nTransformer 具有很强的建立远程依赖关系的能力，但无法捕获主要传达局部信息的高频；\nViT 及其变体非常有能力捕获视觉数据中的低频，主要包括场景或对象的全局形状和结构，但对于学习高频（主要包括局部边缘和纹理）不是很强大(CNNs很擅长，它们通过感受野内的局部卷积覆盖更多的局部信息，从而有效地提取高频表示)；\n最近的研究[21-25]考虑到CNN和ViT的互补优势，将它们集成起来。 一些方法[21,22,24,25]以串行方式堆叠卷积层和注意力层，以将局部信息注入全局上下文中。 不幸的是，这种串行方式仅在一层中对一种类型的依赖关系（全局或局部）进行建模，并且在局部性建模期间丢弃全局信息，反之亦然。❤️ 每个模块都不够全面=\u0026gt;模型要么只有局部感知能力，要么只有全局建模能力 =\u0026gt; 在ECG中，有些疾病不仅仅是局部或全局的病理特征，而且是节律异常伴随着波形形态异常；从这一角度出发，我们希望能够充分的利用Transformer的全局依赖感知能力和CNN的强大的局部感知能力，交互融合有力结合两者优势； 【就像在人类视觉系统中一样，高频分量的细节有助于较低层捕获视觉基本特征，并逐渐收集局部信息以对输入有全局的理解】\n层级式网络，多尺度分辨率特征图，每部分均能全局+局部感知；并且设计频率斜坡结构 =\u0026gt; 底层更注重高频信息(细节信息，局部模式、纹理边缘)；高层更注重低频信息(整体轮廓，全局)\n创新点：\nTransformer中的Multi-Head Self-Attention =\u0026gt; Inception Mixer ; 按channel分两组：1. 低频组；2. 高频组； 低频组 池化稀疏注意力，但仅最低两块用； 高频组 [MaxPool, DWConv]； 频率斜坡结构: 高频组\u0026gt;低频组 =\u0026gt; 高频组\u0026lt;低频组 底层在捕获高频细节方面发挥更多作用，而顶层在建模低频全局信息方面发挥更多作用 architecture\nInception Mixer\npseudo code\n1# x : [batch, channel, width, hight] 2x_h, x_l = torch.chunk(x, chunks=2, dim=1) 3x_h1, x_h2 = torch.chunk(x_h, chunks=2, dim=1) 4 5y_h1 = FC(MaxPool(x_h1)) 6y_h2 = DWConv(FC(x_h2)) 7y_l = MSA(AvePooling (X_l)) 8 9Y = X + ITM(LN(X)) # ITM : Inception Mixer 10H = Y + FFN(LN(Y)) 局部|高频 \u0026amp; 全局|低频 - 傅里叶谱\nTransNeXt - CVPR 2024 TransNeXt: Robust Foveal Visual Perception for Vision Transformers\nanalysis\n目前的稀疏Attention： Local Attention[限制计算量，n×固定窗口计算量]: window-level attention, =\u0026gt; cross-window attn information exchange 需要堆叠很深才能实现全局感知 patially downsamples【降低计算的Token数量】: pool or dwconv =\u0026gt; 信息丢失问题； 【细粒度(丢失)=\u0026gt; 粗粒度】 motivation\n⭐ 观察：生物视觉对视觉焦点周围的特征具有较高的敏锐度，而对远处的特征具有较低的敏锐度。 结合window-level attn \u0026amp; spatial downsample attn，临近的token执行pixel-level attn，稍远的区域执行pool-level attn, 实现视觉仿生聚焦attn contribution\nfocus attn 【局部细粒度，全局粗粒度】\nfocus attn 升级 aggregated attention 【QKV 注意力、LKV 注意力和 QLV 注意力统一】\nQLV 与传统的 QKV 注意力机制不同，它破坏了键和值之间的一对一对应关系，从而为当前查询学习更多隐含的相对位置信息。 LKV：增强表达能力，通过引入可学习的键和值，模型可以学习到更多有用的特征，增强了对复杂关系的建模能力 length-scaled cosine attention 【双路注意力concat经过同一个softmax】\nconvolutional GLU替换MLP\narchitecture\nleft figure: focus attn; right figure: aggregated attn(add QKV-attn、LKV-attn、QLV-attn)\n共享同一个Softmax（作用可能是这里进行多注意力的制约交互）\nConvGLU: 卷积 GLU (ConvGLU) 中的每个标记都拥有一个独特的门控信号，基于其最接近的细粒度特征。 这解决了SE机制中全局平均池化过于粗粒度的缺点。 它还满足了一些没有位置编码设计、需要深度卷积提供位置信息的ViT模型的需求。\nEfficientViT - CVPR 2023 EfficientViT Memory Efficient Vision Transformer with Cascaded Group Attention\n权衡性能和代价\nmotivation\n发现现有 Transformer 模型的速度通常受到内存低效操作的限制，尤其是 MHSA 中的张量整形和逐元素函数; 虽然Transformer性能很好，但是代价很高，不适合实时应用; =\u0026gt;优化;\n发现注意力图在头部之间具有高度相似性，导致计算冗余。// 显式分解每个头的计算可以缓解这个问题，同时提高计算效率\ncontribution\n设计了一种具有三明治布局的新构建块，即在高效 FFN 层之间使用单个内存绑定的 MHSA，从而提高内存效率，同时增强通道通信; 提出了一个级联的组注意力模块，为注意力头提供完整特征的不同分割，这不仅节省了计算成本，而且提高了注意力多样性。 architecture\nToken Interaction：DWConv，增强局部交互能力，引入局部结构信息的归纳偏差来增强模型能力\n三明治结构中，局部建模和全局Attn, 即[Token Interaction, FFN][Cascaded Group Attention][Token Interaction, FFN]堆叠不是1:1:1, 而是N:1:N, Why? because Attention 计算量太大了，能少用就少用。\nCascaded Group Attention pseudo code\n1feature_group = x.chunk(len(self.qkv_group), dim=1) # split head 2feature = feature_group[0]\t# first head 3 4feature_out = [] 5for i, qkv in enumerate(self.qkv_group): 6 if i \u0026gt; 0: 7 feature = feature + feature_group[i] # Cascaded Group 8 Q, K, V = qkv(feature).view().permute() # shape: B, H, N, C/H 9 Q = DWConv[i](Q) # enhance Query Token Set 10\tout = (Q@K.transpose(-2, -1) × scale)@V 11 feature_out.append(out) 12out = torch.cat(feature_out, 1) 13FC(out) 不同于传统Attn，这里先分头再线性映射，头的信息会越来越丰富。 并且实现中(Cascaded Group Attention in Window-level Attention )\nEMO - ICCV 2023 Rethinking Mobile Block for Efficient Attention-based Models\n目标：轻量级 CNN 设计高效的混合模型，并在权衡精度、参数和 FLOP 的情况下获得比基于 CNN 的模型更好的性能\n出发点：我们能否为仅使用基本算子的基于注意力的模型构建一个轻量级的类似 IRB 的基础设施？\n基本算子结构对比\nMulti-head self attention: 线性映射qkv，MHSA, 投影回来\nFeed Forward Network: Linear-Linear\nInverted Residual Block: Conv1x1-DWConv-Conv1x1\n=\u0026gt; 综合考量 提出基本算子Meta Mobile Block\nMeta Former Block vs Inverted Residual Block\n更加细致的抽象\niRMB（Inverted Residual Mobile Block）\n！！！ 由于 MHSA 更适合对更深层的语义特征进行建模，因此我们仅在之前的工作之后的 stage-3/4 中打开它 。\nConv:\nBN+SiLU与DWConv结合； W-MHSA(window-level attention 更加高效):\nLN+GeLU与EW-MHSA结合。\n解释EW-MHSA\n因为iRMB，会先升维，导致MHSA计算量变高， Q,K维度不变，而V的维度变长了，拿attn-score加权求和时应用的是扩展V 深度设计，灵活的设计\nFocal Attention - NeurIPS 2021 Focal Attention for Long-Range Interactions in Vision Transformers\n观察：\n图 1：左：DeiT-Tiny 模型 [55] 第一层中给定查询块（蓝色）处三个头的注意力图的可视化。 右图：焦点注意力机制的说明性描述。 使用三个粒度级别来组成蓝色查询的注意区域。\n创新点：\nClose =\u0026gt; Far Fine =\u0026gt; Coarse 图示：\n伪代码：\n11. 使用torch.roll 再按窗口划分 =\u0026gt; 收集细粒度周边Token, 再使用mask掩码掉多余不需要的Token 22. 先分窗口，执行窗口内Pool，生成超粗粒度Token 3 4Q: 窗口内Token 5K, V: 窗口内Token + 周边细粒度Token + Pool-Token CloFormer - CVPR 2023 Rethinking Local Perception in Lightweight Vision Transformer\narchitecture\n局部+全局 感知并行\n局部感知，类似于CNN中的卷积注意力用在自注意力分支中\nFFN 内追加局部感知增强模块\nMetaFormer - 2023 我们并不试图引入新颖的令牌混合器，而只是将令牌混合器指定为最基本或常用的运算符来探测 MetaFormer 的能力\n⭐探索Meta Block的潜力！\n1X = X + TokenMixer(Norm(X)) 2X = X + ChannelMixer(Norm(X)) MaxViT - ECCV 2022 MaxViT: Multi-Axis Vision Transformer\n动机：解决Self-Attention平方复杂度问题\n框架：\n1️⃣ MobileNetV2中的倒残差块 =\u0026gt; 提供增强局部感知 \u0026amp; 隐式编码位置信息\n2️⃣ Block-Attention =\u0026gt; window-level attention ❌ 限制感受野 ⭐ 降低计算量\n3️⃣ Grid-Attention =\u0026gt; 感受野遍及全局的扩张卷积做法 1. 分窗口 2. 收集每个窗口相同次序的Token成组. 3. 组内计算注意力\nAttention illustration\nCiT - ICCV 2021 Incorporating Convolution Designs into Visual Transformers\n局部增强\n就是Inverted Resiual Block [Conv1×1 =\u0026gt; Depth-wise Conv3×3 =\u0026gt; Conv1×1] 对Token进行局部信息增强\n框架：\n⭐利用了每个Stage中的Class Token，这样可以有层级式信息，而且梯度会通过这个CLS Token直接传递给前面部分\nBi-Interaction Light-ViT Lightweight Vision Transformer with Bidirectional Interaction\n图示：\n框架：\n⭐想法很超前⭐\n局部与全局的相互调制\nUniRepLKNet UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video, Point Cloud, Time-Series and Image Recognition\n⭐超大卷积核 Conv winwinwin\n当我们向小内核 ConvNet 添加 3×3 卷积时，我们期望它同时产生三种效果\n使感受野更大， 增加空间模式的抽象层次（例如，从角度和纹理到物体的形状） 通过使其更深，引入更多可学习的参数和非线性来提高模型的一般表示能力 相比之下，我们认为大内核架构中的这三种影响应该是解耦的，因为模型应该利用大内核的强大优势——能够看到广泛而不深入的能力\n由于在扩大 ERF(感受野) 方面，增加内核大小比堆叠更多层更有效，因此可以使用少量大内核层构建足够的 ERF，从而可以节省计算预算以用于其他高效结构 在增加空间模式的抽象层次或总体上增加深度方面更有效。\n框架：\n重参数化\n块设计\nEdgeViTs - ECCV 2022 EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision Transformers\n架构：\n# 类似MobileViT\n1X = LocalAgg(Norm(X)) + X # 2Y = FFN(Norm(X)) + X 3Z = LocalProp(GlobalSparseAttn(Norm(Y))) + Y 4Xout = FFN(Norm(Z)) + Z 图示： （选举 =\u0026gt; 精英 =\u0026gt; 分发）\nShuffleNet - CVPR 2018 出发点：构建高效模型\n⭐V1⭐\n缺点发现：\n1=\u0026gt; Conv1x1 _ Norm+ReLU # Point-wise 2=\u0026gt; DWConv3x3 _ Norm # Depth-wise 3=\u0026gt; Conv1x1 _ Norm+ReLU # Point-wise 4 5# 为了高效 =\u0026gt; 只是将Conv3x3 =\u0026gt; Conv1x1 6# =\u0026gt; 但是Conv1x1占据了93.4%的乘法-加法 7 8# =\u0026gt; 目标，优化PWConv 操作图示：\n卷积分组减少计算量 （⭐优化组间通信⭐）\nShuffleNet Basic Block\n(a) ResNet bottleneck unit \u0026lt;= DWConv (b) 优化PWConv（Group Conv），并且Channel Shuffle，执行Group communication # 无下采样，输入输出shape一致 (c) 恒等映射占据一半的Channel，另一半精修过的Feature Map ⭐V2⭐\n=\u0026gt; 分析各个类型操作占据的计算成本\n除了FLOPS指标，吞吐量和速度更为直接直观，符合真实贴切\n(使用FLOP作为计算复杂性的唯一度量是不够的，并且可能导致次优设计)\n(具有相同FLOP的操作可能具有不同的运行时间)\n访存时间 \u0026lt;= 并行度 \u0026lt;= (a) basic shuffle net block -v1 (b) basic shuffle net block with downsample -v1 (c) v2 (d) v2 with downsample 1# shape equivalence 2x.shape = (B, 64, H, W) 3x1, x2 = channel-split(x) # =\u0026gt; (B, 32, H, W), (B, 32, H, W) 4# x1 作为恒等映射，残差连接？ 特征复用？ 5out = concat(x1, block(x2)) 6out = channel-shuffle(out) 7 8# with downsample 9x.shape = (B, 64, H, W) 10x1, x2 = x, x # =\u0026gt; (B, 64, H, W), (B, 64, H, W) 11out = concat(branch1(x1), branch2(x2)) 12out = channel-shuffle(out) 特征复用示意图：\n$$ l1-norm = \\sum_{i=1}^n{|v_i|} $$ 相邻层更高效\n准确率参数贡献✔️\nRepVGG - ReParams - CVPR 2021 结构分析\n内存分析：\n=\u0026gt; 权衡：性能和计算内存成本\nTrain：多分支结构，性能好\nTest： 单分支结构，速度快，内存少\n⭐⭐⭐重参化：\n细节：\n举例第一个卷积后的元素\nAgent Attention - ECCV 2024 Attn图示：\n做法：\ncode：\n1q, k, v = qkv[0], qkv[1], qkv[2] 2 3agent_token = pool(q) 4 5agent_attn = softmax(agent_token * scale @ k.T + position_bias) 6agent_v = agent_attn @ v 7 8q_attn = self.softmax((q * self.scale) @ agent_tokens.T + agent_bias) 9x = q_attn @ agent_v 10 11x = x + self.dwc(v) 12 13 14# 复杂度 15o(N * K) + o(N * K) 享受 =\u0026gt; 高表达性和低计算复杂度的优势\nCF-ViT CF-ViT: A General Coarse-to-Fine Method for Vision Transformer\n对于分类任务 - 不需要那么精细的patch\n两步策略：\n粗粒度patch=\u0026gt;ViT =\u0026gt; 预测得分 =若得分小于设定的置信度\u0026gt; 将重要区域细分 =ViT\u0026gt; 最终预测 特征复用\n不重要区域 =\u0026gt; 大尺度粗略的Patch (可能有不相关的背景干扰) 重要区域 =\u0026gt; 小尺度精细的patch(更多边缘细节) \u0026lt;= 第一阶段粗略的Patch充当区域嵌入 利用ViT中[CLS] Token与其他Token的Attn累计区域的重要性\nGlobal-Attn = αAttn_l + (1-α)Attn_l+1\nTraining\nloss = CE(pf, y) + KL(pc,pf)\n训练时每次均进行Patch精细推理。使用精细模型指导粗略Patch推理\nConformer: ResNet + ViT 并行结构 =\u0026gt; 同时保留局部和全局特征 (保持CNN和ViT架构的优势)\nTwins： [Local-Global] [LSA-FFN] =\u0026gt; [GSA-FFN]\nwindow-self-attention =\u0026gt; global-self-attention\nMSG-Transformer 架构\n有趣点 - Shuffle-Net ?\n局部信使 - 传递信息\nDilateFormer IEEE TRANSACTIONS ON MULTIMEDIA \u0026ndash; sci-1\noverview\nnovel\n不同注意力头部，进行细微的调整\nScopeViT Pattern Recognition\nArchitecture\nnovel\n串行交叉：[多尺度, 多份KV]+[dilated Attention] $$ 𝐐 = 𝑋𝐖_𝑄,𝐊_𝑖 = 𝑃_𝑖𝐖^𝐾_𝑖, 𝐕_𝑖 = 𝑃_𝑖𝐖^V_𝑖 $$ 1 Query不变， KV通过多个不同内核大小的DWConv生成多尺度 KV (粗粒度)\n2 Stride Attention (细粒度)\nFastViT - ICCV overview\nStem:\n1reparams-conv 前三阶段：\n1x = x + BN(DWConv(X)) # re-params 2x = x + (DWConv-\u0026gt;BN-\u0026gt;Conv1x1-\u0026gt;GELU-\u0026gt;Conv1x1) # ConvFFN 最后阶段：\n1x = x + DWConv(X) # CPE convolution position embedding 2x = x + BN(Attention(X)) # Attention 3x = x + (DWConv-\u0026gt;BN-\u0026gt;Conv1x1-\u0026gt;GELU-\u0026gt;Conv1x1) # ConvFFN Integration of CNN + Attention Revisiting the Integration of Convolution and Attention for Vision Backbone\nnovel\n1Conv-part: [Conv1x1-\u0026gt;DWConv5x5-\u0026gt;Conv1x1] =\u0026gt; X_conv # ConvFFN ? 2Attn-part: 31. [聚簇] Clustering：X -\u0026gt; pooling -\u0026gt; cluster 42. [提炼] cluster@X.T -\u0026gt; score@X -\u0026gt; cluster$ {这里用点积相似度举例} 53. [全局] cluster$ -\u0026gt; MHSA -\u0026gt; cluster$ 64. [分发] cluster$ -\u0026gt; cluster@score.T =\u0026gt; X_attn 7 8Y = X_conv + X_attn RepNeXt overview\n1Token-Mixer: 2 1. nn.Identity() 3 2. DWConv3x3 + (DWConv1x3 + DWConv3x1) 4 3. DWConv7x7 + DWConv3x5 + DWConv5x3 + (DWConv1x5 -\u0026gt; DWConv5x1) + (DWConv1x7 -\u0026gt; DWConv7x1) 5 4. (DWConv1x11 -\u0026gt; DWConv11x1) 6 7nn.Conv2d(in_channels, out_channels, kernel_size=(3, 5), padding=(1, 2), bias=bias, stride=stride) 8# Fusion =\u0026gt; 重参数化融合 InceptionNeXt\n1Block: [Token-Mixer -\u0026gt; Norm -\u0026gt; FFN] 2025/1/14 Tidying up\nViT with Deformable Attn Vision Transformer with Deformable Attention\n全部采样点如下：\n高得分key采样点如下\n1# 1. 生成 query 2q = Conv1x1(X) 3offset = ConvKxK(q).conv1x1()=\u0026gt; // 将通道映射为2，并且为了提高采样点的多样性，将通道分组，每组获取不一样的信息。 4reference = 规整的网格 5pos = reference + offset // 固定点 + 偏移 6x_sampled = F.grid_sample(X, pos) 7 8k = Conv1x1(x_sampled) 9v = Conv1x1(x_sampled) 10 11MHSA(q, k, v) ⭐⭐⭐\nPVT下采样技术导致严重的信息丢失❗，而Swin-T的shiftwindow注意力导致感受野的增长要慢得多❗，这限制了对大型物体建模的潜力。Deformable DETR已经通过在每个尺度上设置Nk = 4的较低数量的键来减少这种开销，并且作为检测头工作良好，但是由于不可接受的信息丢失，在骨干网络中关注如此少的键是不好❗\n这不就是步幅Attention，添加了可变嘛\n","permalink":"http://121.40.252.207/posts/learning/paper_reading1/","summary":"\u003ch2 id=\"图示\"\u003e图示\u003c/h2\u003e\n\u003ch3 id=\"卷积注意力\"\u003e卷积注意力\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240322202245497\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FnOSHW83hKtIFxFdU34DDsMiOeWO\"\u003e\u003c/p\u003e\n\u003ch3 id=\"自注意力\"\u003e自注意力\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240322202200571\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FvUxt8fwO3J-k8UzUsCI30aE2lRp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"学习\"\u003e学习\u003c/h2\u003e\n\u003ch3 id=\"norm\"\u003eNorm\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240305205407153\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FoDS7JLx483eH0OReKVsf9Rx-4tZ\"\u003e\u003c/p\u003e\n\u003ch3 id=\"loss\"\u003eLoss\u003c/h3\u003e\n\u003ch4 id=\"cross-entropy\"\u003eCross Entropy\u003c/h4\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240302160358957\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FsuefQxQF9qmKbSUd94pmTsYId_D\"\u003e\n$$\nLoss = -\\sum_{i}^{C}y_ilog(p(x_{i})), where \\ y_i\\ is label,p(x_i)\\ is\\ predict.\n$$\u003c/p\u003e\n\u003ch4 id=\"bce-loss\"\u003eBCE Loss\u003c/h4\u003e\n\u003cp\u003e$$\nLoss = −\\sum_{i}^{c}(y_ilog(p(x_i)+(1−y_i)log(1−p(x_i)) \\\nwhere \\ y_i \\in [0, 1] \\\u003c/p\u003e\n\u003cp\u003epos_partition = -log(p(x_i))\\\nneg_partition = -log(1-p(x_i))\n$$\u003c/p\u003e\n\u003ch4 id=\"focal-loss\"\u003eFocal Loss\u003c/h4\u003e\n\u003cp\u003e$$\nLoss = -α_t(1-p_t)^γlog(p_t)\\\u003c/p\u003e\n\u003cp\u003e# Multi-Label:\\\n1.\\ pos_loss = α(1-p(x_i))^γ\\ \\ -log(p_t)\\\n2.\\ neg_loss = (1-α)p(x_i)^γ\\ \\ -log(1-p_t)\n$$\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"论文\"\u003e论文\u003c/h2\u003e\n\u003ch3 id=\"mlp-mixer---nips-2021\"\u003eMlp-mixer - \u003cem\u003eNIPS 2021\u003c/em\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003etitle: Mlp-mixer: An all-mlp architecture for vision\u003c/strong\u003e\u003c/p\u003e","title":"深度学习论文汇总1"},{"content":"CAM - CVPR 2015 Learning Deep Features for Discriminative Localization\n弱监督对象定位 - 仅提供Image level label\n期望：每个单元被其感受野内的某种视觉模式激活。因此 fk （表示空间位置 (x, y) 处最后一个卷积层中单元 k 的激活//输出特征图的一个像素）是该视觉模式存在的地图。类激活图只是这些视觉模式在不同空间位置的存在的加权线性和\n计算卷积特征图对于特定输出单元的重要性来实现的\n⭐⭐⭐网络可以保留其卓越的定位能力，直到最后一层 =\u0026gt; 深层特征的定位能力\n❗❗❗尽管接受了图像级标签的训练，CNN 仍具有出色的对象定位能力\n缺陷：卷积特征图→全局平均池化→softmax层 // 特定网络结构\n做法图示\r数学公式\r在卷积特征图上执行全局平均池化，并将它们用作全连接层的特征，产生所需的输出分类;\n❗❗❗将输出层的权重投影回卷积特征图来识别图像区域的重要性\nGrad-CAM - ICCV 2017 适用CNN模型\n但论文提到在CNN+LSTM的也能定位有区别的图像区域\nα 捕获特征图 k 对于目标类 c 的重要性 // 与CAM的分类线性层权重作用一致\nReLU的作用，只对对感兴趣的类别有积极影响的特征感兴趣。负像素可能属于图像中的其他类别\n上述操作 =\u0026gt; 具有类别区分性并且可以很好地定位相关图像区域 - 最后特征图比较小!\n但缺乏显示细粒度重要性的能力 （能区分猫狗，但对为什么识别为猫，不够精确）\r通过点乘法融合 引导反向传播 和 Grad-CAM =\u0026gt; 可视化\nGrad-CAM : 类别区分性\nGuided Backprop： 细节纹理重要程序。 做法：将梯度值小于等于零的部分置为零，保留梯度值大于零的部分 =\u0026gt; 以突出输入图像中对预测结果有积极影响的区域，来实现对神经网络中每个像素对最终预测结果的影响进行可视化和解释\n浅层卷积关注纹理特征，深层网络关注本质的那种特征？\nDETR - ECCV 2020 ⭐End-to-End⭐ Object Detection with Transformers\n传统：设置锚框 + 非极大值抑制(去除多余的框)\n创新：集合预测(预测分类 + 锚框)\n前向流程\r模型框架\rCNN backbone - local information fusion\nTransformer encoder - global information fusion\nobject queries - learnable information vector 作用： =\u0026gt; anchor\nFFN: 1. classification =\u0026gt; output class vector 2. box =\u0026gt; output 4 number [center_x, center_y, width, hight]\nobject queries: 作用就是锚框，并且一次性生成100个 \u0026raquo; 图片检测的物体数\n如何将object queries 与 groundtrue一一对应？\n匈牙利算法 寻找最佳匹配\n匹配loss = 分类loss(分类正确率) + 框loss(框的重叠度)\n=\u0026gt; 匈牙利算法 =\u0026gt; 哪些框与GT最佳匹配(预测框与GT一一对应)\n最终回传梯度优化参数LOSS = 分类loss(分类正确率) + [框loss + 与框大小无关的iou loss]\n因为框也是生成的，且Transformer容易出大框(全局建模)\nBert - 2018 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding - Computation and Language\nBidirectional Transformers 意思是\nTransformer Encoder中的自注意力计算是全局的，每个Token能观测到其余的Token序列； 而\nTransformer Decoder中由于进行的是Masked Multi Head Self Attention，所以序列只能观测到自己与之前的语境；\n这对于文本上下文语境建模是有弊端的！\n(生成式无监督学习)\n总体结构\n[CLS] 分类Token，凝聚全局语义信息\n[SEP] 分割符，划分句子范围\n用的某个语料库进行词嵌入\n⭐训练方法\n完型填空：使某个词随机被 [Mask] 字符遮挡；为防止模型对[Mask]字符敏感，遮挡时使用概率遮挡 =\u0026gt; 1. 仍替换为[Mask]字符 2.随机替换为其他字符 3. 保持不变 =\u0026gt; 迫使模型学习上下文语境 [句子内信息建模]\n预测下一句： [句子间信息建模]\n丰富的上下文信息：通过考虑单词的左右上下文，BERT 能够更好地理解词义和句法结构，这对于理解语言的复杂性至关重要。\nGPT generative pretrain transformer\n初略版\n模型图：(Transformer Decoder -仅Masked Attention版)\n⭐ input: word =\u0026gt; index(查找词汇表) =\u0026gt; embedding + position embedding\n[batch, sequence_length, embedding_dim]\t# sequence_length 可由多个句子组成，可以使用\u0026lt;s\u0026gt;标识句子结束，\u0026lt;pad\u0026gt;用来填充，使得sequence_length在batch内长度一致\n⭐ train：\nx1 =\u0026gt; x2\nx1, x2 =\u0026gt; x3\nx1, x2, x3 =\u0026gt; x4\n因为每个词都要预测下一个词，故使用masked attention （mask-softmax），防止答案泄漏\nCLIP - 2021 Learning Transferable Visual Models From Natural Language Supervision\n实现zero-shot，上游大数据集预训练好，下游任务迁移学习无需样本微调\n多模态模型的总体目标就是：训练一个模型，一方面能统一特征表达，另一方面又能让不同模态特征间学到相关性\n(判别式无监督学习)\n工作目的 痛点：\n在特点数据集上进行标签训练 =\u0026gt; 输入没见过的类别，那么模型就不能输出正确的结果\n数据出现分布偏移，动物图片与卡通动物图片 =\u0026gt; 识别不出来\n图片 - 文字描述 ， 模型学习配对关系\n一个对象的不同视角表示：图片和文本描述\n对比学习方法 （Train） Text Encoder (resnet/vit) 学习文本描述的 深度特征 - 单模态内特征 // T_i == 一个文本特征 Image Encoder(transformer) 学习图片的 深度特征 - 单模态内特征 // I_i == 一个图像特征 将多模态特征投影到跨模态空间 // 矩阵映射，(特征向量)到同一纬度 计算余弦相似度，很明显，正确配对的位置为对角线 计算Loss： （相似度logit作为预测分数） 按行计算Loss，在每一行范围内做softmax，然后计算cross_entropy（蓝色格子部分是真值）。这样计算Loss的意义是：对于每一张图片，我们都希望找到和它最相似的文字 按列计算Loss，在每一列的范围内做softmax，然后计算cross_entropy（蓝色格子部分是真值）。这样计算Loss的意义是：对于每一段文字，我们都希望找到和它最相似的图片 最后将这两个Loss相加取平均，代表我们在模型优化过程中考虑了“图片-\u0026gt;文字”和“文字-\u0026gt;图片”的双向关系 encoder均从头开始训练\n预测 创建一个标签全集， [f\u0026rsquo;A photo of a {object}\u0026rsquo; for object in dataset_labels] Text Encoder 学习上述 模板文字描述 的 深度特征 Image Encoder 学习 待预测图片 的 深度特征 计算余弦相似度 =\u0026gt; 取最高分作为预测目标 缺点 每次预测需要构建标签全集描述 对抽象任务，性能较差 Two-Stream - 2014 Two-Stream Convolutional Networks for Action Recognition in Videos\n⭐先前工作中通过使用堆叠视频帧作为网络的输入来解决此任务，但结果明显比最好的手工制作的浅层表示差。 =\u0026gt; 这可能表明学习的时空特征不能很好地捕捉运动（简单堆叠 =\u0026gt; 让模型从庞大的数据中学习❌很难） =\u0026gt; 模型很难识别该类特征 =\u0026gt; 预先处理成模型擅长的数据形式\n❗❗❗虽然多帧信息很重要，但以适当的方式将其呈现给 ConvNet 也很重要（饱和）\n信息显式建模 =\u0026gt; 可以简化学习过程\n创新点\n空间流从静止视频帧执行动作识别 时间流以识别密集光流形式的运动动作 =\u0026gt; 贴合人类视觉：识别物体 + 识别运动 =\u0026gt; ⭐[结果角度]表明两个识别流是互补的\n光流：帧帧之间像素变化(描述运动变化的数据形式) | 水平方向和垂直方向 \u0026lt;= 有用的线索 (与魔改模型不一样的思路)\n⭐⭐⭐此类输入明确描述了视频帧之间的运动 =\u0026gt; 这使得识别更容易 =\u0026gt; 因为网络不需要隐式估计运动 （显示建模）\n可以从光流数据 =\u0026gt; 时空局部特征 || 运动学特征 || 运动是使用光流位移场明确表示的\n模型框架（双模态）\n提高模型迁移能力 类似于CLIP的目的\n考虑将两个数据集合并为一个，由于类集之间的交叉，这并不简单\n=\u0026gt; 多任务学习 =\u0026gt; 最后生成多个分类头，对应两个数据集分类。混合多个数据集进行实验\nMOCO - CVPR 2020 Momentum Contrast for Unsupervised Visual Representation Learning\n(判别式无监督学习)\n目标：\n1️⃣ 构建一个足够大的动态词典，包含足够多的负样本，使模型真能够学到判别式的特征; 在海量数据中学到真正的样本分布\r2️⃣ 因为词典是动态变化的，为了使词典中的负样本特征尽可能的保持一致性(模型参数不同，时间维度上，得到的特征向量存在不一致性)，提出动量更新 =\u0026gt; 动量模型的缓慢更新确保了字典中的特征相对稳定，从而提供更一致的负样本，提升对比学习的效果。\r$$ θ_{k} ←mθ_{k} + (1 −m)θ_{q} $$ m ∈ [0, 1) 是动量系数。论文中Query Encoder 和Key Encoder是一样配置架构的编码器。 目的，缓慢的更新Key Encoder，构建一个又大又一致的动态词典。\n框架伪代码\npretext task ： 实例判别任务。目标拉近正样本对在特征空间的距离，并使负样本对尽可能的远离。\n1# f_q, f_k: encoder networks for query and key 2# queue: dictionary as a queue of K keys (CxK) 3# m: momentum 4# t: temperature 5f_k.params = f_q.params # initialize 6for x in loader: # load a minibatch x with N samples 7 x_q = aug(x) # a randomly augmented version 8 x_k = aug(x) # another randomly augmented version 9 10 q = f_q.forward(x_q) # queries: NxC 11 k = f_k.forward(x_k) # keys: NxC 12 k = k.detach() # no gradient to keys 13 14 # positive logits: Nx1 15 l_pos = bmm(q.view(N,1,C), k.view(N,C,1)) 16 17 # negative logits: NxK 18 l_neg = mm(q.view(N,C), queue.view(C,K)) 19 20 # logits: Nx(1+K) 21 logits = cat([l_pos, l_neg], dim=1) 22 23 # contrastive loss, Eqn.(1) 24 labels = zeros(N) # positives are the 0-th 25 loss = CrossEntropyLoss(logits/t, labels) 26 27 # SGD update: query network 28 loss.backward() 29 update(f_q.params) 30 31 # momentum update: key network 32 f_k.params = m*f_k.params+(1-m)*f_q.params 33 34 # update dictionary 35 enqueue(queue, k) # enqueue the current minibatch 36 dequeue(queue) # dequeue the earliest minibatch 两个不同视角的同一张图片为正样本对，不同图片为负样本对。\n抽特征：q, k； 最大化q k相似且与负样本远离\n更新Q_Encoder, 使用Q_Encoder参数更新K_Encoder，动量缓慢更新\n无监督预训练后好，取Q_Encoder作为抽取特征骨干网络，冻结其参数，微调分类头，在进行泛化测试\nMAE - CVPR2022 Masked Autoencoders Are Scalable Vision Learners\n非对称掩码自动编码器；Encoder和Decoder架构可以不同\n(生成式无监督学习)\nCV领域的Bert\n⭐NLP与CV的不同：\n信息密度不同\nNLP：句子信息语义很高，信息密度也高。（人类语言-事先浓缩过的信息）\n视觉：信息很冗余，也没高级的语义（自然界），像素可以被相邻的重建恢复\n恢复难度不一致\n恢复高级语义单词和恢复像素级(低级语义)图片，难度也不一样。 框架：\nEncoder：位置编码所有Patch都加上。但仅输入未被Mask的Patch。并且Mask比例很高(论文mask75%patch)，迫使模型学到高维的特征，而非捷径。\nDecoder：Mask Patch是自学习的向量，并且和Encoded Patch在位置上一致，再次添加位置信息。\n简单实现（shuffle，截取前面的作为Encoder输入，后面Patch被Mask；再shuffle逆操作，将Encoded Patch和learnabel patch位置对齐组合好进行Decoder。再重建像素）\n通过预测每个屏蔽补丁的像素值来重建输入。解码器的最后一层是线性投影，其输出通道的数量等于补丁中像素值的数量。\n损失函数计算像素空间中重建图像和原始图像之间的均方误差。\n问题：\n预训练的输入中具有很大一部分掩码标记，而这在下游任务未损坏的图像中不存在。这种差距可能会降低部署的准确性。\r自监督学习方法通常侧重于预训练的不同借口任务。\n对比学习对两个或多个视图之间的图像相似性和相异性进行建模。\nwav2vec 2.0 - NeurIPS 2020 wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations\n时序信号版本的Bert\n[自监督]学习通用特征 =\u0026gt; 再微调任务头\n(判别式无监督学习)\n总体框架：\n1️⃣ 原始信号[X] =CNN=\u0026gt; 浅在特征表示 [Z]\n2️⃣ 浅在特征表示 [Z] =Transformer Encoder=\u0026gt; 全局上下文特征表示 [C]\n3️⃣ 浅在特征表示 [Z] =量化器=\u0026gt; 对比目标[Q]\n把原来连续的特征空间假设是d维，拆分成G个子空间（codebook），每个子空间维度是d/G。 然后分别在每个子空间里面聚类（K-mean什么的），一共获得V个中心和其中心特征。 每个类别的特征用其中心特征代替。 量化qt和对应ct\n❌ Quantization module 部分不理解\nMask\n随机起点，遮挡后面t个时间步\n对比损失\n![image-20240411210912407](http://sthda9dn6.hd-bkt.clouddn.com/FqYwQ0MDlAXtdrK4q6VHMuWRn3km)\r包括 qt 和 K 个干扰项\n❗❗❗理解不太清晰\nWhisper - 2022 OpenAI Robust Speech Recognition via Large-Scale Weak Supervision\n大力出奇迹\n模型结构\n多任务训练\n[英文口语=\u0026gt; 英文] 语音识别\n[多语言口语 =\u0026gt; 英文] 语音识别 +翻译\n[多语言口语 =\u0026gt; 对应语言文字] 语音识别\n识别背景音(无内容声音)\n⭐⭐⭐信号 =\u0026gt; Log-Mel Spectrogram(频谱图)\n音素\n⭐⭐⭐数据集\n680k小时，超大数据集。 在此基础上预训练，并且0样本迁移(无需特定任务微调)\nCPC - Machine Learning 2018 Representation Learning with Contrastive Predictive Coding\nContrastive Predictive Coding - 无监督学习\n通过预测未来，学习特征表示 (学习对(高维)信号不同部分之间的底层共享信息进行编码的表示 - 局部平滑度)\n不预测原始信号，而是对高维嵌入依赖建模\n(判别式无监督学习)\nCPC框架\n$$ g_{enc}: local\\ feature\\ learning\\ g_{ar}: global\\ context\\ learning $$\n对比学习\n1# 序列： [x1, x2, x3, x4, x5, x6, x7, x8] 2 3# positive sample 4# x1, x2, x3, x4 =\u0026gt; c \u0026lt;=\u0026gt; x5, x6, x7, x8 5 6# negative sample 7# x1, x2, x3, x4 =\u0026gt; c \u0026lt;=\u0026gt; xa, xb, xc, xd (同batch中其他的) 迫使模型学习序列间的high level feature，学习这种内部的顺序逻辑关系\n互信息公式 - 衡量两个随机变量之间的相互依赖程度 $$ I(x;c)=\\sum_{x,c}p(x,c)\\log\\frac{p(x|c)}{p(x)}. \\ I(x;c): x 与 c 的互信息\\ p(x,c): x 和 c 同时发生的联合概率分布\\ p(x|c): 给定 c 的条件下，x 发生的条件概率分布\\ p(x): x 的边缘概率分布 $$ InfoNCE Loss\n最小化CPC定义的损失 =\u0026gt; 实际上最大化 context c_t 和待预测正样本 X_t 之间的互信息\n优化目标：最大化似然概率\n正相关\n近似计算互信息\nLoss\nX = {x1, x2, \u0026hellip;, xN} N个负样本，从batch中其他数据中采样\nE/X 表示似然概率\n最大化互信息 =\u0026gt; 最小化Loss (互信息下界)\n完整InfoNCE-Loss $$ \\text{InfoNCELoss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\text{exp}(s(x_i, x_i^+))}{\\text{exp}(s(x_i, x_i^+)) + \\sum_{j=1}^{K} \\text{exp}(s(x_i, x_j^-))} $$\n不太了解这个最大化互信息的Loss\nDALL·E 2 - 2022.3 OpenAI Hierarchical Text-Conditional Image Generation with CLIP Latents\n层级式图生文\n模型架构\n描述：\n虚线上是CLIP架构(文本和图像的联合表示空间)，学习图文对的关联信息 虚线下是生成框架，prior模型根据Text Embedding生成出CLIP对应的Image Embedding， decoder(diffussion model)根据Image Embedding进行重建 ⭐分步训练\nprior\n生成CLIP image Embedding (diffusion model)\ndecoder\n是根据image Embedding生成图片 \u0026ndash; 并且这个decoder是多个堆叠，先生成低分辨率，再高清化 - (diffusion model)\n简洁表示：\ny - 文字\nx - 图片\nzi - 图片嵌入 （显式生成图像表示可以提高图像多样性，同时将照片真实性和标题相似度的损失降至最低）\ndiffusion model - NeurIPS 2020 Denoising Diffusion Probabilistic Models\n框架：\n加噪 + 去噪(还原)\n正向过程：\n1️⃣ Xt 是 前一张图片加噪生成的，Z1是服从正太分布的噪声\nβt是超参数=范围为[0.0001,0.02]递增，则αt 是随时间减少， 表示公式一中原图信息越来越少，噪声越来越重\n2️⃣ 递推带入一下\n最后可得···\nZt_hat 是一个服从正太分布的随机噪声，at_hat = at*at-1*···*a1, 可由X0直接产生任意时间步的加噪图片\n反向去噪过程：\n核心基础\n1️⃣ 用Xt生成Xt-1 ，按贝叶斯公式转换\n2️⃣ q(Xt|Xt-1) == q(Xt|Xt-1, X0)， 而q(Xt-1) == q(Xt-1|X0) 任意步加噪图可由原图直接产生\n3️⃣ 反解公式7， X0可由Xt进行估计\n4️⃣ 带入并整理\n··· 因此可根据Xt =\u0026gt; Xt-1， 下式为最终的去噪公式 $$ x = \\frac{1}{\\sqrt{\\alpha}} \\left( x - \\frac{1 - \\alpha}{\\sqrt{1 - \\alpha_{\\text{hat}}}} \\cdot \\text{predicted_noise} \\right) + \\sqrt{\\beta} \\cdot \\text{noise} $$ β noise 保证多样性\nƐθ表示预测模型\n代码逻辑\n训练：\n1for i, images in enumerate(pbar): 2 images = images.to(device) 3 t = diffusion.sample_timesteps(images.shape[0]).to(device)\t# 采样几个时间步进行训练 4 x_t, noise = diffusion.noise_images(images, t)\t# @ 公式-7 5 predicted_noise = model(x_t, t)\t# Unet 6 loss = mse(noise, predicted_noise) 7 8 optimizer.zero_grad() 9 loss.backward() 10 optimizer.step() 11 12sampled_images = diffusion.sample(model, n=images.shape[0]) # @ 去噪公式 预测模型\nUnet 带时间点嵌入(用余弦-位置嵌入实现的)\n1def forward(self, x, t): 2 t = t.unsqueeze(-1).type(torch.float) 3 t = self.pos_encoding(t, self.time_dim)\t# 嵌入时间步顺序 4 5 x1 = self.inc(x)\t# cnn 6 x2 = self.down1(x1, t) # pooling 7 x2 = self.sa1(x2)\t# self attention 8 x3 = self.down2(x2, t) 9 x3 = self.sa2(x3) 10 x4 = self.down3(x3, t) 11 x4 = self.sa3(x4) 12 13 x4 = self.bot1(x4)\t14 x4 = self.bot2(x4) 15 x4 = self.bot3(x4) 16 17 x = self.up1(x4, x3, t)\t# 插值上采样，再拼接skip connect 18 x = self.sa4(x) 19 x = self.up2(x, x2, t) 20 x = self.sa5(x) 21 x = self.up3(x, x1, t) 22 x = self.sa6(x) 23 output = self.outc(x) 24 return output p(Xt-2|Xt-1, t, y) t是时间步嵌入，y是条件嵌入\n最简单的融合方法就是相加\n？？？ 疑惑点 - 反向过程求的t时刻的均值方差用在哪了？\n2025/1/14 更新：\n// X =\u0026gt; X_noise_t 可以一步生成，可以时间步t可以直接生成对应t时间步的噪声图。\n// 使用U-net预测时间步t的噪声 使用MSE-Loss进行训练\n1# 训练循环 2for epoch in range(num_epochs): 3 for x_0 in dataloader: # x_0 是原始数据 4 # 1. 随机选择一个时间步 t 5 t = torch.randint(0, T, (x_0.size(0),)) # 为每个样本随机选择一个时间步 6 7 # 2. 前向过程：添加噪声 8 epsilon = torch.randn_like(x_0) # 采样噪声 9 alpha_bar_t_t = alpha_bar_t[t].view(-1, 1, 1, 1) # 选择对应时间步的 alpha_bar_t 10 x_t = torch.sqrt(alpha_bar_t_t) * x_0 + torch.sqrt(1 - alpha_bar_t_t) * epsilon # 添加噪声 11 12 # 3. 反向过程：预测噪声 13 predicted_epsilon = model(x_t, t) # 模型预测噪声 14 15 # 4. 计算损失函数 16 loss = F.mse_loss(predicted_epsilon, epsilon) # 均方误差损失 17 18 # 5. 反向传播和优化 19 optimizer.zero_grad() 20 loss.backward() 21 optimizer.step() // 串行，一步一步去噪\n1# 生成过程 2def generate_samples(model, num_samples, T, alpha_bar_t): 3 x_T = torch.randn(num_samples, ...) # 从标准正态分布中采样初始噪声 4 for t in range(T-1, 0, -1): # 从 T-1 到 1 5 # 预测噪声 6 epsilon = model(x_T, t) 7 8 # 计算去噪后的数据 \u0026lt;= 消除噪声 9 alpha_t = alpha_bar_t[t] / alpha_bar_t[t-1] 10 x_T = (x_T - torch.sqrt(1 - alpha_t) * epsilon) / torch.sqrt(alpha_t) 11 12 return x_T Time-Frequency Consistency - NeurIPS 2022 Self-Supervised Contrastive Pre-Training for Time Series via Time-Frequency Consistency\n期望同一示例的基于时间和基于频率的表示在时频空间中靠近在一起\n(判别式无监督学习)\npretext task：实例判别 (一对正样本，其余负样本)\n框架\n时域增强：基于时间特性从 xi 扩充，包括抖动、缩放、时移和邻域分段；\n频域增强：频谱特征扰动 xFi 的增强，添加或删除频率分量来扰动频谱 (确保扰动时间序列仍然与原始样本在频域和时域仍相似)\nLoss：\n余弦相似度：衡量两个向量之间相似性，范围[-1, 1]\n// 补充 2025/1/14\n样本越相似 =\u0026gt; sim(i, j) 越大 =\u0026gt; exp(sim) 越大 =\u0026gt; exp(sim)/\\sum(exp) 越接近于1 =\u0026gt; log(·)越接近于0\n-log(·) 将图像倒置，样本越不相似 =\u0026gt; exp(sim)/\\sum(exp) 越接近于0 =\u0026gt; loss 越大\nCOMET - NeurIPS 2023 Contrast Everything A Hierarchical Contrastive Framework for Medical Time-Series\n(判别式无监督学习)\n我们的方法旨在弥合标记数据的有限可用性与医疗时间序列分析中稳健且可概括的模型的需求之间的差距 对比表示学习背后的关键思想是通过将相似的数据靠近在一起并将不相似的数据进一步分开来挖掘数据一致性 关键是要利用所有可用的信息；除了样本标签之外，数据集是否还有其他信息？(补充信息)\n患者间、患者内进行测试(定义打乱规则)\n⭐⭐⭐多级信息\n多级对比学习框架\n代码分析总结\n1X_train.size == [Batch, channels, segment] # segment length 330, sampling_rate = 250Hz 2y_train # 心肌梗塞二分类标签， patient_id， segment_id 细分为样本级别(心跳)，故图示Encoder不同级别对比学习可复用\n关键，计算不同级别的对比Loss\nPatient-Level Loss\n1x = [Batch, channels, segment] 2 3out1 = net(x) 4out2 = net(x) # ? 模拟数据增强后的不同视角或版本，以便在对比学习中生成有效的正例和负例 5 6# 根据y_train 病人id，构建mask矩阵 7pid1, pid2 = np.meshgrid(str_pid, str_pid)\t8pid_matrix = pid1 + \u0026#39;-\u0026#39; + pid2\t# 每项为 id_x - id_y\t9# 目标位置 id_x - id_x 10pids_of_interest = np.unique(str_pid + \u0026#39;-\u0026#39; + str_pid) # unique combinations of pids of interest i.e. matching 11bool_matrix_of_interest = np.zeros((len(str_pid), len(str_pid))) 12for pid in pids_of_interest: 13 bool_matrix_of_interest += pid_matrix == pid 14 15# 上三角和下三角目标row，col 16rows1, cols1 = np.where(np.triu(bool_matrix_of_interest, 1)) # upper triangle same patient combs 17rows2, cols2 = np.where(np.tril(bool_matrix_of_interest, -1)) # down triangle same patient combs 18 19out1, out2 =\u0026gt; sim_matrix_exp # 余弦相似度矩阵 20 21# @@ 对比学习：不考虑对角线元素的原因主要是因为对角线元素表示的是特征向量与其自身的相似度 22# @@ 我们关注的是如何使具有相同标签的不同特征向量之间更相近，而使不同标签的特征向量之间更疏远 23 24# Loss 分母， 某样本与其他样本相似度之和， @分上三角和下三角 25triu_sum = torch.sum(sim_matrix_exp, 1) # add column 26tril_sum = torch.sum(sim_matrix_exp, 0) # add row 27 28loss_terms = 0 # 取平均 29if len(rows1) \u0026gt; 0: 30 triu_elements = sim_matrix_exp[rows1, cols1] # row and column for upper triangle same patient combinations 31 loss_triu = -torch.mean(torch.log(triu_elements / triu_sum[rows1])) 32 loss += loss_triu # technically need to add 1 more term for symmetry 33 loss_terms += 1 34... 35 36loss = loss/loss_terms Trial-Level Loss\n同上，只不过patient_id =\u0026gt; segment_id\n❌❌❌Sample-Level Loss \u0026amp; Observation-Level Loss\n看不懂源码~ 😎😭\nTS2Vec - AAAI 22 TS2Vec: Towards Universal Representation of Time Series\n(判别式无监督学习)\n现存工作局限：\n它们都没有以不同尺度的时间序列为特征来捕获尺度不变的信息，而这对于时间序列任务的成功至关重要。多尺度特征可以提供不同级别的语义并提高学习表示的泛化能力 粗粒度表示 - 整个时间序列，可能没那么细致 之前工作的问题\n正样本对会误判\n当存在水平偏移时，子系列一致性很容易受到攻击 (左图) 当出现异常时，时间一致性可能会引入误报对 (右图) 创新：\nTS2Vec 中的对比目标基于增强上下文视图，即相同子系列在两个增强上下文中的表示应该是一致的 (上下文语境下) 层级式对比Loss，由细粒度=\u0026gt;粗粒度，局部到全局 # 学习各种语义级别的任意子系列的上下文表示，灵活且通用的表示。 顶级语义级别的对比使模型能够学习实例(样本)级表示 框架\n流程：\n实例(一段信号)，分两个重叠的子序列, [batch, channel, dim_feature] 投影，[batch, channel, dim_feature] =\u0026gt; [batch, channel, dim_hidden] 随机Mask掉部分信号 CNN-Encoder ⭐⭐⭐ Hierarchical Contrasting Loss\ninstance \u0026amp; temporal contrastive loss\n![image-20240425172445164](http://sthda9dn6.hd-bkt.clouddn.com/FjeDH748BsrYQtTOEOmSjYW_SEMr)\r*用 -F.log_softmax(x, dim=-1) 实现*\rz1 = F.max_pool1d(z1.transpose(1, 2), kernel_size=2).transpose(1, 2) z2 = F.max_pool1d(z2.transpose(1, 2), kernel_size=2).transpose(1, 2)\n编码特征浓缩，多尺度的Contrast loss\n图示Loss过程\n子序列是从原始信号中裁剪下来的，并且有重叠部分\nTimesURL - AAAI 2024 TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning\n代码在TS2Vec上修改\n=\u0026gt; 在这里，我们必须提到，重要的时间变化信息，例如趋势和季节，在多次最大池化操作后会丢失，因此顶层对比实际上无法为下游任务捕获足够的实例级信息\n=\u0026gt; 掩码重建进行学习实例级信息\n(判别式+生成式 混合 无监督学习)\n观察\n**简单负样本：**大多数时间序列片段可以被视为容易负样本。 这些片段往往表现出与锚点的语义差异，并且仅贡献较小的梯度，因此无法提供有用的区分信息\n硬负样本： 硬负样本就是离正样本很近，并且模型很难区别的\n正样本-硬负样本-负样本：，这些样本如果让其远离正样本可以大大提高模型性能。 其有效性被大量的简单负样本所掩盖。（现存框架没有特点显示的指出）\n由于时间序列中的局部平滑性和马尔可夫特性，大多数负样本很容易不足以捕获时间信息，因为它们从根本上缺乏驱动对比学习所需的学习信号。 作为图 2 中真实示例，对于每个正锚点（红色方块），相应的负样本（灰色标记）包含许多简单的负样本和很少的困难负样本，即许多负片太远，无法造成对比损失。\n对比学习的一个关键组成部分是选择适当的增强，这些增强可以施加一些先验来构建可行的正样本，以便编码器可以被训练来学习鲁棒和有区别的表示\n频率混合用于通过将通过快速傅里叶变换（FFT）运算计算出的一个训练实例 xi 中的一定比例的频率分量替换为同一批次中的另一个随机训练实例 xk 的相同频率分量来生成新的上下文视图 （保持病理相同）\n随机裁剪。 重叠两个子序列 - 随机裁剪是上下文一致性策略的关键步骤。 它可以保持时间序列的重要时间关系和语义一致性\n创新点：\n提出双Universum概念，就是利用Mix-up增强F(x)，追加硬负样本。 对比学习+自监督掩码重建，联合优化，来捕获段级和实例级信息， 实现通用表示 ⭐ 第一类包括预测、异常检测和插补，它们更多地依赖于在分段级别捕获的细粒度信息，因为这些任务需要推断特定的时间戳或子序列。细粒度(局部)\n⭐ 第二类包括分类和聚类优先考虑实例级信息（即粗粒度信息），旨在推断整个系列的目标。粗粒度(全局)\n实现 : 分段(对比学习，学习片段)，整句(掩码重建，学习整体)\n框架：\nAUG：\n频率增强，**x =\u0026gt; fft() =mask+fusion=\u0026gt; ifft() =\u0026gt; y**，①该篇论文fusion是融合同batch其他信号的某些部分 =\u0026gt; 领域创新 （fusion的信号应该和这个信号相同病理，扩张数据分布）\rDualConv：\n原始信号的两个增强子视图，z1 = Encoder(x1), z1' = Encoder(x1'), =\u0026gt; mix-up option =\u0026gt; **z1_mix = α × z1 + (1-α) × z1[torch.randperm(z1.shape[0])]**，z1'_mix。 [z1, z1', z1_mix, z1'mix] @ [z1, z1', z1_mix, z1'mix].T =\u0026gt; sim =\u0026gt; **-F.log_softmax(sim)**\rloss: 俩视图对应段为正样本(分子)\r负样本在母分，x_mix做负样本增强。\nMixup - 2017 Machine Learning mixup: BEYOND EMPIRICAL RISK MINIMIZATION\n一种简单并且不需要专业领域知识的数据增强\n现存问题讨论：\n过拟合(大模型，直接记忆Train data，走捷径) - overfitting 精心设计样本(对抗性例子，人难以察觉，但模型会给出错误的答案) - generalize 👇\nERM(经验风险最小化原则)问题\n一方面，即使存在强正则化，ERM 也允许大型神经网络记忆（而不是归纳）训练数据 另一方面，使用 ERM 训练的神经网络在对训练分布之外的示例进行评估时会极大地改变其预测。 CV: 图像的邻近区域定义为其水平反射、轻微旋转和轻微缩放的集合\n=\u0026gt; 数据增强始终可以提高泛化能力, 但该过程依赖于数据集，因此需要使用专家知识 （不同领域增强不一定通用）\n数据增强假设邻近的示例共享同一类，并且不会对不同类的示例之间的邻近关系进行建模。(聚类)\n=\u0026gt; 邻近风险最小化 (VRM) 原则\n⭐=\u0026gt; 从训练样例的邻近分布中提取额外的虚拟样例，以扩大训练分布的支持度\n方法：\n框架伪代码：\n图例：\n虚拟数据，让数据边界过渡； 当不在Train数据的分布出现时，降低不确定性。 稍微清晰化边界\nYOLO-v1 - CVPR 2016 You Only Look Once: Unified, Real-Time Object Detection\n⭐将目标检测视作回归问题 =\u0026gt; 预测出来\n前向推理\nModel:\ninput: [3, 448, 448] =\u0026gt; output: [30, 7, 7]\n置信度(confidence): 这个值代表了模型认为预测的边界框内存在对象的概率\n框的中心坐标 + 宽高\n框中的物体是什么类\n非极大值抑制 （最佳：每个类别独立执行非极大值抑制，从而更精确地处理多类别情况）\n置信度排序：首先将所有的预测边界框按照它们的置信度（confidence scores）进行降序排序。 选择最高置信度边界框：从排序后的列表中选择置信度最高的边界框作为参考框（reference box）。 计算IOU：计算选中的参考框与列表中其他所有边界框的交并比（IOU）。交并比是两个边界框的交集面积与它们的并集面积的比值。 抑制：如果参考框与任何其他边界框的IOU超过预先设定的阈值（通常设置为0.5），那么这些边界框会被认为是多余的，并从列表中删除。 重复步骤：从剩余的边界框列表中再次选择置信度最高的边界框，重复上述过程，直到所有的边界框都被处理完毕。 最终结果：经过非极大值抑制后，剩余的边界框被认为是对目标位置的最佳预测，它们将被用于最终的目标检测输出。 训练：\nλcoord = 5, λnoobj = 0.5, 调整各个部分的重要性 $$ 1_{ij}^{obj}: 表示第ij个格子有对象 \\ 1_{ij}^{noobj}: 表示第ij个格子没有对象\\ S^{2}: 图片划分格子 \\ B: 每个格子预测多少个框 $$ bounding box loss : 中心点 + 框宽高\nconfidence: 格子是否有对象\nclasses：格子分类是否正确\nSemi-Supervised Hybrid Loss - Machine Learning 2023 Semi-Supervised End-To-End Contrastive Learning For Time Series Classification\n1️⃣无标签数据对比学习(增强视图一致性)，2️⃣有标签对比学习(相同种类一致性)，3️⃣有标签分类监督学习\n(判别式无监督学习 + 有监督学习)\n框架对比\n⭐ End to End\n框架\nUnlabeled Sample : 使用两个增强视图作为positive pair，与其他sample为negative pair (标准的对比学习)\nLabeled Sample：1️⃣ 同类型的sample为positive pair，不同类型的sample为negative pair. 2️⃣过分类头，计算分类Loss\n❤️ 混合上述三个Loss，联合优化Encoder\nSimCLR - 2020 A Simple Framework for Contrastive Learning of Visual Representations\n贡献：\n数据增强对于对比学习至关重要 (裁剪缩放，翻转，颜色紊乱，旋转， 掩盖， 高斯噪声， 高斯模糊，Sobel 滤波) - 裁剪缩放+颜色紊乱 比较好\n在经过Resnet编码器后，追加MLP能增强模型性能\n样本x，增强视图xi和xj(正样本)，batch size =N，一共2N的增强视图，对于某个样本x，xi和xj为正样本，和batch中剩余的样本的增强为负样本\n(大batchsize, 性能更好， 全局BN)\n样本自成一类，来尽可能地让编码器找到图像中最重要的特征\n框架\n共享参数 shared weight\nLoss\n上面是正样本对，下面是负样本对 -log_softmax() =\u0026gt; 挑选出需要的值\n算法\nViLT - 2021 ViLT Vision-and-Language Transformer Without Convolution or Region Supervision\n极简结构的图片文多模态融合\n速度限制-问题分析\n归纳总结：\n(a) vision embedding 参数量 \u0026gt; Text Embedding \u0026gt; Modality Interaction # 缺点，视觉嵌入太重(比重太大)，并且融合非常简单即点乘算相似度\n(b) vision embedding和Text embedding 占比差不多 \u0026gt; Modality Interaction # 模态融合之前，工作太繁杂，而且前抽取特征不好，限制后面融合，并且不重视后面的模态融合操作。\n(c) 重视visual Embed和后期的modality interaction，# text 和 vision不均等，重要性不平衡\n=\u0026gt; 简单框架，Text词嵌入(bert中的BertEmbeddings加载训练后的权重)，vision用patch projection，都很快\n⭐ 1. 图像和文本前期嵌入应该有相似均匀的表达能力 2. 这两种模态是否在深层网络中相互作用。\n模型框架：\n初始化参数-ViT，而不是bert\n优化目标(主要)：\nImage Text Matching：0.5概率将图片替换为与文本不匹配的图片，预测一致性(二分类问题) Masked Language Modeling：预测被遮掩的词 text cls: 预测图文是否一致，二分类\ntext token set： 全局上下文=\u0026gt;预被掩词\ntext token set 和 visual token set：进行对齐Loss\nBEIT-v3 2022 Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks\n统一Vision 和 NLP\n⭐ 核心思想是图像可以被建模为一门外语，这样我们就可以对图像、文本和图文对进行统一的掩码“语言”建模。\n结果非常好\n基础块\n共享注意力矩阵(都是一个物体的不同视角)，但是最后的FFN各个模态专享\n拓展到不同的模态：\n任务：\n图像字幕任务：采用了特殊的自注意力掩模。 图像标记（即图像块）只能在图像序列内双向相互关注。 标题的标记可以关注图像标记、它们的左侧标题标记以及它们本身。 在微调过程中，我们随机屏蔽一定比例的标题标记。 该模型经过训练，可以根据图像的线索及其左侧标题上下文来恢复这些标记。 我们还屏蔽了特殊的边界标记 [SEP]，以帮助模型学习终止生成\n视觉问答： 将任务表述为分类问题。 该模型经过训练，可以从训练集中 3129 个最常见的候选答案中预测答案。我们将给定问题和图像的嵌入连接起来，然后将输入嵌入输入多路转换器以联合编码图像-问题对。 最终的池化输出被输入到分类器层来预测答案。\n**图像文本检索任务：**是测量图像和文本之间的相似度。 根据检索目标的模态，有两个方向：图像到文本检索和文本到图像检索。 双编码器模型分别对图像和文本进行编码以获得它们的表示。 然后我们计算这些表示的余弦相似度分数。\n图像分类： 将该任务制定为图像到文本检索任务。 我们使用类别名称作为文本来构建图像-文本对。 BEIT-3 被训练为双编码器，以找到图像最相关的标签。 在推理过程中，我们首先计算可能的类名的特征嵌入和图像的特征嵌入。 然后计算它们的余弦相似度分数以预测每个图像最可能的标签。\nALBEF - 2021 Align before Fuse: Vision and Language Representation Learning with Momentum Distillation\n现存问题：大多数现有方法采用基于变压器的多模态编码器来联合建模-视觉Token（基于区域的图像特征）和文本Token。 由于视觉标记和单词标记未对齐，因此多模态编码器学习图像文本交互具有挑战性。\n（1）图像特征和文本符号映射仍然停留在他们自己的空间，使得多模态编码器很难学习建模他们之间的交互；\n（2）物体检测器 \u0026mdash; 标注费钱，使用费算力 \u0026mdash; 在预训练阶段需要标注矩形框，在推理阶段高分辨率图像，如 600*1000，速度较慢；\n（3）广泛使用的 image-text 数据集均是从网上搜集的带有严重噪声的数据，现有的预训练目标，如 MLM 可能过拟合到文本数据，降低了模型的泛化性能。\n框架：\nimage encoder: ViT(ImageNet预训练参数) - CLS token\ntext encoder: Bert(预训练参数) - CLS token\nmultimodal encoder: Bert(预训练参数) + cross-attention\n⭐ **在传入multi-modal encoder前，使用ITC迫使模型进行对齐 ** align before fuse的align\n对齐图像特征和文本特征，使多模态融合编码器更容易执行跨模态学习 改进了单模态编码器，以更好地理解图像和文本的语义 它学习一个共同的低维空间来嵌入图像和文本，这使得图像文本匹配目标能够通过我们的对比硬负挖掘找到更多信息样本。 Image-Text Contrastive Loss：\n正样本对：配对的Image-Text\n负样本对：Queue存储着的样本表示\nImage =\u0026gt; 匹配Text-Queue(Momentum)\nText =\u0026gt; 匹配Image-Queue(Momentum)\n(代码中利用了Momentum Distillation \u0026hellip;)\nImage-Text Matching:\n有了multi-modal encoder输出的 embed token (正确样本的表征) =\u0026gt; 即喂入Multi-modal encoder的 text embed = (positive), Image embed = (positive), 拿融合的CLS作为最终表征，过MLP =\u0026gt; 二分类预测是否匹配；这部分Targets=(1, 1, \u0026hellip;, 1)\n从同batch中，按相似性大小随机挑选一个(hard)负样本，\n然后，text embed = (positive, \u0026hellip;, negetive, \u0026hellip;) , Image embed = (negetive, \u0026hellip;, positive)\nmulti-modal encoder =\u0026gt; CLS =\u0026gt; MLP =\u0026gt; two probability\nTargets = (0, 0, \u0026hellip;, 0)\n// 重新梳理如下：\n1# 图像i-文本j =\u0026gt; 多模态编码器 =\u0026gt; 是否匹配； 2图像 1-文本 1 : 匹配对 3图像 2-文本 2 : 匹配对 4图像 1-文本 2 : 不匹配 // 这里使用余弦相似度选取最困难的样本 5图像 2-文本 1 : 不匹配 // 这里使用余弦相似度选取最困难的样本 Masked Language Modeling:\n屏蔽掉一些词，通过从图片模态信息中预测掉被屏蔽的词(多分类Loss)\n这里也借助了图像的信息去更好的恢复被mask掉的单词\n【这里只对匹配的对计算 掩码Loss】\n目的：缓解noisy web data的不足，真正的label不一定有momentum的好\n真实label不一定比momentum model给出的predict label好，=\u0026gt; 使用KL散度进行约束 一致性\n最大化互信息视角解释：\n在自监督学习中，a 和 b 是同一图像的两个增强。 在视觉语言表示学习中，我们将 a 和 b 视为捕获其语义的图像文本对的不同变体。 我们的目标是学习对观点变化不变的表征。\n最小化Loss =\u0026gt; 最大化互信息的下限(最大化了图像-文本对的**不同“视图”**之间的互信息（MI）的下限)\nInfoNCE Loss\nImage-Text Contrastive Loss\n最大化Text和Image中的互信息， ITC 将两个单独的模态（即 I 和 T）视为图像-文本对的两个视图\nMLM:\nMLM 将图像-文本对的两个视图视为：(1) 随机选择的单词标记，以及 (2) 图像 + 带有该单词屏蔽的上下文文本。\nInstance discrimination - 2018 Unsupervised Feature Learning via Non-Parametric Instance Discrimination\n首次提出个体判别任务！\n观察：\n在监督学习中。在预测\u0026rsquo;花豹\u0026rsquo;时，预测概率除了\u0026rsquo;花豹\u0026rsquo;，剩余预测得分比较高的是\u0026rsquo;美洲虎\u0026rsquo;、\u0026lsquo;猎豹\u0026rsquo;； 最不相似的是\u0026rsquo;救生艇\u0026rsquo;、\u0026lsquo;购物车\u0026rsquo;、\u0026lsquo;书柜\u0026rsquo;;\n最高响应的类都是视觉相关的\n⭐ 并不是语义标签，而是数据本身的明显相似性使某些类比其他类更接近；\n❗❗❗ 个体判别：将类监督发挥到了极致，并学习了区分各个实例的特征表示。\n这些观察结果表明，典型的判别学习方法可以自动发现语义类别之间的明显相似性，而无需明确指导这样做。\n我们能否通过纯粹的判别学习来学习反映实例之间明显相似性的有意义的度量？ 图像本身就是独特的，并且每个图像都可能与同一语义类别中的其他图像显着不同。如果我们学会在没有任何语义类别概念的情况下区分各个实例，我们最终可能会得到一个捕获实例之间明显相似性的表示，就像类明智的监督学习如何仍然保留类之间的明显相似性一样。\n目标:\n在没有监督的情况下学习嵌入函数 v = fθ(x)。 fθ 是一个具有参数 θ 的深度神经网络，将图像 x 映射到特征 v。这种嵌入将在图像空间上产生一个度量，对于实例 x 和 y, dθ(x, y) = |fθ(x) − fθ(y)|。 良好的嵌入应该将视觉上相似的图像映射得彼此更接近。 我们新颖的无监督特征学习方法是实例级区分。 我们将每个图像实例视为其自己的不同类，并训练分类器来区分各个实例类。\r方法：\n用一个memory bank存储4096个样本embed feature(128-dimention) 随着网络更新, 目的是让特征在嵌入空间中远离(每一个样本都是一个类)，学习那种有监督时类和类之间相似聚集的现象。\nBYOL - 2020/6 Bootstrap Your Own Latent A New Approach to Self-Supervised Learning\n1无监督学习： { 2 判别式：从增强视图的表示中，他们学会区分同一图像的另一个增强视图的表示和不同图像的增强视图的表示 =\u0026gt; 这种判别方法通常需要将增强视图的每个表示与许多反例进行比较。 3 生成式：通过预测同一图像的不同视图（例如，不同的随机裁剪）来学习表示 =\u0026gt; 图像的增强视图的表示应该能够预测同一图像的另一个增强视图的表示。 4} 方法：\n在线网络θ + 目标网络γ(提供回归目标，γ = α×γ + (1-α)×θ ，指数移动平均 )\nyθ是目标编码器，其余的训练好后丢掉\n⭐一张图片的两个增强表示的相同的语义 =\u0026gt; 在高维的嵌入表示中，应该可以预测对方(相近)\n1yθ：Encoder 2zθ：Projection head 3qθ：Prediction head Loss: $$ 注意图像增强t(x)和t^{}x会对等的传给online\\ net 和 target\\ net\\\\\rLoss: 1/2 × ( || q_{θ}(z_{θ}) - z^{}{ξ}||^{2} + || q{θ}(z_{θ}) - z^{`}_{ξ}||^{2} ) $$ Train: $$ θ：online\\ net\\ parameters\\ ξ：target\\ net\\ parameters\\ θ \u0026lt;- optimizer(θ),\\ \\ \\ ξ \u0026lt;- αξ + (1-α)θ $$\nDINO - 2021 Emerging Properties in Self-Supervised Vision Transformers\nViT最后的CLS注意力图示⭐⭐⭐\n探讨：质疑自监督学习是否为 Vision Transformer (ViT) 提供了比卷积网络 (convnets) 更突出的新属性？\n框架：(借鉴BYOL)\n教师是在训练过程中动态构建的。知识蒸馏就不再被用作自监督预训练的后处理步骤，而是直接作为自监督目标。\n其中学生和教师具有相同的架构并在训练期间使用蒸馏。\n教师在我们工作中用学生的动量平均值进行更新。\n增强策略：\n1. 多裁剪策略构建图像的不同扭曲视图或裁剪。 更准确地说，根据给定的图像，我们生成一组 V 的不同视图。 该集合包含两个全局视图 xg 1 和 xg 2 以及几个分辨率较小的局部视图。\r1. 所有的裁剪都通过学生传递，而只有全局观点通过老师传递，因此鼓励“局部到全局”的对应。\r伪代码：\n防止模型坍塌：\n1. *对动量教师输出进行居中和锐化，以避免模型崩溃。*\r2. **居中（Centering）**：对动量教师的输出进行居中操作是为了减少批次之间的偏差，增加输出的稳定性。具体做法是从每个输出中减去其均值，确保输出围绕零分布，这有助于避免网络输出在特征空间内偏向某一方向，从而降低了模型坍塌的风险。\r3. **锐化（Sharpening）**：锐化是通过增加输出分布的峰值来实现的，目的是使模型的输出更加区分明显，即使不同类别之间的区别更加清晰。这通常通过提高输出概率分布的熵来实现，比如可以采用温度调整（temperature scaling）等方法来调整概率分布，使得主要的概率值更加突出，而其他的概率值则相对降低。\r图示：\n不同颜色是不同的注意力头\n无监督注意力更能学到本质！\nSimSiam - CVPR 2021 Exploring Simple Siamese Representation Learning\n简单设计的Siamese(孪生)网络。 我们的极简主义方法的竞争力表明\n1️⃣ “没有动量编码器的 BYOL”\n2️⃣ “没有负样本的 SimCLR“ + stop-grad(⭐这个非常关键， 这个对防止模型坍塌很关键)\n方法：\n一幅图像的两个增强视图由同一编码器网络 f（主干网络加投影 MLP）处理。 然后在一侧应用预测 MLP-h，在另一侧应用停止梯度操作。 该模型最大化了双方之间的相似性。 它既不使用负对也不使用动量编码器。\n伪代码：\n消融\nLoss:\n负的余弦相似度 和 交叉熵\n相似度：\n交叉熵：\nBatchNorm的影响：\nBatchSize的影响：\n预测头的影响：\nLoss的对称性：\nsym对称；asym非对称；asym. 2×(每个图像采样两对来粗略地补偿对称性)\nSegment Anything 即时分割\n模型组件\n模型框架：\nprompt encoder：\nSparse prompts: point: point =\u0026gt; 256 dimensional vectorial embedding. 这个使用index去索引位置嵌入像Swin-T， foreground or backgroud embedding（自学习）. to add together. box: 左上角位置编码 + 左上角的学习嵌入；左上角位置编码+“右下角”的学习嵌入 text: clip的text encoder. dense prompts: mask: CNN =\u0026gt; 256 特征向量。有则加mask，没有就加可学习的表示无mask的学习嵌入 mask decoder：\nKNN(K-Nearest Neighbors) K-近邻算法\n核心思想：相似的样本具有相似的输出。\n=\u0026gt; KNN通过计算输入样本与训练数据集中所有样本的距离，找到距离最近的K个样本，然后根据这些样本的类别来决定输入样本的类别\n主要步骤:\n选择K值：选择一个正整数K，代表你要比较的邻居数量。\n计算距离：对每个待分类样本，计算它与训练数据集中所有样本的距离。常用的距离度量有欧氏距离、曼哈顿距离和余弦相似度等。\n$$ \\textbf{欧氏距离}: d(x, x_i) = \\sqrt{\\sum_{j=1}^{m}(x_j-x_{ij})^2} $$ 选择最近的K个邻居：根据计算得到的距离，从训练数据集中选择距离待分类样本最近的K个样本\n投票或加权：在分类任务中，K个邻居中最多的类别即为待分类样本的预测类别。在回归任务中，可以对K个邻居的数值进行平均或者加权平均。\n输出结果：输出投票或加权后的结果作为待分类样本的预测结果。\nPatchTST - ICLR 2023 Patchify .\n有监督 =\u0026gt; 可以重叠 自监督 =\u0026gt; 不可以重叠，避免网络可以从重叠区域走捷径学习 多变量独立：\n每个时间序列将有自己的潜在表示，通过共享权重机制交叉学习 ？？？\n共享Encoder权重，不同通道使用相同的模型参数。这种方法允许模型在不同的任务之间共享知识\nOverview\n1x = [batch, channel, length] 2x = [batch, channel, num_token, len_token] 3x = [batch*channel, num_sample, dim_hidden] 4 5=\u0026gt; Transformer Encoder but residual attn # 6 7=\u0026gt; Linear head =\u0026gt; CrossFormer - ICLR 2023 TRANSFORMER UTILIZING CROSSDIMENSION DEPENDENCY FOR MULTIVARIATE TIME SERIES FORECASTING\n创新点：\n显示建模时间依赖关系 + 通道依赖关系 两阶段注意力 （时间：MHSA，通道：Router MHSA） 嵌入方式 and 依据：\n自注意力呈现小局部一致性，一坨而不是一个。\n保持通道独立 ✔️ 注意力优化 ✔️ TwoStageAttention\n1# Step 1. Time Dependency 2x = [batch, channel, length] 3x = [batch, channel, num_patch, dim_patch] # \u0026lt;= DSW (Dimension-Segment-Wise) 4x = [batch*channel, num_patch, dim_patch] 5y = TransformerEncoer(x, x, x) # \u0026lt;= capture time dependency 6 7# Step 2. Channel Dependency 8y = [batch, channel, num_patch, dim_patch] 9y = [batch*num_patch, channel, dim_patch] 10router = [1, num_router, dim_patch] # \u0026lt;= router 11router =\u0026gt; repeat =\u0026gt; [*, num_router, dim_patch] 12z = TransformerEncoder(router, y, y) # \u0026lt;= capture channel dependency 13z = TransformerEncoder(y, router, router) 14 15# save per stage output 16=\u0026gt; Unet Decoder =\u0026gt; to predict ECG与多变量的异同：\n相似点 不同通道贡献不同 =\u0026gt; DSW-patch, 能够更加细粒度编码局部波形 == 多变量(通道) patch化的成功！！！ 不同点 由于是对心脏电活动的同一时间不同角度的观察 =\u0026gt; 病理位置相同 =\u0026gt;是否能够通过共享策略 降低计算成本🤔❓ Informer - AAAI 2021 Best \u0026ndash; TopK-Q\n观察：(Q\u0026amp;K 是等价的)\n注意力呈现长尾分布：\nQuery分为活跃于惰性Token\n衡量指标：\n注意力优化：\n1Q, K, V 2# probe 3K = [batch, num_head, len_token, dim_head] 4K_sample = [batch, num_head, random_len, dim_head] 5Q_K_sample = [batch, num_head, len_token, random_len] 6M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K) # 衡量指标 7M_top = M.topk(n_top, sorted=False)[1] 8 9Q_reduce = Q[:, :, M_top, :] 10attn_active = softmax(torch.matmul(Q_reduce, K.transpose(-2, -1))*scale) 11 12contex = V.sum(-2).expand() =\u0026gt; [batch, num_head, len_token, dim_head] # 均匀分布的就直接取V的均值 13contex[:, :, M_top, :] = attn_active@V 结构优化：\n1# Encoder: 2for num_layer ...: 3 x = attn(x) 4 x = conv_layer(x) # \u0026lt;- maxpool(act(norm(conv()))) 5return enc_out 1# Decoder: 2cross = enc_out 3x = # 预测引导 4for num_layer ...: 5 x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask) # Note：Masked MHSA-ProbeAttn 框架逻辑\n1Class Exp_Basic(Object): 2 def __init__(): 3 def _build_model(): 4 def _acquire_device(): 5 def _get_data(): 6 def train(): 7 def vali(): 8 def test(self): 9 10Class Exp_Model(Exp_Basic): 11 def _select_optimizer(): 12 def _select_criterion(): 13 def _process_on_batch(): 1# data_loader.py 2Class Dataset_XXX(Dataset): 3 def __init__(): 4 def __read_data__(self): 5 def __getitem__(self, index): 6 def __len__(self): 1# main.py 2 3parser = argparse.ArgumentParser(description=\u0026#39;[Model] Task\u0026#39;) 4... 5args = parser.parse_args() 6setting = ...args 7 8exp = Exp_Model(args) 9exp.train(setting) 10exp.test(setting) Adaptive Token Dictionary - CVPR2024 Transcending the Limit of Local Window: Advanced Super-Resolution Transformer with Adaptive Token Dictionary\n扩展局部窗口的限制\nwindow-based self-attention token dictionary cross-attention =\u0026gt; Attention(Q(XW),K(TW), V(TW)) 基于2的Attn，将token map排序分group(类)，进行group内部的Attention Architecture\nPoly Kernel Inception - CVPR 2024 Poly Kernel Inception Network for Remote Sensing Detection\n遥感图像中的目标检测面临着多种挑战，包括目标尺度变化大、测距环境多样等。现有的方法试图通过大核卷积或扩张卷积来扩展脊柱的空间感受野来解决这些挑战。然而，前者通常会引入相当大的背景噪声，而后者则有生成过度稀疏的特征表示的风险。本文提出了一种多核初始化网络（PKINet）来解决上述问题。PKINet采用无膨胀的多尺度卷积核来提取不同尺度的对象特征并捕获局部上下文。此外，一个上下文锚注意（CAA）模块并行引入捕获远程上下文信息。\n不同尺度-局部上下文 并行引入捕获远程上下文信息 1# 十字架型汇聚 =\u0026gt; 近似标准的DWConvKxK =\u0026gt; 降低参数量 2agg = Conv1x1(AvgPool(X)) 3agg = Conv1x1(DWConvKx1(DWConv1xK(agg))) 4attn = Sigmoid(agg) DANet - CVPR 2019 Dual Attention Network for Scene Segmentation\nAt the end of the model, we use the dual attention mechanism to explicitly capture position and channel dependencies.\n1class PAM_Module(Module): 2 \u0026#34;\u0026#34;\u0026#34; Position attention module\u0026#34;\u0026#34;\u0026#34; 3 #Ref from SAGAN 4 def __init__(self, in_dim): 5 super(PAM_Module, self).__init__() 6 self.chanel_in = in_dim 7 8 self.query_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1) 9 self.key_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1) 10 self.value_conv = Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1) 11 self.gamma = Parameter(torch.zeros(1)) 12 13 self.softmax = Softmax(dim=-1) 14 def forward(self, x): 15 \u0026#34;\u0026#34;\u0026#34; 16 inputs : 17 x : input feature maps( B X C X H X W) 18 returns : 19 out : attention value + input feature 20 attention: B X (HxW) X (HxW) 21 \u0026#34;\u0026#34;\u0026#34; 22 m_batchsize, C, height, width = x.size() 23 proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1) 24 proj_key = self.key_conv(x).view(m_batchsize, -1, width*height) 25 energy = torch.bmm(proj_query, proj_key) 26 attention = self.softmax(energy) 27 proj_value = self.value_conv(x).view(m_batchsize, -1, width*height) 28 29 out = torch.bmm(proj_value, attention.permute(0, 2, 1)) 30 out = out.view(m_batchsize, C, height, width) 31 32 out = self.gamma*out + x 33 return out 34 35 36class CAM_Module(Module): 37 \u0026#34;\u0026#34;\u0026#34; Channel attention module\u0026#34;\u0026#34;\u0026#34; 38 def __init__(self, in_dim): 39 super(CAM_Module, self).__init__() 40 self.chanel_in = in_dim 41 42 43 self.gamma = Parameter(torch.zeros(1)) 44 self.softmax = Softmax(dim=-1) 45 def forward(self,x): 46 \u0026#34;\u0026#34;\u0026#34; 47 inputs : 48 x : input feature maps( B X C X H X W) 49 returns : 50 out : attention value + input feature 51 attention: B X C X C 52 \u0026#34;\u0026#34;\u0026#34; 53 m_batchsize, C, height, width = x.size() 54 proj_query = x.view(m_batchsize, C, -1) 55 proj_key = x.view(m_batchsize, C, -1).permute(0, 2, 1) 56 energy = torch.bmm(proj_query, proj_key) 57 energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy)-energy 58 attention = self.softmax(energy_new) 59 proj_value = x.view(m_batchsize, C, -1) 60 61 out = torch.bmm(attention, proj_value) 62 out = out.view(m_batchsize, C, height, width) 63 64 out = self.gamma*out + x 65 return out MixNet MixConv: Mixed Depthwise Convolutional Kernels\nconvulution =\u0026gt; capture local pattern\nearly stages: edges later stages: objects⭐ 这项研究表明了单个内核大小的局限性：我们既需要大内核来捕获高分辨率模式，也需要小内核来捕获低分辨率模式，以获得更好的模型精度和效率\n在单一机制下实现多种效果，进行增强\nMultimodal Learning Multimodal Learning With Transformers: A Survey\n融合策略\nDual Aggregation Transformer Dual Aggregation Transformer for Image Super-Resolution\nMotivation: 现有方法利用自我注意沿着不同的维度，空间或通道，并取得了令人印象深刻的性能。这启发我们将Transformer中的两个维度结合起来，以获得更强大的表示能力。\nDual Vision Transformer 研究全局语义和更精细的像素级特征之间的依赖关系 =\u0026gt; pixel-level token \u0026amp; semantic token\n分解和集成的全局语义和本地功能\nFish-Speech Tech-report Text-to-Speech End2End Model\n两阶段训练策略：\nStage 1:\nAudio:Mel Spectrogram =\u0026gt; 【Encoder】 =\u0026gt; Embedding =\u0026gt; Quantize Tokens =\u0026gt; 【⭐Decoder⭐】=\u0026gt; Audio\r**⭐重构目标⭐**\rStage 2:\nText:Quantize Tokens =\u0026gt; 【✨AR Model✨】=\u0026gt; Quantize Tokens ⭐**Text:Audio一致性 + 自回归预测Next**⭐\rInference:\nText:Prompt-Tokens =\u0026gt; 【✨AR Model✨】=\u0026gt; Quantize Tokens =\u0026gt; 【⭐Decoder⭐】=\u0026gt; Audio\rVector Quantize Tech:\nExample：\n1有一组连续的温度数据（如 20.3°C, 21.7°C, 22.5°C, 19.8°C），你想将其离散化为几个类别: 21.低温: 15°C - 20°C 32.中温: 20°C - 25°C 43.高温: 25°C - 30°C 5=\u0026gt; 620.3°C → 中温 721.7°C → 中温 822.5°C → 中温 919.8°C → 低温 10 11假设编码本有 512 个向量 Shape:[512, dim] 12Encoder得到的Embedding Shape:[T, dim] 13对于 Encoder 输出的每个时间步的特征向量，VQ 会找到编码本中与之最接近的向量，并用其索引表示。 14最终输出是一个离散的索引序列，例如 [42, 123, 87, ...]，每个索引对应编码本中的一个向量。 15 16编码本随机初始化，在训练过程中，编码本会通过梯度下降和优化算法（如 Adam）不断更新： 17最近邻搜索 =\u0026gt; 量化误差计算 =\u0026gt; 梯度更新,BP 18编码本的作用 =\u0026gt; 降维与压缩 + 离散化表示 + 提升生成质量(通过离散化减少生成过程中的模糊性，提升生成语音的自然度s) Blip Image-2-Text 任务之一 Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation Architecture\n相同颜色共享参数\nStage 1：\nImage =\u0026gt; 【Image Encoder:ViT】 =\u0026gt; image Embedding\nText =\u0026gt; 【Text Encoder:Bert】 =\u0026gt; text Embedding\n目标：图文一致性, 训练Encoder\nStage 2：\nImage =\u0026gt; 【Image Encoder:ViT:Freeze🥶】 =\u0026gt; image Embedding\nText =\u0026gt; 【Text Encoder:Bert:Freeze🥶 + Cross-Attention:image Embedding🥵】 =\u0026gt; Linear:2class\n目标：图文是否匹配-2分类, 训练Cross-Attention部分\nStage 3:\nImage =\u0026gt; 【Image Encoder:ViT:Freeze🥶】 =\u0026gt; image Embedding\nText =\u0026gt; 【Text Decoder:GPT🥵 + Cross-Attention:image Embedding:Freeze🥶】 =\u0026gt; Linear:multi-class\n目标：Image Embedding + text 自回归预测Next\nInference\nImage =\u0026gt; 【⭐Image Encoder⭐】 =\u0026gt; image Embedding\nPrompt-Text =\u0026gt; 【⭐Text Decoder:GPT⭐ + Cross-Attention:image Embedding:⭐】 =\u0026gt; Linear:multi-class =\u0026gt; Next-Token\n实现Image =\u0026gt; Text\nBEVFormer BEVFormer: Learning Bird’s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers\n网络架构信息流思路：\n具体：\n一组可学习的BEV Queries，二维网格，模拟鸟瞰图； Spatial Cross Attention，每个视图经过backone提取，拿其中多个层级的输出，拼接为多尺度特征(多个层的特征图，校准通道)。然后每个位置的q，只查询对应几个视图的周边几个k； Temporal Attention，t时刻的BEV中的q，查询t-1时刻，相应位置周边的几个k。 这里的t-1时刻的BEV特征，需要通过一个角度还是啥校准空间对齐； Deformable DETR architecture figure：\nAttn figure：\n1# 伪代码 - 单尺度的 2import torch 3import torch.nn as nn 4import torch.nn.functional as F 5 6class DeformableAttention(nn.Module): 7 def __init__(self, embed_dim, num_heads, num_points): 8 super().__init__() 9 self.embed_dim = embed_dim 10 self.num_heads = num_heads 11 self.num_points = num_points 12 13 # 用于预测采样偏移的线性层 14 self.offset_proj = nn.Linear(embed_dim, num_heads * num_points * 2) 15 16 # 用于计算注意力权重的线性层 17 self.attn_proj = nn.Linear(embed_dim, num_heads * num_points) 18 19 # 输出投影层 20 self.out_proj = nn.Linear(embed_dim, embed_dim) 21\t22 # reference_points, 每个采样点初始，共用同一个reference_point，靠offset进行局部位置偏移 23 def forward(self, query, reference_points, value): 24 B, N, C = query.shape 25 H, W = value.shape[-2:] 26 27 # 预测采样偏移 28 offsets = self.offset_proj(query).view(B, N, self.num_heads, self.num_points, 2) 29 30 # 生成采样点 31 sampling_points = reference_points.unsqueeze(2) + offsets 32 33 # 双线性插值采样特征值 34 sampled_value = F.grid_sample( 35 value, 36 sampling_points.view(B, -1, H, W, 2), 37 mode=\u0026#39;bilinear\u0026#39;, 38 align_corners=True 39 ).view(B, N, self.num_heads, self.num_points, C // self.num_heads) 40 41 # 计算注意力权重 42 attn_weights = self.attn_proj(query).view(B, N, self.num_heads, self.num_points) 43 attn_weights = F.softmax(attn_weights, dim=-1) 44 45 # 加权求和 46 output = (sampled_value * attn_weights.unsqueeze(-1)).sum(dim=3) 47 output = output.view(B, N, C) 48 49 # 输出投影 50 output = self.out_proj(output) 51 52 return output ","permalink":"http://121.40.252.207/posts/learning/paper_reading2/","summary":"\u003ch3 id=\"cam----cvpr-2015\"\u003e\u003cstrong\u003eCAM\u003c/strong\u003e  - CVPR 2015\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eLearning Deep Features for Discriminative Localization\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e弱监督对象定位\u003c/strong\u003e  - 仅提供Image level label\u003c/p\u003e\n\u003cp\u003e期望：每个单元被其感受野内的某种视觉模式激活。因此 fk （表示空间位置 (x, y) 处最后一个卷积层中单元 k 的激活//输出特征图的一个像素）是该视觉模式存在的地图。类激活图只是这些视觉模式在不同空间位置的存在的加权线性和\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e计算卷积特征图对于特定输出单元的重要性来实现的\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e⭐⭐⭐网络可以保留其卓越的定位能力，直到最后一层   =\u0026gt; 深层特征的定位能力\u003c/p\u003e\n\u003cp\u003e❗❗❗尽管接受了图像级标签的训练，CNN 仍具有出色的对象定位能力\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺陷\u003c/strong\u003e：卷积特征图→全局平均池化→softmax层  // 特定网络结构\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240322134603157\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FizSzlSfuX9fZOO_3HduKDclEzcI\"\u003e\u003c/p\u003e\n\u003ccenter style=\"color: red; font-weight: bold;\"\u003e做法图示\u003c/center\u003e\r\n\u003cp\u003e\u003cimg alt=\"image-20240322134441902\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FiBRel9zde6IJ3STCIWgQtDspaZx\"\u003e\u003c/p\u003e\n\u003ccenter style=\"color: red; font-weight: bold;\"\u003e数学公式\u003c/center\u003e\r\n\u003cp\u003e在卷积特征图上执行全局平均池化，并将它们用作全连接层的特征，产生所需的输出分类;\u003c/p\u003e\n\u003cp\u003e❗❗❗将输出层的权重投影回卷积特征图来识别图像区域的重要性\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"grad-cam----iccv-2017\"\u003eGrad-CAM  - ICCV 2017\u003c/h3\u003e\n\u003cp\u003e适用CNN模型\u003c/p\u003e\n\u003cp\u003e但论文提到在CNN+LSTM的也能定位有区别的图像区域\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240322141249072\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FjU70VichK5n125Mrm0J9kJnVy43\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240322141305661\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FpssA7XV30OJ4BKmn1aDL-1GNYSa\"\u003e\u003c/p\u003e\n\u003cp\u003eα 捕获\u003cstrong\u003e特征图\u003c/strong\u003e k 对于目标\u003cstrong\u003e类\u003c/strong\u003e c 的\u003cstrong\u003e重要性\u003c/strong\u003e  // 与CAM的分类线性层权重作用一致\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240322141314248\" loading=\"lazy\" src=\"http://sthda9dn6.hd-bkt.clouddn.com/FoLeKuhJnfw8veLYf18fRWRhEy09\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReLU\u003c/strong\u003e的作用，只对对感兴趣的类别有积极影响的特征感兴趣。负像素可能属于图像中的其他类别\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e上述操作 =\u0026gt; 具有\u003cstrong\u003e类别区分性\u003c/strong\u003e并且可以很好地定位相关图像区域\u003c/em\u003e   - 最后特征图比较小!\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\t\t\t\t  但缺乏显示细粒度重要性的能力 （能区分猫狗，但对为什么识别为猫，不够精确）\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e通过点乘法融合 \u003cstrong\u003e引导反向传播\u003c/strong\u003e 和 \u003cstrong\u003eGrad-CAM\u003c/strong\u003e =\u0026gt; 可视化\u003c/p\u003e","title":"深度学习论文汇总2"},{"content":"Hi!\n","permalink":"http://121.40.252.207/about/","summary":"about","title":"About Me"}]